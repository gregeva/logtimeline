#!/opt/homebrew/bin/perl

# TO DO:

# - [In progress] Capture custom log message values for "count=" and "rowCount=" - if present could include it in the message totals
# - [Prototyping] group similar messages together with unique part replacement mask #### based on memory used >50MB and messages where count is 1 (only group the lower ones) option to change the number considered which would essetially create different sets of message groups
# - Adapt message field widths based on terminal width (object field and thread pool)
# - Add message parse pattern for AkkaCommunications logs

# - Filter options for min/max impact (count*duration)

# TO DO: the bytes for each message is captured, but not surfaced in the message results
# - add total counts for duration and bytes; what makes this harder to fit in is that there should obviously also be seperate counters for "highlight" (bottom of table makes sense, also summary table, or both)
# - Add AND match possibility for include and exclude using RegEx lookahead (?=.*word)
# - Second graph (stats): line chart showing evolution of some of the percentile stats in different colors (with points) 
# - Second graph (throughput): outbound throughput based on bytes returned
# - need to save X-axis charaters with all the information - when terminal width < X and all time windows on same day, omit printing the date on each line (instead print it at the start or end) - this saves 10 chars
# - adjust the adaptive time window sizes as now they are too small by default (typically a log file is 12-24 hours)
# - add a soft memory limit (after having made most of the tweaks) to avoid accidents in production reading large files with 100k's of different messages - will need to optimize performance of memory checking
# - multi-threaded file reading
# - Similar to JMC, percentile calculations should include the representative counts
# - BUG if the command line options are too long (i.e. with long regex) and output is specified, then the file name creation can fail as filename too long.  In this case, it should be truncated to a maxium file name length.


# BUGS
#
# - when many graph columns present, the line overflows down to the next, this seems that the width calculation of either the "values" or "rate" column is wrong and this is what is adding 1-2 extra characters
# - when using the -o flag, the provided command line options are used in the file name, however when using a long list of filters, the filename can be too long causing error - need to truncate the filename

# NOT PRIORITY BACKLOG
# - color and highlight CV and Z-score according to their values (want to make larger numbers jump out)
# - add pagination support for the summary overview and the top messages
# - add feature to auto-calculate time window bucket based on terminal height and min and max time range in file (this would be based on previous file reads, or better filesize) - would have to go thought all input files
# - reading duration should have a variable which will determine what the units are and this will depend on the detected log file.  For example nginx uses seconds, most other use milliseconds.  Then convert to MS before adding to the stats map so that you can mix and match files with different units.
# - add a feature to include/exclude HTTP status codes which would need to be converted to RegEx as 4xx isn't going to be found
# - add a feature to allow for grouping of various other log categories like ThreadPool or Object context (instead of errors)
# - performance improvement: leverage a temp file with cached file stats (log start/end times, num lines, ...) to start/stop reading the file when provided start/end time ranges based on guesses around filesize
# - support for live tailing

## LOG STRUCTURES ##
# RAC client: [2025-02-04T12:06:22.784] [TRACE] MessageStream - handling data from GAS with chunk size: 88
# TWX logs: 2025-02-04 12:05:57.481+0000 [L: DEBUG] [O: c.t.p.p.StreamEntryProcessor] [I: ] [U: ] [S: ] [P: ] [T: pool-6-thread-3] Stream Entry Block Size Threshold Reached...
# Tomcat access logs: 10.224.212.63 - - [02/Feb/2025:00:00:11 +0000] "GET /Thingworx/Metrics?x-thingworx-session=false HTTP/1.1" 200 17626 295
# Catalina.out: 20-Feb-2025 08:55:05.055 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/app/opt/apache-tomcat/webapps/Thingworx] has finished in [37,549] ms
# GC Logs
# [2024-12-17T06:10:16.351+0000][29576.409s][info][gc             ] GC(25524) Pause Full (G1 Evacuation Pause) 17047M->16380M(17408M) 2459.735ms
# [2024-12-17T06:10:16.351+0000][29576.409s][info][gc,cpu         ] GC(25524) User=4.73s Sys=0.01s Real=2.46s
# [2024-12-17T06:10:16.993+0000][29577.052s][info][gc,start       ] GC(25525) Pause Young (Concurrent Start) (G1 Evacuation Pause)
# [2024-11-21T18:36:30.300+0000][info][gc            ] GC(16) Pause Young (Normal) (G1 Evacuation Pause) 949M->685M(9216M) 106.703ms
# 2021-05-11T07:41:12.706+0000: 0.578: [GC pause (G1 Evacuation Pause) (young), 0.0069706 secs]


use strict;
use warnings;
use POSIX qw(strftime floor);
use Math::Round;
use Time::Piece;
use DateTime;
use Term::ReadKey;
use Getopt::Long;
use Term::ANSIColor;
use Time::HiRes qw(gettimeofday tv_interval);
use Proc::ProcessTable;
use List::Util qw(min max);
use Text::CSV;
use Text::CSV_PP;

# Change code page to UTF-8
if ($^O eq 'MSWin32') {
	system("chcp 65001 > nul");
}

# Start time
my $start_time = [gettimeofday];

# Configuration
my $version_number = "0.5.7";
my $log_base = 2;
my ( @rolling_window, @ORIGINAL_ARGV, @files_processed );
my $rolling_window_size = 5;					# Adjust this value as needed - more time buckets included in the rolling window will give better sample for Z-score
my $impact_time_exponent = 7;		# it was 5, and was weighting a few slow executions too heavily compared to frequent faster executions
my ( $bucket_size_minutes, $bucket_size_seconds, $print_seconds, $print_milliseconds, $print_version, $omit_empty, $omit_summary, $omit_rate, $omit_stats, $omit_durations, $omit_bytes ) = 0;
my ( $include_query_string, $include_session, $include_threadpool_summary ) = ( 0, 0, 0 );
my ( $current_memory_usage, $max_memory_usage, $end_time, $elapsed_total, $elapsed_read_files, $elapsed_initialize_empty_time_windows, $elapsed_calculate_statistics, $elapsed_normalize_data, $elapsed_group_similar_messages ) = ( 0,0,0,0,0,0,0,0,0 );
# this is where the counts of log entries are tallied across the time buckets
my ( %log_counts, %category_totals, %log_analysis, %log_messages, %log_stats, %log_threadpools, %threadpool_activity, %log_userdefinedmetrics );
my $max_log_message_length = 0;							# used to define the maximum key length of the log message bucket counts
my $mask_uuid;									# temporary command line option to mask UUIDs with HASH characters for grouping purposes (to be replaced by more generic group similar feature)
my $durations_graph_width = 0;
my ( $graph_count, $max_graph_width ) = ( 1, 0 );
my ( $graph_column_padding_all, $graph_column_padding_legend, $graph_column_padding_count, $graph_column_padding_other, $graph_column_padding_latency ) = ( 1, 0, 2, 1, 1 );	# used to add padding (removed from width) in normalize data function
my %graph_width;
my @graph_columns = qw( duration bytes );
my ( @printed_column_widths, @printed_column_spacing, @printed_column_names );
my ( @populated_graph_columns, @graph_threadpools_activity, @graph_user_defined_metrics );
my ( $print_durations, $track_memory ) = ( 0, 0 );
my ( $filter_duration_min, $filter_duration_max );
my ( $filter_bytes_min, $filter_bytes_max );
my $top_n_messages = 10;
my ( $write_messages_to_csv, $csv, $csv_fh, $csv_file_args ) = ( 0, undef, undef, "" );
my $total_lines_read = 0;
my $total_lines_included = 0;
my $total_lines_highlighted = 0;
my $legend_length = 0;
my $timestamp_length = 0;
my $filter_range_start = "";
my $filter_range_end = "";
my $filter_range_start_epoch = 0;
my $filter_range_end_epoch = 0;
my %filter_range_epoch = ( 'start' => 0, 'end' => 2521843200 );
my %result_range_epoch = ( 'start' => 0, 'end' => 2521843200 );
my %filter_range;
my $output_timestamp_format = "%Y-%m-%d %H:%M";
my $output_timestamp_min = 0;
my $output_timestamp_max = 0;
my( $exclude_regex, $include_regex, $highlight_regex, $threadpool_activity_regex, $user_defined_metrics, $user_defined_metrics_regex, $user_defined_metrics_pre_regex, $user_defined_metrics_post_regex );
my $pause_output = 0;
my $omit_values = 0;
my ( $sort_type, $sort_key ) = ( "count", "count" );
my ( $group_similar_sensitivity, $trend_value ) = ( "none" );
my ( @in_files, @output_columns );
my %in_files_matched;
my ($terminal_width, $terminal_height) = GetTerminalSize();
my %timestamp_cache;

# Define log bucket printing order
my @log_levels = (
    'FORCE-HL', 'FORCE',
    'ERROR-HL', 'ERROR', 'WARN-HL', 'WARN', 'INFO-HL', 'INFO', 
    'DEBUG-HL', 'DEBUG', 'TRACE-HL', 'TRACE', '5xx-HL', '5xx', 
    '4xx-HL', '4xx', '3xx-HL', '3xx', '2xx-HL', '2xx', '1xx-HL', 
    '1xx', 'Pause Young-HL', 'Pause Young', 'Pause Full-HL', 'Pause Full',
    'err-rate', 'msg-rate', 'empty'
);

my %blocks = (
    'A' => '█',    # Full block
    'B' => '▓',    # Heavy shading
    'C' => '▒',    # Medium shading
    'D' => '░',    # Light shading
    'E' => '▪',    # Black Square
    'F' => '▫',    # White Square
    'G' => '☰',    # Menu
    'H' => '•',    # Bullet Point
    'I' => '■',    # Black Very Heavy
    'J' => '□'     # White square
);
my $default_chart_block = $^O ne 'MSWin32' ? "A" : "A";   # had initially set it to I for Windows

my %colors = (
    'FORCE' => "\033[0;35m",
    'ERROR' => "\033[0;31m",
    'WARN'  => "\033[0;33m",
    'INFO'  => "\033[0;32m",
    'DEBUG' => "\033[0;34m",
    'TRACE' => "\033[0;35m",
    '1xx'  => "\033[0;34m",
    '2xx'  => "\033[0;32m",
    '3xx'  => "\033[0;35m",
    '4xx'  => "\033[0;33m",
    '5xx'  => "\033[0;31m",
    'Pause Young' => "\033[0;35m",
    'Pause Full' => "\033[0;31m",
    'err-rate' => "\033[91m\033[109m",
    'msg-rate'    => "\033[0m",
    'NC'    => "\033[0m",
    'black' => "\033[30m\033[49m",
    'red' => "\033[0;31m",
    'green'  => "\033[0;32m",
    'yellow'  => "\033[0;33m",
    'blue'  => "\033[0;34m",
    'magenta' => "\033[35m\033[49m",
    'cyan' => "\033[36m\033[49m",
    'white' => "\033[36m\033[37m",
    'bright-black' => "\033[90m\033[109m",
    'bright-red' => "\033[91m\033[109m",
    'bright-green' => "\033[92m\033[109m",
    'bright-yellow' => "\033[93m\033[109m",
    'bright-blue' => "\033[94m\033[109m",
    'bright-magenta' => "\033[95m\033[109m",
    'bright-cyan' => "\033[96m\033[109m",
    'bright-white' => "\033[97m\033[109m",
    'black-underline' => "\033[4;30m",
    'red-underline' => "\033[4;31m",
    'green-underline' => "\033[4;32m",
    'yellow-underline' => "\033[4;33m",
    'blue-underline' => "\033[4;34m",
    'magenta-underline' => "\033[4;35m",
    'cyan-underline' => "\033[4;36m",
    'white-underline' => "\033[4;37m"
);

# Standard 8 Colors: Uses codes like \e[30m for black, \e[31m for red, etc.
# Bright 8 Colors: Uses codes like \e[90m for bright black (grey), \e[91m for bright red, etc.
# 256 Colors: Uses codes like \e[38;5;<color_code>m for foreground and \e[48;5;<color_code>m for background.
# True Color (24-bit): Uses codes like \e[38;2;<r>;<g>;<b>m for foreground and \e[48;2;<r>;<g>;<b>m for background.

# Create new keys with -HL and yellow background
foreach my $key (keys %colors) {
    next if $key eq 'NC';  # Skip NC
    my $new_key = "$key-HL";
    
    my $original_fg_color = $colors{$key}; # Get original foreground

    # Extract the original colour code from the FG code
    $original_fg_color =~ s/^\e\[(.*?)m/$1/g;

    my $bg_color_256;
    if ($original_fg_color eq "0;31") {    # Red
        $bg_color_256 = "196";            # 256-color code for Red
    } elsif ($original_fg_color eq "0;33") { # Yellow
        $bg_color_256 = "226";            # 256-color code for Yellow
    } elsif ($original_fg_color eq "0;32") { # Green
        $bg_color_256 = "46";             # 256-color code for Green
    } elsif ($original_fg_color eq "0;34") { # Blue
        $bg_color_256 = "21";             # 256-color code for Blue
    } elsif ($original_fg_color eq "0;35") { # Magenta
        $bg_color_256 = "201";            # 256-color code for Magenta
    } else {
        $bg_color_256 = "0";              # Black background as default
    }

    #$colors{$new_key} = "\033[48;5;${bg_color_256}m${white_fg}";
    $colors{$new_key} = "$colors{$key}\033[48;5;${bg_color_256}m";
    #print "$colors{$key}$key$colors{'NC'} -- HIGHLIGHT -- $colors{$new_key}$new_key$colors{'NC'}\n";
}

## SUBS ##

# utility function for formating numbers to normal format
sub normalize { $_[0] =~ s/\.0+$//r }

# utility functions for trimming spaces off of a string
sub ltrim { my $s = shift; $s =~ s/^\s+//; return $s }
sub rtrim { my $s = shift; $s =~ s/\s+$//; return $s }
sub trim  { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s }

sub print_title {
    my $title = <<"END";
\033[0;37m \033[90m\033[109m
──────────────────────────────────────────────────────────────────────────────────────────────
   ,:: ltl ::' log timeline [$version_number] --  by Greg Eva // geva\@ptc.com // gregeva\@gmail.com
──────────────────────────────────────────────────────────────────────────────────────────────
\033[0m
END
    print $title;
    return;
}

sub print_usage {
    my ( $error_reason ) = @_;
    print "Usage: $0 [--bucket-size|-bs <time block>] [--pause|-p] [--start|-st <YYYY-MM-DD HH:MM:SS>] [--end|-et <HH:MM>] [--exclude|-e <RegEx>] [--include|-i <RegEx>] [--highlight|-h <RegEx>] [--seconds|-s] [--milliseconds|-ms] [--output-csv|-o] [--omit-values|-ov] [--omit-stats|-os] [--omit-empty|-oe] [--omit-summary|-osum] [--omit-rate|-or] [--omit-durations|-od] [--omit-bytes|-ob] [--include-query-string|-iqs] [--include-session|-is] [--duration-min|-dmin <value>] [--duration-max|-dmax <value>] [--bytes-min|-bmin <value>] [--bytes-max|-bmax <value>] [--sort|-so count,duration,bytes,impact] [--threadpool-activity-summary|-tpas] [--threadpool-activity|-tpa <RegEx>] [--mask-uuid|-uuid] [--version|-v] <file1> <file2> ...\n";
    print "\n  Error: $error_reason\n";
    return;
}

sub print_version {
    print "Version: $version_number\n\n";
    return;
}

# Function to get current memory usage
sub get_memory_usage {
    my $memory_usage;

    if ($^O eq 'darwin' || $^O eq 'linux') {
        # For Mac OS and Debian (Linux)
        eval {
            require Proc::ProcessTable;
            my $t = Proc::ProcessTable->new();
            ($memory_usage) = map { $_->rss } grep { $_->pid == $$ } @{$t->table};
        };
        if ($@) {
            die "Failed to load Proc::ProcessTable: $@";
        }
    } elsif ($^O eq 'MSWin32') {
        # For Windows
        eval {
            require Win32::Process::Info;
            Win32::Process::Info->import();  # Explicitly call import
            my $pi = Win32::Process::Info->new();
            my $info = $pi->GetProcInfo();
            ($memory_usage) = map { $_->{WorkingSetSize} } grep { $_->{ProcessId} == $$ } @$info;
        };
        if ($@) {
            die "Failed to load Win32::Process::Info: $@";
        }
    } else {
        die "Unsupported operating system: $^O";
    }

    return $memory_usage;
}

sub convert_bytes {
    my ($input_value, $input_unit) = @_;
    my ($value, $unit);

    if( defined( $input_unit ) ) {
        $value = $input_value;
        $unit = $input_unit;
    } else {
        ( $value, $unit ) = $input_value =~ /^(\d+)[ ]?(\w+)$/;
    }

    my %units = (
        'B'  => 1,
        'b'  => 1,
        'kB' => 1024,
        'KB' => 1024,
        'k' => 1024,
        'K' => 1024,
        'MB' => 1024**2,
        'M' => 1024**2,
        'GB' => 1024**3,
        'G' => 1024**3,
        'TB' => 1024**4,
        'T' => 1024**4,
    );

    # Convert input value to bytes
    my $bytes = $value * $units{$unit};

    return $bytes;
}

sub format_bytes {
    my ($value, $unit) = @_;
    my %units = (
        'b'  => 1,
        'B'  => 1,
        'kB' => 1024,
        'MB' => 1024**2,
        'GB' => 1024**3,
        'TB' => 1024**4,
    );

    return undef unless defined $value;
    # Convert input value to bytes
    my $bytes = $value * $units{$unit};

    # Determine the most relevant unit
    my @unit_order = ('B', 'kB', 'MB', 'GB', 'TB');
    my $formatted_value = $bytes;
    my $formatted_unit = 'B';

    foreach my $u (@unit_order) {
        if( length( $bytes ) >= length( $units{$u} ) ) {
# TO DO: 1000kB should convert to MB
        #if ($bytes >= $units{$u}) {
            $formatted_value = $bytes / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    # Format the value to 1 decimal place
    $formatted_value = sprintf("%.1f", $formatted_value);
    $formatted_value =~ s/\.0//;

    return "$formatted_value $formatted_unit";
}

sub format_number {
    my ($value, $space, $decimals) = @_;
    my %units = (
        '1'  => 1,
        'k' => 1000,
        'Mil' => 1000**2,
        'Bil' => 1000**3,
        'Tril' => 1000**4,
    );

    # Determine the most relevant unit
    my @unit_order = ('1', 'k', 'Mil', 'Bil', 'Tril');
    my $formatted_value = $value;
    my $formatted_unit = '';
    $decimals = 1 if !defined $decimals;

    foreach my $u (@unit_order) {
        if ($value >= $units{$u}) {
            $formatted_value = $value / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    # Format the value to 1 decimal place
    $formatted_value = sprintf("%.${decimals}f%s%s", $formatted_value, defined($space) ? " " : "", $formatted_unit eq "1" ? "" : $formatted_unit );
    $formatted_value =~ s/\.0//;

    return $formatted_value;
}

sub format_time {
    my ($value, $unit, $format, $space) = @_;
    my %units = (
        'us' => 1,                      # Microseconds
        'ms' => 1000,                   # Milliseconds
        's'  => 1000000,                # Seconds
        'm'  => 60 * 1000000,           # Minutes
        'h'  => 60 * 60 * 1000000,      # Hours
        'D'  => 24 * 60 * 60 * 1000000, # Days
    );

    my %unit_names = (
        'us' => { short => 'us', medium => 'usec', long => 'microseconds' },
        'ms' => { short => 'ms', medium => 'msec', long => 'milliseconds' },
        's'  => { short => 's',  medium => 'sec',      long => 'seconds' },
        'm'  => { short => 'm',  medium => 'min',      long => 'minutes' },
        'h'  => { short => 'h',  medium => 'hr',       long => 'hours' },
        'D'  => { short => 'd',  medium => 'day',      long => 'days' },
    );

    $format = "short" if !defined $format;

    # Convert input value to microseconds
    my $microseconds = $value * $units{$unit};

    # Determine the most relevant unit
    my @unit_order = ('us', 'ms', 's', 'm', 'h', 'D');
    my $formatted_value = $microseconds;
    my $formatted_unit = 'us';

    foreach my $u (@unit_order) {
        if ($microseconds >= $units{$u}) {
            $formatted_value = $microseconds / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    # Format the value to 1 decimal place
    $formatted_value = sprintf("%.1f", $formatted_value);
    $formatted_value =~ s/\.0+$//;

    # Get the appropriate unit name based on the format
    my $unit_name = $unit_names{$formatted_unit}{$format};
    $unit_name = " " . $unit_name if defined( $space );

    return defined $value ? "$formatted_value$unit_name" : undef;
}

sub adapt_to_command_line_options {
    @ORIGINAL_ARGV = @ARGV;

    # Get command-line options
    GetOptions(
        'bucket-size|bs=i' => \$bucket_size_minutes,
        'pause|p' => \$pause_output,
        'start|st=s' => \$filter_range_start,
        'end|et=s' => \$filter_range_end,
        'exclude|e=s' => \$exclude_regex,
        'include|i=s' => \$include_regex,
        'highlight|h=s' => \$highlight_regex,
        'top-messages|n=i' => \$top_n_messages,
        'omit-values|ov' => \$omit_values,
        'omit-stats|os' => \$omit_stats,
        'omit-empty|oe' => \$omit_empty,
        'omit-summary|osum' => \$omit_summary,
        'omit-rate|or' => \$omit_rate,
        'omit-durations|od' => \$omit_durations,
        'omit-bytes|ob' => \$omit_bytes,
        'include-query-string|iqs' => \$include_query_string,
        'include-session|is' => \$include_session,
        'seconds|s' => \$print_seconds,
        'milliseconds|ms' => \$print_milliseconds,
        'version|v' => \$print_version,
        'duration-min|dmin=i' => \$filter_duration_min,
        'duration-max|dmax=i' => \$filter_duration_max,
        'bytes-min|bmin=i' => \$filter_bytes_min,
        'bytes-max|bmax=i' => \$filter_bytes_max,
	'memory-usage|mem' => \$track_memory,
        'output-csv|o' => \$write_messages_to_csv,
        'sort|so=s' => \$sort_type,
        'threadpool-activity-summary|tpas' => \$include_threadpool_summary,
        'threadpool-activity|tpa=s' => \$threadpool_activity_regex,
        'user-defined-metrics|udm=s' => \$user_defined_metrics,
        'mask-uuid|uuid' => \$mask_uuid,
        'group-similar|g=s' => \$group_similar_sensitivity
    ) or die print_usage( "required options not provided" ); 

    $filter_range{'start'} = $filter_range_start if defined( $filter_range_start );
    $filter_range{'end'} = $filter_range_end if defined(  $filter_range_end );

    if( $print_version ) {
        print_version();
        exit;
    }

    # Ensure at least one file is provided
    #@in_files = @ARGV;

    foreach my $pattern (@ARGV) {									# do in process file globbing for common experience across environments (Windows doesn't glob in the shell, passes in the parameters)
        push @in_files, glob($pattern);
    }

    die print_usage( "unable to open any files" ) unless @in_files;
    die print_usage( "invalid sort type used" ) unless grep { $_ eq $sort_type } qw( count duration time bytes impact );

    if( $sort_type =~ /^duration|time$/i ) {
        $sort_key = "total_duration_num";
    } elsif( $sort_type =~ /^bytes$/i ) {
        $sort_key = "total_bytes";
    } elsif( $sort_type =~ /^impact$/i ) {
        $sort_key = "impact";
    }

# bookmark24
    if( defined $user_defined_metrics ) {
        my $separator = qr/\s*[=:]?\s*/;
        #my $number = qr/-?\d{1,3}(?:[ ,]?\d{3})*(?:\.\d+)?/;								# Number pattern with optional negative, thousands separators, and decimals
        my $number = qr/-?\d+(?:\.\d+)?/;								# Number pattern with optional negative, thousands separators, and decimals
        $user_defined_metrics_regex = join( '|', split( ',', $user_defined_metrics ) );

        foreach my $user_metric ( split( ',', $user_defined_metrics ) ) {
            my $metric = quotemeta($user_metric);  # Escape special characters

            $user_defined_metrics_pre_regex .= qr/\s+$metric$separator(?<$metric>$number)/x;
            $user_defined_metrics_post_regex .= qr/(?<$metric>$number)$separator$metric\s+/x;
            #$user_defined_metrics_post_regex .= qr/(?<${metric}>-?\d+(?:\.\d+)?)\s*[=:]?\s*${metric}\s+/;
            #$user_defined_metrics_post_regex = qr/(?<rows>-?\d+(?:\.\d+)?)\s*[=:]?\s*rows/;


#            $user_defined_metrics_regex .= "${metric}[ =:](<${metric}>?[0-9.])";
        }

#print "udm: $user_defined_metrics\t\tudm regex: $user_defined_metrics_regex udm: metrics post regex: $user_defined_metrics_post_regex\n";

    }

    $output_timestamp_format .= ":%S" if $print_seconds || $print_milliseconds;
    #$bucket_size_seconds = $print_seconds ? $bucket_size_minutes : $bucket_size_minutes * 60;		# if they say they want milliseconds, we're going to assume that their bucket sizes are in seconds instead
    if( $print_seconds ) {
        $bucket_size_seconds = $bucket_size_minutes;
    } elsif( $print_milliseconds ) {
        $bucket_size_seconds = $bucket_size_minutes / 1000;
    } else {
        $bucket_size_seconds = $bucket_size_minutes * 60;
    }

    my %argv_hash = map { $_ => 1 } @ARGV;
    foreach my $arg (@ORIGINAL_ARGV) {
        unless (exists $argv_hash{$arg}) {
            $csv_file_args .= "$arg" if $write_messages_to_csv;
        }
    }

    return;
}

# Parse various possible formats for input of start and end times and set associated filter variables
sub calculate_start_end_filter_timestamps {
    my ( $log_time ) = @_;
    my $log_date = $log_time->epoch() - ( $log_time->hour * ( 60 * 60 ) + $log_time->minute * 60 + $log_time->second );

    foreach my $key (keys %filter_range) {
        my $value = $filter_range{$key};  # Get the value (either $filter_range_start or $filter_range_end)
        next unless length( $filter_range{$key} ) > 0;
        my $epoch_value;  # Variable to store the epoch time

        # Convert timestamp to epoch seconds using Time::Piece -- WARNING -- use of strptime can cause timezone problems, it appears to work here as I've manually set TZ to UTC on input
        if ( $value =~ /^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{2}:\d{2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d %H:%M:%S" )->epoch;
        } elsif ( $value =~ /^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d %H:%M" )->epoch;
        } elsif ( $value =~ /^\d{4}-\d{1,2}-\d{1,2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d" )->epoch;
        } elsif ( $value =~ /^\d{1,2}:\d{2}:\d{2}/ ) {
            $epoch_value = $log_date + Time::Piece->strptime( $value, "%H:%M:%S" )->epoch;
        } elsif ( $value =~ /^\d{1,2}:\d{2}/ ) {
            $epoch_value = $log_date + Time::Piece->strptime( $value, "%H:%M" )->epoch;
        } else {
            print "Warning: unhandled date/time format - option not taken into account\n";
        }

        #print "Epoch value in seconds: $epoch_value\n";
        $filter_range_epoch{$key} = $epoch_value if defined( $epoch_value );  # Store the epoch value in the hash
    }
    return 1;
}

sub adapt_to_terminal_settings {
    $terminal_width //= 80; # Default to 80 if terminal width cannot be determined
    $terminal_height //= 24; # Default to 24 if terminal height cannot be determined

    # Auto-adjust the bucket size based on the terminal height (larger terminal can handle more rows)
    if( $terminal_height <= 24 ) {
        $bucket_size_minutes = 60;
    } elsif( $terminal_height <= 45 ) {
        $bucket_size_minutes = 30;
    } elsif( $terminal_height <= 65 ) {
        $bucket_size_minutes = 10;
    } elsif( $terminal_height <= 85 ) {
        $bucket_size_minutes = 5;
    } elsif( $terminal_height > 85 ) {
        $bucket_size_minutes = 1;
    } else {
        $bucket_size_minutes = 60;
    }
    #print "Terminal is: $terminal_width x $terminal_height -- Bucket size: $bucket_size_minutes\n";

    $max_log_message_length = $terminal_width;		# this is the max that we can print without wrapping, depends on the summary table width, and terminal width 
    return;
}

sub pause_for_keypress {
    my ($prompt) = @_;  # Get the optional prompt message
    $prompt = "Press any key to continue (or Q to quit)..." unless defined $prompt;
    print "\033[0;44m$prompt\033[0m";

    ReadMode 4;  # Turn off line buffering
    my $key = ReadKey(0);
    ReadMode 0;  # Restore normal input mode

    if (defined $key) {
        if ($key eq "q" || $key eq "Q") {
            print "\r";
            print " " x length( $prompt );
            print "\r\033[0;35mExiting program.\033[0m\n";
            exit 0;
        } else {
            print "\r";
            print " " x length( $prompt );
            print "\r";
            return 1;  # Return a value indicating "continue"
        }
    } else {
        print "\r";
        print " " x length( $prompt );
        print "\r";
        return 1;
    }
}

# Parse logs, bucket by time, and count log levels
sub read_and_process_logs {
    %in_files_matched = map { $_ => 0 } @in_files;			# set hash key per file to match boolean = false

    foreach my $in_file (@in_files) {
        open my $fh, '<', $in_file or die "Cannot open file: $in_file";
        push @files_processed, $in_file;
        my $line_number = 0;
        my $filter_range_filter_initialized = 0;
        my %month_map = ( Jan => 1, Feb => 2, Mar => 3, Apr => 4, May => 5, Jun => 6, Jul => 7, Aug => 8, Sep => 9, Oct => 10, Nov => 11, Dec => 12 );
        my( $file_name ) = $in_file =~ /(.+)(\W\d{4,}).+$/;

        while (<$fh>) {
            $line_number++;
            my ( $timestamp_str, $log_level, $category_bucket, $category, $object, $instance, $user, $platform, $thread, $threadpool, $session, $message ) = ("") x 12;
            my ( $is_line_match, $is_access_log, $match_type, $status_code, $heap_from, $heap_to, $heap_size ) = ( 0, 0, 0, 0, 0, 0, 0 );
            my ( $bytes, $duration, $count ) = ( undef, undef, undef );
            my ( $timestamp, $threadname );							# I actually don't want these to be defined
            $total_lines_read++;

            if ($line_number % 997 == 0) {	# only print processing status update every X lines processed
                printf("\rProcessing line %d in file %s (%d overall)", $line_number, $in_file, $total_lines_read);
                $| = 1; # Flush output
            }

            if ($track_memory && $line_number % 100000 == 0) {								# only collect memory in use around every 100000 lines processed
                $current_memory_usage = get_memory_usage();								# track maximum memory usage
                if ($current_memory_usage > $max_memory_usage) {
                    $max_memory_usage = $current_memory_usage;
                }
            }

# bookmark1
            ## ThingWorx Standard Log Format (ApplicationLog, ErrorLog, ScriptLog, ...) ##
            if ( ($timestamp_str, $category_bucket, $object, $instance, $user, undef, $platform, $thread, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3})[\+\-]\d{4} \[L: ([^\]]*)\] \[O: ([^\]]*)] \[I: ([^\]]*)] \[U: ([^\]]*)] \[S: ([^\]]*)] \[P: ([^\]]*)] \[T: ([^\]]*)] (.*)/) {
                $is_line_match = 1;
                $match_type = 1;			# this is matching ThingWorx standard log format 2025-02-04 12:05:57.481+0000 [L: DEBUG] 
#                $thread =~ s/(.*)-\d+$/$1/;

                # this section is optional, for cases where log line has included additional context which should be interpretted (row count, execution duration, result size)
                ( $bytes ) = $message =~ / bytes\s*=\s*(\d+)/;								# 2025-04-22 remove the trailing whitespace as same as below
                ( $duration ) = $message =~ / durationM[sS]\s*=\s*(\d+)/;						# 2025-04-17 remove the trailing white space as it was not picking up the variable if it was at the end of the line
                ( $count ) = $message =~ / count\s*=\s*(\d+)/;
                $is_access_log = 1 if defined $bytes || defined $duration || defined $count;

# [elapsed 39ms]
#  [elapsed 20m 47s 399ms] Import completed successfully
# ApplicationLog.2025-04-29.135.log:2025-04-29 09:07:04.340+0000 [L: INFO] [O: c.t.c.ImportProcessor] [I: ] [U: Administrator] [S: ] [P: ] [T: https-jsse-nio-8443-exec-1] ***  [elapsed 20m 47s 399ms] Import completed successfully
#( $duration ) = $message =~ /\[elapsed (\d+)ms\]/;
#$message =~ s/\[elapsed (\d+)ms\]/\[duration ??ms\]/g;
#                $message =~ s/=\d+/=?/g;

                $message =~ s/=\d+/=?/g;

# START the following are temporary
                $message =~ s/(session id: )\d+/$1\?\?/g;

                $message =~ s/(\w+_)+\d{14}-/ModelFamily_CustomerPC_DateString-/g;
                
                $message =~ s/Successfully added for import \/.+$/Successfully added for import \/ThingworxStorage\/repository\/SystemRepository\/\.\.\./g;
                $message =~ s/Setting visibility permissions for (.+)$/Setting visibility permissions for \.\.\./g;
                $message =~ s/Ancestors for Entity(.+)$/Ancestors for Entity \.\.\./g;
                $message =~ s/input document: (.+)$/input document: \.\.\./g;
                $message =~ s/Transaction was successfully ended for request (.+)$/Transaction was successfully ended for request \.\.\./g;
                $message =~ s/Ending transaction for request (.+)$/Ending transaction for request \.\.\./g;
                $message =~ s/(TimerEventHandler|TimerThing)\@(\S+)/$1\@/g;
                $message =~ s/correspond to sent message (\S+) \]/correspond to sent message ###################### \]/g;


                # VILINK.Location.b698a817-
                # VIRTUO_PCOEM_20250221153912-
                # CONNECT_UP_CUSTOMERPC_20250221085610-
                # -12fa9d24-faf9-4df0-95b3-ca0f4341d26f
                # -f9883b39-f19c-4c8f-b21c-141630e3b9a7
# END the following are temporary

#printf( "$message -- durationMS=%s bytes=%s count=%s\n", defined $duration ? $duration : "-", defined $bytes ? $bytes : "-", defined $count ? $count : "-" );

            ## ThingWorx Connection Server Standard Log Format ##
            } elsif ( ($timestamp_str, $thread, $category_bucket, $object, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \[([^\]]*)\] ([^ ]*)  ([^ ]*) - (.*)/) {
                $is_line_match = 1;
                # for some reason needed to move this before other more generic patterns which shouldn't be matching this, or are valid
                $match_type = 10;                       # 2025-08-14 21:00:34.633 [vert.x-eventloop-thread-12] INFO  c.t.c.a.AlwaysOnHttpServerVerticle - Enabled fix for WebSocket compression sometimes causing frames to exceed maximum WebSocket frame size

                ( $duration ) = $message =~ / (\d+) milliseconds/;
                $message =~ s/(from \d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:)\d{4,5} /${1}XXXXX /;	# remove the ephemeral port in order to group common messages
                $is_access_log = 1 if defined $bytes || defined $duration || defined $count;

            ## Generic Java/Logback Pattern with timestamp and level ##
            } elsif ( ($timestamp_str, $category_bucket) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3})\+\d{4} \[L: ([^\]]*)\]/) {
                $is_line_match = 1;
                $match_type = 1;			# this is matching ThingWorx standard log format 2025-02-04 12:05:57.481+0000 [L: DEBUG] 

            ## ThingWorx Remote Access Client Log Format ##
            } elsif ( ($timestamp_str, $category_bucket ) = $_ =~ /^[\[]?(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}\.\d{3}).*? \[[L: ]*([^\]]*)\]/ ) {
                $is_line_match = 1;
                $match_type = 2;			# this is matching RAC client log format [2025-02-04T12:06:22.784] [TRACE]
                $timestamp_str =~ tr/T/ /;

            ## Apache Tomcat Access Log with Service Execution Time (%D), and optionally thread (%I) and session (%S) ##
            #} elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, $duration, $thread, $session) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-) (\d+)[ ]?(\S+)?[ ]?(\S+)?/ ) {
            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, $duration, $thread, $session) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-)[ ]?(\d+)?[ ]?(\S+)?[ ]?(\S+)?/ ) {
                $is_line_match = 1;
                $match_type = 3;			# this is matching Tomcat access log format with service execution time 43.52.82.172 - - [02/Feb/2025:00:00:11 +0000] "GET /Thingworx/Metrics?x-thingworx-session=false HTTP/1.1" 200 17626 295
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset
                undef $bytes if $bytes eq "-";

                $message =~ s/ HTTP\/\d\.\d$//;							# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;				# chop off the query string from the URI
                $message = "[$session] $message" if defined $session && $include_session;	# include session if we found it in the logs

#print "$message -- $_";
            ## Apache Tomcat Standard/Common Access Log Format ##
            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-)$/ ) {    # added $ to end to differentiate from later pattern
                $is_line_match = 1;
                $match_type = 4;			# this is matching Tomcat access log format with service execution time 43.52.82.172 - - [02/Feb/2025:00:00:11 +0000] "GET /Thingworx/Metrics?x-thingworx-session=false HTTP/1.1" 200 17626
                					# this is matching Nginx ingress access log format 3.133.31.181 - - [18/Nov/2024:14:19:55 +0000] "GET / HTTP/1.1" 404 431 "-" "WizDynamicScanner/1.0"
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset
                undef $bytes if $bytes eq "-";

                $message =~ s/ HTTP\/\d\.\d$//;					# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;		# chop off the query string from the URI
# TO DO - update RegEx to pull out message, thread name (2025-04-23 not sure what this implies as match type 3 picks up thread name and session if present)

            ## ThingWorx Connection Server JSON Formatted Logs ##
            } elsif ( ($timestamp_str, $category_bucket) = $_ =~ /^{"\@timestamp":"([^"]*).*"level":"([^"]*)/ ) {
                $is_line_match = 1;
                $match_type = 5;			# this matches Connection Server JSON formatted logs : {"@timestamp":"2025-02-02T21:03:06.725+00:00","@version":1,"message":"Error encountered, closing WebSocket: endpointId=2608459","logger_name":"com.thingworx.connectionserver.alwayson.AbstractClientEndpoint","thread_name":"vert.x-eventloop-thread-16","level":"WARN","level_value":30000,"stack_trace":"io.vertx.core.http.HttpClosedException: Connection was closed\n"}
                $timestamp_str =~ s/\+\d{2}:\d{2}$//;	# chop off the timezone offset
                $timestamp_str =~ tr/T/ /;
# TO DO: Pull out thread name

            ## Java 11 GC Log Format with Timestamps Enabled ##
            } elsif ( ( $timestamp_str, $category_bucket, $message, $heap_from, $heap_to, $heap_size, $duration ) = $_ =~ /^[\[]?(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}\.\d{3})[+-]\d{4}.*?\[info\]\[gc\s*\] GC\(\d+\) (.+?) (\(.+?\)) (\d[^-]+)->(\d[^(]+)\((\d[^)]+)\) (\d.*)ms/ ) {
                $is_line_match = 1;
                $match_type = 6;			# this matches Java GC log info level pause
                $is_access_log = 1;			# need this to have statistics calculated
                $default_chart_block = 'C' unless $default_chart_block ne 'C';

                $bytes = convert_bytes( $heap_from ) - convert_bytes( $heap_to );
                $bytes = $bytes < 0 ? 0 : $bytes;

            ## ThingWorx Analytics Log Formats ##
            } elsif ( ( $category_bucket, $timestamp_str, $message ) = $_ =~ /^([^ ]+)\s+\[(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[.,]\d{3})\] (.*)$/ ) {  
            # adaptor     # ERROR [2025-02-19 18:31:00,284] com.thingworx.sdk.impl.transport.netty.NettyChannelHandler: [ClientHandler: 76b37675] WebSocket error: An existing connection was forcibly closed by the remote host, closing connection!
            # sync        # INFO  [2025-02-20 04:49:11,450] org.ehcache.core.EhcacheManager: Cache 'scorefunc_cachex' created in EhcacheManager.
            # async       # WARN  [2025-02-19 18:30:01,437] org.apache.zookeeper.ClientCnxnSocketNetty: future isn't success.
                $is_line_match = 1;
                $match_type = 7;			# this matches ThingWorx Analytics V2 types for adaptor, sync, async
                $timestamp_str =~ tr/,/./;
                $timestamp_str =~ tr/T/ /;
                $message =~ s/\s+$//g;

            } elsif ( ( $timestamp_str, $thread, $category_bucket, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[^ ]*)\s+\[([^]]+)\]\s+(\w+)\s+(.*)$/ ) {  
            # worker      # 2025-02-20 10:06:10 [nioEventLoopGroup-2-1] WARN  io.netty.channel.ChannelInitializer - Failed to initialize a channel. Closing: [id: 0x8171dc41]
                $is_line_match = 1;
                $match_type = 8;			# this matches ThingWorx Analytics worker type
#                $thread =~ s/(.*)-\d+$/$1/;
                $timestamp_str =~ tr/,/./;
                $timestamp_str =~ tr/T/ /;
                $message =~ s/\s+$//g;

            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, undef, undef, $duration) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+) "([^"]+)" "([^"]+)" (\d+)$/ ) {
            # access logs # 127.0.0.1 - - [13/Mar/2025:09:02:41 +0000] "GET /async/prediction/evaluation?limit=99999 HTTP/1.1" 200 51 "-" "Jersey/2.37 (HttpUrlConnection 11.0.22)" 651
                $is_line_match = 1;
                $match_type = 9;			# this is matching Jboss access log format with service execution time 127.0.0.1 - - [13/Mar/2025:09:02:41 +0000] "GET /async/prediction/evaluation?limit=99999 HTTP/1.1" 200 51 "-" "Jersey/2.37 (HttpUrlConnection 11.0.22)" 651
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset

                $message =~ s/ HTTP\/\d\.\d$//;					# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;		# chop off the query string from the URI
#print "$message -- $_";
            } elsif ( ( $category_bucket, $timestamp_str, $message ) = $_ =~ /^([^ ]+) (\d{4}-\d{2}-\d{2} \d{1,2}:\d{2}:\d{2}[,.]\d+) (.*)/ ) {  
                $is_line_match = 1;
                $match_type = 11;			# this is matching ThingWorx Edge C SDK format # FORCE 2025-08-09 18:27:18,40 8012 twx_connection.cpp:246 Run Error in the TWX processor thread, have to reinitialize. Error was [sdk_wrapper_->IsConnected() failed]
                chop $message;

                # INFO 2025-08-09 18:19:04,479 libremotesession::RemoteConnectionManager::ReloadAllowList : Attempting to load the allowlist.
                # INFO 2025-08-09 18:19:04,479 8012 change_notification_source.cpp:11 OnProvisioningChanged provisioning change update received
                # ERROR 2025-08-09 18:27:18,38 TW_SSL_READ: Error reading from SSL stream
                # WARN 2025-08-09 18:19:04,729 getCurrentPropertyValuesForEachHandler -  startType parameter is missing but optional. Assumed to be useDefaultValue
                # INFO 2025-08-09 18:27:18,128 8012 twx_app_executor.cpp:83 Detach Detach requested

                $message =~ s/\d+ (.*)$/$1/;			# remove process ID if log messages contains it
                if( $message =~ /\w+\.cpp:\d+ / ) {
                    $message =~ s/(\w+\.cpp:\d+) (.*)$/$2/;
                    $object = $1;
                }
                

         #       $object = $file_name if defined $file_name;	# set the object to the extracted file name in case it might be an agent identifier
            }

if( 0 ) {

    print "$match_type $category_bucket $object - $message\n";
    last if $total_lines_included >= 15;

}


            # Populate Thread Pool name if thread name was found
            if( defined $thread && $thread ne "" ) {
                ( $threadpool ) = $thread =~ /(.*)-\d+$/;
                $threadname = defined $threadpool ? $threadpool : $thread;
            }

            ## USER DEFINED METRICS CAPTURE ##
            if( defined $user_defined_metrics && /$user_defined_metrics_regex/ ) {
# bookmark25
                if( /$user_defined_metrics_post_regex/g ) {
                    foreach my $user_metric ( split( ',', $user_defined_metrics ) ) {
                        my $metric = quotemeta( $user_metric );
                        my $regex = qr/(?<$metric>-?\d+(?:\.\d+)?)\s*[=:]?\s*$metric\s+/x;
                    #foreach my $metric ( keys %+ ) {
                        my $value = defined $+{$metric} ? normalize( $+{$metric} ) : "N/A"; 
                        print "$metric=$value ";
                    }
                }

            }

            #print "\033[0;32m[$timestamp_str|$category_bucket] HTTP $status_code [$is_line_match/$match_type] \033[0m$_";
            #$| = 1; # Flush output

            if( $is_line_match ) {
                $bytes = 0 if( defined( $bytes ) && $bytes < 0 );

                $timestamp_str =~ s/(:\d{2}:\d{2})\.\d{3}/$1/;	# remove the milliseconds if present, as the code does not presently support them

                unless (grep { $_ eq $category_bucket } @log_levels) {				# this condition importantly only continues if the read/parsed log category is one of the ones defined
                    next;
                } elsif( $match_type == 1 || $match_type == 2 || $match_type == 5 || $match_type == 6 || $match_type == 7 || $match_type == 8 || $match_type == 10 || $match_type == 11 ) {
                    if (exists $timestamp_cache{$timestamp_str}) {
                        $timestamp = $timestamp_cache{$timestamp_str};
                    } else {
                        $timestamp = DateTime->new(
                            year      => substr($timestamp_str, 0, 4),
                            month     => substr($timestamp_str, 5, 2),
                            day       => substr($timestamp_str, 8, 2),
                            hour      => substr($timestamp_str, 11, 2),
                            minute    => substr($timestamp_str, 14, 2),
                            second    => substr($timestamp_str, 17, 2),
                            time_zone => 'UTC',
                        );
                        $timestamp_cache{$timestamp_str} = $timestamp;
                    }

                    # print "\033[0;35m[%d]\033[0m", $timestamp->epoch();
                    # $| = 1; # Flush output
                } elsif( $match_type == 3 || $match_type == 4 || $match_type == 9 ) {
                    if (exists $timestamp_cache{$timestamp_str}) {
                        $timestamp = $timestamp_cache{$timestamp_str};
                    } else {
                        my ($day, $month_str, $year, $hour, $minute, $second) = $timestamp_str =~ m/(\d{2})\/([A-Za-z]+)\/(\d{4}):(\d{2}):(\d{2}):(\d{2})/;
                        my $month = $month_map{$month_str};
                        $timestamp = DateTime->new(
                            year      => $year,
                            month     => $month,
                            day       => $day,
                            hour      => $hour,
                            minute    => $minute,
                            second    => $second,
                            time_zone => 'UTC',
                        );
                        $timestamp_cache{$timestamp_str} = $timestamp;
                    }
                    # print "\033[0;35m[%d]\033[0m", $timestamp->epoch();
                    # $| = 1; # Flush output
                }

                $filter_range_filter_initialized = calculate_start_end_filter_timestamps( $timestamp ) unless $filter_range_filter_initialized;

                # a number of conditions determine if this read row should be skipped
                next if( $timestamp->epoch() < $filter_range_epoch{'start'} || $timestamp->epoch() >= $filter_range_epoch{'end'} );
                next if( defined( $exclude_regex ) && /$exclude_regex/ );
                next if( defined( $include_regex ) && !/$include_regex/ );
                next if( defined( $filter_duration_min ) && ( !defined( $duration ) || $duration <= $filter_duration_min ));		# skip if duration value is below specified minimum filter
                next if( defined( $filter_duration_max ) && ( !defined( $duration ) || $duration >= $filter_duration_max ));		# skip if duration value is above specified maximum filter
                next if( defined( $filter_bytes_min ) && ( !defined( $bytes ) || $bytes < $filter_bytes_min ));				# skip if bytes value is below specified minimum filter
                next if( defined( $filter_bytes_max ) && ( !defined( $bytes ) || $bytes > $filter_bytes_max ));				# skip if bytes value is above specified maximum filter

                # take note if any results were found in this file
                $in_files_matched{$in_file} = 1 unless $in_files_matched{$in_file};

                # determine if this line should be highlighted (matches in result search)
                if( defined( $highlight_regex ) && /$highlight_regex/ ) {
                    $category_bucket .= '-HL';
                    $category = 'highlight';
                    $in_files_matched{$in_file} = 2 unless $in_files_matched{$in_file} == 2;
                } else {
                    $category = 'plain';
                }
                
                # sets earliest and latest timestamp values being displayed (after the range filtering selection)
                $output_timestamp_min = $timestamp->epoch() if $output_timestamp_min == 0 || $output_timestamp_min > $timestamp->epoch();
                $output_timestamp_max = $timestamp->epoch() if $output_timestamp_max == 0 || $output_timestamp_max < $timestamp->epoch();

                my $bucket = int($timestamp->epoch() / $bucket_size_seconds) * $bucket_size_seconds;

                $log_counts{$bucket}{$category_bucket}{count}++;
                $total_lines_included++;

                if( defined( $message ) ) {
                    my $log_key = "";
                    my $max_object_length = 25;
                    my $log_level = $status_code > 0 ? $status_code : $category_bucket;			# If we received an actual HTTP status code, use that for the message statistic data model
                    $log_level =~ s/-HL$//;

                    # Substitute UUID with HASH if command line option to do so is present (temporary feature to be eclipsed by group similar feature)
                    $message =~ s/\S{8}-\S{4}-\S{4}-\S{4}-\S{12}+/########-####-####-####-############/g if defined $mask_uuid && $mask_uuid;

                    if( defined( $threadname ) && defined( $object ) ) {				# ThingWorx log line parsed and usable for additional analysis
                        my $truncated_thread = substr( $threadname, 0, 20 );
                        my $truncated_object = substr( $object, length($object) > $max_object_length ? length($object)-$max_object_length : 0, $max_object_length );
                        # truncate the log message key to either the screen width or hardcoded value if writing to output to CSV file
                        $log_key = substr("[$log_level] [$truncated_thread] [$truncated_object] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } elsif( defined( $object ) ) {
                        my $truncated_object = substr( $object, length($object) > $max_object_length ? length($object)-$max_object_length : 0, $max_object_length );
                        $log_key = substr("[$log_level] [$truncated_object] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } elsif( defined( $threadname ) ) {
                        my $truncated_thread = substr( $threadname, 0, 20 );
                        $log_key = substr("[$log_level] [$truncated_thread] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } else {
                        $log_key = substr("[$log_level] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    }

                    $log_messages{$category}{$log_key}{count}++;

                    ## CAPTURE MESSAGE BASED STATISTICS DATA AND PREPARE FOR SORTING ##
                    if( $is_access_log ) {
                    #if( defined $duration ) {

                        # Initialize the hash if not already done
                        $log_messages{$category}{$log_key} //= {
                            count => 0,
                            total_bytes => 0,
                            total_duration => 0,
                            sum_of_squares => 0,
                            durations => [],
                        };

                        # Accumulate the total duration and bytes
                        $log_messages{$category}{$log_key}{total_bytes} += $bytes if defined $bytes;

                        if( defined $duration && !$omit_durations ) {
print " duration: $duration -- $_ \n" if !$duration || $duration < 1;
                            $log_messages{$category}{$log_key}{total_duration} += $duration;
                            $log_messages{$category}{$log_key}{total_duration_num} += $duration;

                            # Accumulate the sum of squares for variance calculation
                            $log_messages{$category}{$log_key}{sum_of_squares} += $duration ** 2;
                            push @{$log_messages{$category}{$log_key}{durations}}, $duration;

                            # by calculating impact as the numbers build, it will be ready to use for sorting without having to go through the whole dataset
                            if( $duration > 0 ) {
                                my $mean = $log_messages{$category}{$log_key}{total_duration} / $log_messages{$category}{$log_key}{count}; 
#print "Count: $log_messages{$category}{$log_key}{count} Duration: $log_messages{$category}{$log_key}{total_duration} Mean : $mean\n";
                                $log_messages{$category}{$log_key}{impact} = round( log( $mean ** $impact_time_exponent * $log_messages{$category}{$log_key}{count} ) * 100 ) / 100;
                            }
                        }
                    }
                }

                ## CAPTURE TIME-WINDOWS BASED STATISTICS DATA ##
                #if( $is_access_log && !$omit_stats ) {			# removing this as I need the stats for other things than printing the duration stats table (like the total time and bytes trends)
                if( $is_access_log  ) {
                    $print_durations = 1 if $print_durations != 1;

                    ## STATISTICAL DATA CAPTURE ##
                    #print "$duration -- $_";
                    $duration = 0 if !defined( $duration );
                    $bytes = 0 if !defined( $bytes );
    
                    # Initialize the hash if not already done
                    $log_analysis{$bucket} //= {
                        count => 0,
                        total_bytes => 0,
                        total_duration => 0,
                        sum_of_squares => 0,
                        durations => [],
                    };

                    # Update the hash with the new data
                    $log_analysis{$bucket}{count}++;

                    if( defined $duration && !$omit_durations && $duration >= 0 ) {
                        $log_analysis{$bucket}{total_duration} += $duration;

                        $log_analysis{$bucket}{'total_duration-HL'} += $duration if $category_bucket =~ /-HL$/;
                        $log_analysis{$bucket}{sum_of_squares} += $duration ** 2;
                        push @{$log_analysis{$bucket}{durations}}, $duration;
                    }

                    if( defined $bytes && $bytes ) {
                        $log_analysis{$bucket}{total_bytes} += $bytes;
                        $log_analysis{$bucket}{'total_bytes-HL'} += $bytes if $category_bucket =~ /-HL$/;
                    }

                  #  printf "\033[0;35m[duration: %d] [bytes: %d]\033[0m\n", $duration, $bytes;
                  #  printf "\033[0;35m[status: %s] [duration: %d] [bytes: %d]\033[0m\n", $category_bucket, $log_counts{$bucket}{duration}, $log_counts{$bucket}{bytes};
                  #  $| = 1; # Flush output
                }

                ## CAPTURE THREAD AND THREAD POOL BASED STATISTICS DATA ##
                if( ( defined $threadpool && $threadpool ne "" ) && ( ( defined $threadpool_activity_regex && $threadpool =~ /$threadpool_activity_regex/ ) || ( !defined $threadpool_activity_regex && $include_threadpool_summary ) ) ) {
#                    $threadpool =~ s/[*\-!\#=\$\?]//g;
#                    $thread =~ s/[*\-!\#=\$\?]//g;

                    # Thread Pool Based Statistics Capture (Overall Summary) #
                    $threadpool_activity{$category}{$threadpool}{$thread} = 0 if !defined $threadpool_activity{$category}{$threadpool}{$thread};
                    $threadpool_activity{$category}{$threadpool}{$thread} += 1;

                    # Time Window Based Statistics Capture (Time Window Graphs) #
                    $log_threadpools{$bucket}{$threadpool}{plain}{$thread} += 1;

                    if( $category_bucket =~ /-HL$/ ) {                  # capture total duration and bytes for highlighted rows
                        $log_threadpools{$bucket}{$threadpool}{highlight}{$thread} += 1;
                    }

#print "Thread Pool: $threadpool  Thread: $thread   $log_threadpools{$bucket}{$threadpool}{plain}{$thread}     Object: $object   Message: $message\n";
#exit if $total_lines_included > 50;
                }
            }
        }
# I don't think that this should be here
#        close $fh;

        print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    }
    print "\r$colors{'bright-green'}Processing completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Processing completed." ) );
    print "\n";

    return;
}

sub calculate_all_statistics {

    print "\rCalculating statistics...";

    foreach my $bucket (sort { $a <=> $b } keys %log_analysis) {
        my $aggregated_data = {
            count               => 0,
            total_duration      => 0,
            'total_duration-HL' => 0,
            total_bytes         => 0,
            'total_bytes-HL'    => 0,
            sum_of_squares      => 0,
            durations           => [],
        };

# TO DO: shouldn't check memory on each pass; use approach like reading lines
        if( $track_memory ) {
            $current_memory_usage = get_memory_usage();								# track maximum memory usage
            if ($current_memory_usage > $max_memory_usage) {
                $max_memory_usage = $current_memory_usage;
            }
        }
   
        my $bucket_data = $log_analysis{$bucket};

        next if !defined( $log_analysis{$bucket}{count} );

# TO DO: I think that I can get rid of aggregate_data now that I've simplified the data model
        $aggregated_data->{count} += $bucket_data->{count};
        $aggregated_data->{total_duration} += $bucket_data->{total_duration};
        $aggregated_data->{total_bytes} += $bucket_data->{total_bytes};
        $aggregated_data->{sum_of_squares} += $bucket_data->{sum_of_squares};
        push @{$aggregated_data->{durations}}, @{$bucket_data->{durations}};

        # free up the memory from the data structure as it is no longer needed
        undef $log_analysis{$bucket}{durations};
        delete $log_analysis{$bucket}{durations};
    

        if( $print_durations && !$omit_durations ) {
            my ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv) = calculate_statistics($aggregated_data);

            $log_stats{$bucket} = {
                count         => $aggregated_data->{count},
                bytes         => $bucket_data->{total_bytes},
                'bytes-HL'    => $bucket_data->{'total_bytes-HL'},
                duration      => $bucket_data->{total_duration},
                'duration-HL' => $bucket_data->{'total_duration-HL'},
                min           => $min,
                mean          => $mean,
                max           => $max,
                p1            => $p1,
                p50           => $p50,
                p75           => $p75,
                p90           => $p90,
                p95           => $p95,
                p99           => $p99,
                p999          => $p999,
                std_dev       => $std_dev,
                cv            => $cv,
                z_score       => undef 
            };
    
            # Calculate rolling mean and std_dev
            my $rolling_mean = 0;
            my $rolling_sum_of_squares = 0;
            my $rolling_count = 0;
            foreach my $prev_bucket (@rolling_window) {
                $rolling_mean += $prev_bucket->{mean};
                $rolling_sum_of_squares += $prev_bucket->{sum_of_squares};
                $rolling_count++;
            }
            if ($rolling_count > 0) {
                $rolling_mean /= $rolling_count;
                my $rolling_variance = ($rolling_sum_of_squares / $rolling_count) - ($rolling_mean ** 2);
                my $rolling_std_dev = sqrt($rolling_variance);
                my $z_score = calculate_z_score($mean, $rolling_mean, $rolling_std_dev);

        #        print "Time Bucket: $bucket\n";
        #        print "Count: $aggregated_data->{count}, Bytes: $aggregated_data->{total_bytes}, Min: $min, Mean: $mean, Max: $max, P1: $p1, P50: $p50, P70: $p75, P90: $p90, P95: $p95, P99: $p99, P99.9: $p999, Std Dev: $std_dev, Coefficient of Variance: $cv, Z-score: $z_score\n";
                $log_stats{$bucket}{z_score} = $z_score;
            } else {

        #        print "Time Bucket: $bucket\n";
        #        print "Count: $aggregated_data->{count}, Bytes: $aggregated_data->{total_bytes}, Min: $min, Mean: $mean, Max: $max, P1: $p1, P50: $p50, P75: $p75, P90: $p90, P95: $p95, P99: $p99, P99.9: $p999, Std Dev: $std_dev, Coefficient of Variance: $cv, Z-score: N/A\n";
            }

            # Update rolling window logic
            push @rolling_window, { mean => $mean, sum_of_squares => $aggregated_data->{sum_of_squares} };
            shift @rolling_window if @rolling_window > $rolling_window_size;

        } else {

            $log_stats{$bucket} = {
                count         => $aggregated_data->{count},
                bytes         => $bucket_data->{total_bytes},
                'bytes-HL'    => $bucket_data->{'total_bytes-HL'},
            }

        }
    }

    ## STATS FOR TOP LOG MESSAGES ##
    if( $print_durations ) {
        foreach my $category (keys %log_messages) {
            # Collect and sort the log keys based on the count within each log_key
            my @sorted_log_keys;

            @sorted_log_keys = sort {
               my $count_a = $log_messages{$category}{$a}{$sort_key} // 0;
               my $count_b = $log_messages{$category}{$b}{$sort_key} // 0;
               $count_b <=> $count_a;
            } keys %{$log_messages{$category}};

            # Process only the top N log keys
            my @top_keys = @sorted_log_keys[0 .. min($#sorted_log_keys, $top_n_messages - 1)]; 

            foreach my $log_key (@top_keys) {
                my $aggregated_data = {
                    count => 0,
                    total_duration_num => undef,
                    total_duration => undef,
                    total_bytes => undef,
                    sum_of_squares => 0,
                    durations => [],
                };

# TO DO: Shouldn't check memory usage on each pass, only every few
                if( $track_memory ) {
                    $current_memory_usage = get_memory_usage();								# track maximum memory usage
                    if ($current_memory_usage > $max_memory_usage) {
                        $max_memory_usage = $current_memory_usage;
                    }
                } 

                my $message_data = $log_messages{$category}{$log_key};

                next if !defined( $message_data->{count} );
    
                $aggregated_data->{count} += $message_data->{count};
                $aggregated_data->{total_bytes} += $message_data->{total_bytes} if defined $message_data->{total_bytes};

                if( defined $message_data->{total_duration} && !$omit_durations ) {
                    $aggregated_data->{total_duration} += $message_data->{total_duration};
                    $aggregated_data->{sum_of_squares} += $message_data->{sum_of_squares};
                    push @{$aggregated_data->{durations}}, @{$message_data->{durations}};
                }

#foreach my $key ( keys %{$aggregated_data} ) {
#    print "$log_key $key ";
#    print defined $aggregated_data->{$key} ? $aggregated_data->{$key} : "undefined";
#    print "\n"; 
#}

                if( defined $aggregated_data->{total_duration} && !$omit_durations ) { 

                    my ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv) = calculate_statistics($aggregated_data);
                    my $impact = $log_messages{$category}{$log_key}{impact};
                    #print "--- $log_key ---\n     Count: $aggregated_data->{count}, Min: $min, Mean: $mean, Max: $max, P1: $p1, P50: $p50, P75: $p75, P90: $p90, P95: $p95, P99: $p99, P99.9: $p999, Std Dev: $std_dev, Coefficient of Variance: $cv, Z-score: N/A, Total duration: $aggregated_data->{total_duration}\n";
    
                    $log_messages{$category}{$log_key}{min} = $min;
                    $log_messages{$category}{$log_key}{mean} = $mean;
                    $log_messages{$category}{$log_key}{max} = $max;
                    $log_messages{$category}{$log_key}{std_dev} = $std_dev;
                    $log_messages{$category}{$log_key}{p1} = $p1;
                    $log_messages{$category}{$log_key}{p50} = $p50;
                    $log_messages{$category}{$log_key}{p75} = $p75;
                    $log_messages{$category}{$log_key}{p90} = $p90;
                    $log_messages{$category}{$log_key}{p95} = $p95;
                    $log_messages{$category}{$log_key}{p99} = $p99;
                    $log_messages{$category}{$log_key}{p999} = $p999;
                    $log_messages{$category}{$log_key}{cv} = $cv;
                    $log_messages{$category}{$log_key}{total_duration_num} = $aggregated_data->{total_duration} if defined $aggregated_data->{total_duration};
                    $log_messages{$category}{$log_key}{total_duration} = format_time( $aggregated_data->{total_duration}, 'ms', 'medium', 'space' ) if defined $aggregated_data->{total_duration};
                }

                $log_messages{$category}{$log_key}{total_bytes} = $aggregated_data->{total_bytes} if defined $aggregated_data->{total_bytes};

                # free up the memory from the data structure as it is no longer needed
                undef $log_messages{$category}{$log_key}{durations};
                delete $log_messages{$category}{$log_key}{durations};
            }
        }
    }


    ## STATS FOR THREAD POOL ACTIVITY ##
    my %threadpools;
    my ( @ordered_threadpools );
    my $threadpools_included = 0;

    foreach my $category ( qw( highlight plain ) ) {
        foreach my $threadpool ( keys %{$threadpool_activity{$category}} ) {
            $threadpools{$threadpool}{threads} += scalar keys %{$threadpool_activity{$category}{$threadpool}};
            foreach my $thread ( keys %{$threadpool_activity{$category}{$threadpool}} ) {
                $threadpools{$threadpool}{count} += $threadpool_activity{$category}{$threadpool}{$thread};
            }
        }
    }

#$, = "\n";

    @ordered_threadpools = sort { $threadpools{$b}{count} <=> $threadpools{$a}{count} } keys %threadpools;

#print "\nThread Pools\n";
#print @ordered_threadpools;
#print "\n----\nThread Pools to Graph\n";

# TO DO - If I built up the max_totals while going through the files, by the time we calculate the statistics I could removed empty graph fields like duration and bytes,
#         then we'd be OK to add more custom columns in order to still fit within the 6 column limit.
    foreach my $threadpool ( @ordered_threadpools ) {
        last if $threadpools_included++ > 3;
        push( @graph_threadpools_activity, $threadpool ) if( $include_threadpool_summary || $threadpool =~ /${threadpool_activity_regex}/i );
    }

    push @graph_columns, @graph_threadpools_activity;			# add matched thread pools to the list of data points to be graphed

# bookmark20
#print @graph_threadpools_activity;
#print "\n";
#$, = "";

#    foreach my $bucket ( keys %log_threadpools ) {
#        # Capture Relevant Thread Pool Stats for Graphing
#print "\n $bucket-- ";
#        foreach my $threadpool ( @graph_threadpools_activity ) {
#print "$threadpool ";
#            my $threadpool_highlight = "$threadpool-HL";
#
#            $log_stats{$bucket}{$threadpool} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{plain}};
#            $log_stats{$bucket}{$threadpool_highlight} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{highlight}};
#print ".. ";
#print "$log_stats{$bucket}{$threadpool_highlight}:$log_stats{$bucket}{$threadpool} ";
#                $| = 1; # Flush output
#        }
#    }

    # Capture Relevant Thread Pool Stats for Graphing
    foreach my $bucket (keys %log_threadpools) {
        foreach my $threadpool (@graph_threadpools_activity) {
            my $threadpool_highlight = "$threadpool-HL";
        
            # Ensure the keys exist before accessing them
            if (exists $log_threadpools{$bucket}{$threadpool}{plain} ) {
                $log_stats{$bucket}{$threadpool} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{plain}};
                $log_stats{$bucket}{$threadpool_highlight} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{highlight}};
#                print ".. ";
#                print "$log_stats{$bucket}{$threadpool_highlight}:$log_stats{$bucket}{$threadpool}\n";
            } else {
                 $log_stats{$bucket}{$threadpool} = 0;
#                print "Error: Missing data for $threadpool in $bucket\n";
            }
#            $| = 1; # Flush output
             # Free up no longer needed memory
             undef $log_threadpools{$bucket}{$threadpool};
             delete $log_threadpools{$bucket}{$threadpool};
        }
    }

    print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    print "\r$colors{'bright-green'}Calculating statistics completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Calculating statistics completed." ) );
    print "\n";

    return;
}

# Function to calculate the log scale bucket
sub log_bucket {
    my ($value, $base) = @_;
    $value = 0 if !defined( $value );
    return $value > 0 ? floor(log($value) / log($base)) : 0;
}

# Function to calculate Z-score
sub calculate_z_score {
    my ($current_mean, $rolling_mean, $rolling_std_dev) = @_;
    return undef if $rolling_std_dev == 0;
    return sprintf("%.2f", ($current_mean - $rolling_mean) / $rolling_std_dev);
}

# Function to calculate statistical metrics
sub calculate_statistics {
    my ($bucket_data) = @_;
    my $count = $bucket_data->{count};
    return unless $count > 0;

    my $min = min( @{$bucket_data->{durations}} );
    my $mean = int($bucket_data->{total_duration} / $count);
    my $max = max( @{$bucket_data->{durations}} );
    my $variance = ($bucket_data->{sum_of_squares} / $count) - ($mean ** 2);
    my $std_dev = round( sqrt($variance) * 1000 ) / 1000;
    my $cv = $mean != 0 ? sprintf("%.2f", $std_dev / $mean ) : undef;
    my @sorted = sort { $a <=> $b } @{$bucket_data->{durations}};

#looking for a bug in @durations for messages getting empty value (seen where log line is likely corrupt)
#print "min: $min, mean: $mean, max: $max ";
#print "count: $count p1 = " . int($count *0.01) . " - ". $sorted[int($count *0.01)] . "\n";

    my $p1   = int($sorted[int($count * 0.01)]);
    my $p50  = int($sorted[int($count * 0.5)]);
    my $p75  = int($sorted[int($count * 0.75)]);
    my $p90  = int($sorted[int($count * 0.9)]);
    my $p95  = int($sorted[int($count * 0.95)]);
    my $p99  = int($sorted[int($count * 0.99)]);
    my $p999 = int($sorted[int($count * 0.999)]);
    
    return ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv);
}

sub initialize_empty_time_windows {

    # Go through all of the buckets between the earliest and latest times and ensure that they have empty data to print time buckets with no data
    unless( $omit_empty ) {
        my $start_bucket = int($output_timestamp_min / $bucket_size_seconds) * $bucket_size_seconds;

        print "\rInitializing empty time windows...";

        for (my $bucket = $start_bucket; $bucket <= $output_timestamp_max; $bucket += $bucket_size_seconds) {
            $log_counts{$bucket}{'empty'}{'count'} = 0;
        }

        print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
        print "\r$colors{'bright-green'}Initializing empty time windows completed.$colors{'NC'}";
        print " " x ( $terminal_width - length( "Initializing empty time windows completed." ) );
        print "\n";
    }

    return;
}

sub normalize_data_for_output {
    # Determine the maximum total log messages for any time window
    my %max_total = (
        count => 0,
        bytes => 0,
        duration => 0,
    );
    my %output_columns;
    my $count_column_number = 2;

# TO DO : user defined value will need to have a max total determined for scaling and printing

    print "\rScaling and normalizing data...";

# bookmark23
    push @output_columns, "timestamp";

    foreach my $bucket (keys %log_counts) {
        my $total_count = 0;
        my $total_bytes = $log_stats{$bucket}{bytes};
        my $error_count = 0;

        foreach my $category_bucket (keys %{$log_counts{$bucket}}) {
            my $count = $log_counts{$bucket}{$category_bucket}{count};
            next unless $count > 0 && $category_bucket !~ /^empty|err-rate|msg-rate$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
            $total_count += $count;
            $error_count += $count if $category_bucket =~ /^ERROR|5xx|4xx$/i;
        }

        # this part takes the time windows error and message counts and converts them to a per minute rate
        unless( defined( $omit_rate ) && $omit_rate ) {
            $log_counts{$bucket}{'err-rate'}{count} = $error_count / $bucket_size_seconds * 60;
            $log_counts{$bucket}{'msg-rate'}{count} = $total_count / $bucket_size_seconds * 60;
        }

        # Calculate the maximum value of the selected trend type if it is activated
        $max_total{count} = $total_count if $total_count > $max_total{count};
        $max_total{bytes} = $total_bytes if ( defined $total_bytes && !$omit_bytes && $total_bytes > $max_total{bytes} );
        $max_total{duration} = $log_stats{$bucket}{duration} if ( defined $log_stats{$bucket}{duration} && $log_stats{$bucket}{duration} > $max_total{duration} );
    }

# bookmark21
    if( scalar @graph_threadpools_activity > 0 ) {
        foreach my $bucket ( keys %log_threadpools ) {
           foreach my $threadpool ( @graph_threadpools_activity ) {
               $max_total{$threadpool} = 0 if !defined $max_total{$threadpool};
               $max_total{$threadpool} = $log_stats{$bucket}{$threadpool} if ( defined $log_stats{$bucket}{$threadpool} && $log_stats{$bucket}{$threadpool} > $max_total{$threadpool} );
#print "$threadpool " . ( defined $log_stats{$bucket}{$threadpool} ? $log_stats{$bucket}{$threadpool} : "N/A" ) . " - Set max-total for $threadpool to $max_total{$threadpool}\n";
           }
        }
    }

#print "Max totals --- count: $max_total{count}  bytes: $max_total{bytes}  duration: $max_total{duration}\n";

    # Calculate the maximum length of log level titles and counts
    foreach my $bucket (keys %log_counts) {
        my $bucket_legend_length = 0;

        foreach my $category_bucket (keys %{$log_counts{$bucket}}) {
            my $count = $log_counts{$bucket}{$category_bucket}{count};
            my $title_length = 0;
            #next unless ( $count > 0 || $category_bucket =~ /^(err|msg)-rate$/ ) && $category_bucket !~ /^empty$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
            next unless ( $count > 0 || $category_bucket =~ /^(err|msg)-rate$/ ) && $category_bucket !~ /^empty$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
            next if $omit_values && $category_bucket !~ /^(err-rate|msg-rate)$/;
            next if $omit_rate && $category_bucket =~ /^(err-rate|msg-rate)$/;
            next if $category_bucket =~ /^(err|msg)-rate$/ && $log_counts{$bucket}{'err-rate'}{count} == 0 && $log_counts{$bucket}{'msg-rate'}{count} == 0;

## WARNING: Legend length calculations may exists here
            if( $category_bucket =~ /-HL$/ ) {
                $title_length = length("$count ");
            } elsif( $category_bucket =~ /^err-rate$/ ) {
                $title_length = length(format_number( $count ) . ":");
                $title_length += length(" ") if !$omit_values;		# need to add the spacing between values and rate if it will exist
            } elsif( $category_bucket =~ /^msg-rate$/ ) {
                $title_length = length( format_number( $count ) . "/m ");
            } else {
                $title_length = length("$category_bucket: $count ");
#print "$category_bucket: $count = $title_length\n";
            }
            $bucket_legend_length += $title_length;
            $output_columns{$category_bucket} = 1 if !exists $output_columns{$category_bucket};
        }

        $legend_length = $bucket_legend_length if $bucket_legend_length > $legend_length;
    }

    foreach my $category_bucket ( @log_levels ) {
        if( exists $output_columns{$category_bucket} ) {
            #push @output_columns, "totalCount" if $category_bucket =~ /^err-rate$/;
            push @output_columns, $category_bucket;
        }
    }
    push @output_columns, "totalCount"; # if $category_bucket =~ /^err-rate$/;

    #print "Overall Legend length: $legend_length\n";

# bookmark8
# WARNING: statically speaking the durations stats are 52 characters long with the leading double space - meaning the size calculation doesn't account properly for the line and column seperator
    $durations_graph_width = $print_durations && !$omit_durations && !$omit_bytes && !$omit_stats ? 50 + 2: 0;

    # Normalize counts to fit terminal width - static values based on timestamp length, some white space, maybe a vertical line spacer

    $timestamp_length = length( strftime($output_timestamp_format, gmtime(0) ) ) + 1 + ( $print_milliseconds ? 4 : 0 ) ;     # +1 for built in space after timestamp

    $max_graph_width = $terminal_width - $legend_length - $timestamp_length - $durations_graph_width;
#print "max_graph_width: $max_graph_width terminal_width: $terminal_width legend_length: $legend_length timestamp length: " . length( $output_timestamp_format ) . " durations_graph_width: $durations_graph_width\n";
print "max_graph_width: $max_graph_width terminal_width: $terminal_width legend_length: $legend_length timestamp length: " . $timestamp_length . " durations_graph_width: $durations_graph_width\n";

# Don't think that I need this anymore as I moved the calculation of timestamp length before max_graph_width
#    $max_graph_width -= 4 if $print_milliseconds;								# remove 4 characters from the X size of graph to leave room for millisecond output
## WARNING timestamp length is displaying wrong = 14 versus actual 17 characters
print "$output_timestamp_format - ", strftime($output_timestamp_format, gmtime(0) ), "\n";
    #$timestamp_length = length( $output_timestamp_format ) + ( $print_milliseconds ? 4 : 0 ) ;
print "max_graph_width: $max_graph_width terminal_width: $terminal_width legend_length: $legend_length timestamp length: " . $timestamp_length . " durations_graph_width: $durations_graph_width\n";
    push @printed_column_widths, $timestamp_length;
    push @printed_column_names, "timestamp"; 
    push @printed_column_spacing, ( $graph_column_padding_all );

#herenow
    if( !$omit_values || !$omit_rate ) {
        push @printed_column_widths, $legend_length;
        push @printed_column_spacing, ( $graph_column_padding_all + $graph_column_padding_legend );
        push @printed_column_names, "legend"; 
    } else {
	$count_column_number = 1;
    }

    push @printed_column_names, "occurrences"; 									# this count column is required, not sure how to make the logic more coherent
    #push @printed_column_spacing, ( $graph_column_padding_all + $graph_column_padding_count );

    %graph_width = ( 1 => $max_graph_width );

    # Split the graph spacing into parts if more than one graph is to be drawn
# TO DO : Determine which columns should be printed, and from this determine the column layout

    foreach my $graph_type ( @graph_columns ) {									# Count how many of the to be displayed data columns actually have values to be printed
        $graph_count += ( $max_total{$graph_type} > 0 );
    }

    #if( $graph_count > 1 && ( $max_total{duration} > 0 || $max_total{bytes} > 0 || scalar @graph_threadpools_activity ) ) {
# 2025-12-07 - I don't think that I need this condition, as it should operate the same way with few or many columns
#    if( $graph_count > 1 ) {

        my %graph_relative_size;

        # Determine and store which of the possible columns to print have data
        foreach my $key ( @graph_columns ) {
            if( defined $max_total{$key} && $max_total{$key} != 0 ) {
                push @populated_graph_columns, $key;
                push @printed_column_names, $key;
                push @output_columns, "${key}Nice" if $key =~ /^(duration|bytes)$/;
                push @output_columns, $key;
            }
        }

        #push @output_columns, @populated_graph_columns;								# Add additionally trended data columns to the file output column list

# bookmark6
        if( $graph_count == 2 ) {
            my $offset = 1;		# add timestamp column
	    $offset++ if( !$omit_rate && !$omit_values );

            
            %graph_relative_size = (
                1 => 65,
                2 => 35,
            );
            %graph_width = (
                1 => round( $graph_relative_size{1} / 100 * $max_graph_width ),
                2 => round( $graph_relative_size{2} / 100 * $max_graph_width ),
            );
         } elsif( $graph_count == 3 ) {
            %graph_relative_size = (
                1 => 62,
                2 => 21,
                3 => 17,
            );
            %graph_width = (
                1 => round( $graph_relative_size{1} / 100 * $max_graph_width ),
                2 => round( $graph_relative_size{2} / 100 * $max_graph_width ),
                3 => round( $graph_relative_size{3} / 100 * $max_graph_width ),
            );
         } elsif( $graph_count == 4 ) {
            %graph_relative_size = (
                1 => 50,
                2 => 18,
                3 => 16,
                4 => 16,
            );
            %graph_width = (
                1 => round( $graph_relative_size{1} / 100 * $max_graph_width ),
                2 => round( $graph_relative_size{2} / 100 * $max_graph_width ),
                3 => round( $graph_relative_size{3} / 100 * $max_graph_width ),
                4 => round( $graph_relative_size{4} / 100 * $max_graph_width ),
            );
         } elsif( $graph_count == 5 ) {
            %graph_relative_size = (
                1 => 40,
                2 => 15,
                3 => 15,
                4 => 15,
                5 => 15,
            );
            %graph_width = (
                1 => round( $graph_relative_size{1} / 100 * $max_graph_width ),
                2 => round( $graph_relative_size{2} / 100 * $max_graph_width ),
                3 => round( $graph_relative_size{3} / 100 * $max_graph_width ),
                4 => round( $graph_relative_size{4} / 100 * $max_graph_width ),
                5 => round( $graph_relative_size{5} / 100 * $max_graph_width ),
            );
         } elsif( $graph_count == 6 ) {
            %graph_relative_size = (
                1 => 30,
                2 => 14,
                3 => 14,
                4 => 14,
                5 => 14,
                6 => 14,
            );
            %graph_width = (
                1 => round( $graph_relative_size{1} / 100 * $max_graph_width ),
                2 => round( $graph_relative_size{2} / 100 * $max_graph_width ),
                3 => round( $graph_relative_size{3} / 100 * $max_graph_width ),
                4 => round( $graph_relative_size{4} / 100 * $max_graph_width ),
                5 => round( $graph_relative_size{5} / 100 * $max_graph_width ),
                6 => round( $graph_relative_size{6} / 100 * $max_graph_width ),
            );
         }


         foreach my $column ( 1 .. $graph_count ) {							# capture and build up list containing width and spacing between columns
             my $column_spacing = $graph_column_padding_all;
             $column_spacing += $graph_column_padding_count if $column == 1;
             $column_spacing += $graph_column_padding_other if $column > 1;
             push @printed_column_widths, $graph_width{$column} - $column_spacing;
             push @printed_column_spacing, $column_spacing;
         }

#     }

     if( $print_durations && !$omit_durations && !$omit_stats ) {
         my $column_spacing = ( $graph_column_padding_all + $graph_column_padding_latency );
         push @output_columns, qw( min mean max std_dev p1 p50 p75 p90 p95 p99 p999 cv z_score );
         push @printed_column_widths, $durations_graph_width - $column_spacing;
         push @printed_column_spacing, $column_spacing;
         push @printed_column_names, "latency statistics";
     }

print "printed columns: $#printed_column_names graph_count: $graph_count\n";
    foreach my $column ( 0 .. $#printed_column_names ) {
        my $title = $printed_column_names[$column];
        # my $max_length = $printed_column_widths[$column] - $printed_column_spacing[$column];
        my $max_length = $printed_column_widths[$column];
# 2025-12-07 - next problem to solve, perhaps only diagnostic, but perhaps not - column number relative to which one we are processing doesn't line up with the sizing hash
        my $column_offset = 0;
        $column_offset = 0 if( !$omit_rate && !$omit_values );

print "$column - $title ! width:$graph_width{$column-$column_offset} maxlen:$max_length (colwidth:$printed_column_widths[$column] - colspacing:$printed_column_spacing[$column])\n";
        $printed_column_names[$column] = substr( $title, 0, $max_length ) if length( $title ) > $max_length;
    }

$, = ", ";
print "\nPopulated graph columns:", @populated_graph_columns;
print "\nOutput column length:   ", @printed_column_widths;
print "\nOutput column spacing:  ", @printed_column_spacing;
print "\nOutput column names:    ", @printed_column_names;
print "\n";
$, = "";

print "Graph column count $graph_count -- Graph column widths: $graph_width{1} $graph_width{2} $graph_width{3}\n";
# bookmark2    
    foreach my $bucket (keys %log_counts) {
        my $processed_time_buckets //= 0;
	my $check_memory_every = $^O ne 'MSWin32' ? 50 : 500;
		
# TO DO : need to handle cases where we don't have bytes, but would have duration
        # scale the transferred bytes for printing the statistics table
        my $bytes = $log_stats{$bucket}{bytes};
        my $scaled_bytes = ( defined $bytes && defined $max_total{bytes} && $max_total{bytes} != 0 ) ? int(($bytes / $max_total{bytes}) * $durations_graph_width) : 0;
        $log_stats{$bucket}{scaled_bytes} = $scaled_bytes;

# bookmark3 : scale the total values to the printable size
        if( $graph_count > 1 ) {
            my $column_number = 2; 

            foreach my $key ( @populated_graph_columns ) {			# go through the list of possible columns and populate the scaled value for that metric for the current time bucket
                next if $key =~ /^count$/;					# the counts have already been printed, so should skip this entry even if it is legitimate
                my $key_highlight = "$key-HL";
                my $scaled_key = "scaled_${key}";
                my $scaled_key_highlight = "${scaled_key}-HL";
                # need to subtract a few for additional space for the scaled amount to allow for room for separators - also these are wrongly scaled to the column width, not the @printed_column_widths

                $log_stats{$bucket}{$scaled_key} = ( defined $log_stats{$bucket}{$key} && defined $max_total{$key} && $max_total{$key} != 0 ) ? int(( $log_stats{$bucket}{$key} / $max_total{$key} ) * $printed_column_widths[$column_number] ) : 0;
                $log_stats{$bucket}{$scaled_key_highlight} = ( defined $log_stats{$bucket}{$key_highlight} && defined $max_total{$key} && $max_total{$key} != 0 ) ? int(( $log_stats{$bucket}{$key_highlight} / $max_total{$key} ) * $printed_column_widths[$column_number] ) : 0;
                $column_number++;
            }
        }

# NEXT TO DO: rebuild column structure to use column names as indexes, not 1, 2, 3

        # Scale the log message counts for printing the graph
        foreach my $category_bucket (keys %{$log_counts{$bucket}}) {
            #next if $category_bucket =~ /^(err|msg)-rate$/ && $log_counts{$bucket}{'err-rate'}{count} == 0 && $log_counts{$bucket}{'msg-rate'}{count} == 0;    # should be caught by below 
            my $count = $log_counts{$bucket}{$category_bucket}{count};
            next if !defined $count;										# skip scaling where varible was left or is undefined (ie; no error or message rate)
# 2025-12-07 removing -1 which I guess was meant as padding, shouldn't be in the scaling algorithm but instead in the graph width calculation
#            my $scaled_count = $max_total{count} != 0 ? int(($count / $max_total{count}) * $graph_width{1} ) - 1: 0;	# Adapting count scaling to multi-graph functionality
            my $scaled_count = $max_total{count} != 0 ? int(($count / $max_total{count}) * $printed_column_widths[$count_column_number] ) : 0;	# Adapting count scaling to multi-graph functionality
my $tmp = int(($count / $max_total{count}) * $printed_column_widths[$count_column_number] );

print "Scaling bucket $category_bucket:\t\tmax_total{count}=$max_total{count} count=$count graph_width{$count_column_number}=$graph_width{$count_column_number} col_width=$printed_column_widths[$count_column_number] tmp=$tmp scaled_count=$scaled_count\n";

            $log_counts{$bucket}{$category_bucket}{scaled_count} = $scaled_count;
            $category_totals{$category_bucket} += $count;							# tally the totals for each category bucket
            $total_lines_highlighted += $count if $category_bucket =~ /-HL$/;
        }

# TO DO: Establish more graceful strategy for memory tracking on Windows (with acceptable performance)
        if( $track_memory && $processed_time_buckets++ % $check_memory_every == 0 && $^O ne 'MSWin32' ) {
            $current_memory_usage = get_memory_usage();								# track maximum memory usage
            if ($current_memory_usage > $max_memory_usage) {
                $max_memory_usage = $current_memory_usage;
            }
        }
    }

    if( $track_memory ) {
        $current_memory_usage = get_memory_usage();								# track maximum memory usage
        if ($current_memory_usage > $max_memory_usage) {
            $max_memory_usage = $current_memory_usage;
        }
    }	

    print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    print "\r$colors{'bright-green'}Scaling and normalizing data completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Scaling and normalizing data completed." ) );

    return;
}

sub print_bar_graph {
    my $lines_printed = 0;
    my @csv_data;

    if( $total_lines_included ) {
        print "\n$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";

        print $colors{'bright-black'};
        foreach my $column (0 .. $#printed_column_names) {
            my $name   = $printed_column_names[$column];
            my $width  = $printed_column_widths[$column];
    
            my $padding = $width - length($name);
            my $left_pad  = int($padding / 2);
            my $right_pad = $padding - $left_pad;

## temporary for helping with spacing ##
   $right_pad -= 1;
   
            print ' ' x $left_pad if $left_pad > 0;
            print $name;
            print ' ' x $right_pad if $right_pad > 0;
print '│';
            print ' ' x $printed_column_spacing[$column] if $column < $#printed_column_names;
        }

#        $, = "\t\t"; print "$colors{'bright-black'}timestamp", "", "count", "\t",  @populated_graph_columns; $, = "";
        print "\n$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";
        $lines_printed++;

        foreach my $bucket (sort keys %log_counts) {
            my $bucket_time_str = strftime($output_timestamp_format, gmtime($bucket));
            my $printed_chars = 0;
            my $total_count = 0;

            ## PRINT TIMESTAMP IN CHART ROW
            $bucket_time_str .= sprintf ".%03d", ($bucket-int($bucket))*1000 if $print_milliseconds;
            my $timestamp_legend_length = $timestamp_length + $graph_column_padding_all;
            print $bucket_time_str . " " x $graph_column_padding_all;
            $printed_chars += $timestamp_legend_length;

            $timestamp_legend_length += $graph_column_padding_legend + $legend_length + $graph_column_padding_all if( !$omit_values || !$omit_rate );

            my $log_details = "";
            my $rate_metrics = "";
            my $legend_length_bucket = 0;
            my %output_columns;

            ## LOOP THROUGH LOG CATEGORY BUCKETS AND PRINT PER ROW LEGEND COUNTS
            foreach my $category_bucket (@log_levels) {
                if (exists $log_counts{$bucket}{$category_bucket}) {
                    my $count = $log_counts{$bucket}{$category_bucket}{count};
                    my $color = $colors{$category_bucket} // $colors{'NC'};
                    next if $omit_values && $category_bucket !~ /^(err-rate|msg-rate)$/;	# we don't want to count data that won't be printed
                    next if $category_bucket =~ /^(err|msg)-rate$/ && $log_counts{$bucket}{'err-rate'}{count} == 0 && $log_counts{$bucket}{'msg-rate'}{count} == 0; 

                    if( $category_bucket =~ /(-HL|err-rate|msg-rate)$/ ) {
                        if( $category_bucket =~ /^err-rate$/ ) {
                            $rate_metrics .= " " if !$omit_values;
                            $rate_metrics .= "${color}" . format_number( $count ) . "$colors{'NC'}";
                            $rate_metrics .= "$colors{'bright-black'}:$colors{'NC'}";
                            $legend_length_bucket += length( " " ) if !$omit_values;
                            $legend_length_bucket += length( format_number( $count ) . ":" );
                        } elsif( $category_bucket =~ /^msg-rate$/ ) {
                            #$rate_metrics .= "${color}$count$colors{'NC'}";
                            $rate_metrics .= "${color}" . format_number( $count ) . "$colors{'NC'}";
                            $rate_metrics .= "$colors{'bright-black'}/m$colors{'NC'} ";
                            $legend_length_bucket += length( format_number( $count ) . "/m " );
                        } else {
                            $log_details .= "${color}$count$colors{'NC'}" . " " if $category_bucket =~ /-HL$/;
                            $legend_length_bucket += length("$count ");
                        }
                    } elsif( $count < 1 ) {					 		# don't include the empty bucket who's purpose is to normalize the buckets represented
                        next;
                    } else {
                        $log_details .= "$color$category_bucket: $count$colors{'NC'} ";
                        $legend_length_bucket += length("$category_bucket: $count ");
                    }

		    # push bucket count to CSV data list
                    $total_count += $count if $category_bucket !~ /^(err-rate|msg-rate)$/;
                    $output_columns{$category_bucket} = $count;
                }
            }

            # Add the log level message counts to the output CSV file
            foreach my $category_bucket ( @output_columns ) {
               next if $category_bucket =~ /^timestamp$/;								# skip the first column and get to the counts
               last if $category_bucket =~ /^totalCount$/;								# only fill in empty values up to the totalCount
               if( exists $output_columns{$category_bucket} ) {								# if there was a count for this log level, add it to the list 
                   push @csv_data, $output_columns{$category_bucket}; 
               } else {
                   push @csv_data, undef;										# if there wasn't a count for this log level, add a blank column
               }
            }

            push @csv_data, $total_count;										# add the total message count to the output CSV data

            print $log_details unless $omit_values;
            my $padding = $legend_length - $legend_length_bucket;
            $printed_chars += $legend_length_bucket ;

#print "\n legend_length: $legend_length legend_length_bucket: $legend_length_bucket padding: $padding [$rate_metrics]" . length($rate_metrics) . "\n";

            print " " x ($padding >= 0 ? $padding : 0);
            $printed_chars += ($padding >= 0 ? $padding : 0);
            print $rate_metrics unless $omit_rate;

            if( $graph_column_padding_count >= 1 ) {						# if there is a padding character, make the first one the separator
                print "$colors{'bright-black'}│$colors{'NC'}";
		$printed_chars++;
	    }

	    if( $graph_column_padding_count - 1 >= 1 ) {					# and these are the remaining padding characters
                my $padding = $graph_column_padding_count - 1;
		print " " x $padding;
                $printed_chars += $padding;
            }

            ## PRINT STANDARD 'COUNT' BAR GRAPH ##
            foreach my $category_bucket (@log_levels) {
                next unless $category_bucket !~ /^empty|err-rate|msg-rate$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
                if (exists $log_counts{$bucket}{$category_bucket}) {
                    my $scaled_count = $log_counts{$bucket}{$category_bucket}{scaled_count};
                    my $color = $colors{$category_bucket} // $colors{'NC'};
                    print "$color" . ( $category_bucket =~ /^[12345]xx(-HL)?$/ ? $blocks{'A'} : $blocks{$default_chart_block} ) x $scaled_count . "$colors{'NC'}";	# provide a global way to change the bar character
                    $printed_chars += $scaled_count;
                }
            }

            print " " x $graph_column_padding_all;
            $printed_chars += $graph_column_padding_all;

# bookmark5
            ## PRINT ADDITIONAL TRENDED VALUES ##
            if( $graph_count > 1 ) {
                my $column_number = 2;
                my $padding = $graph_column_padding_all + $graph_column_padding_other;					# used by normalize to remove and scale data, then add spacing between columns here
## OCCURRENCES -> DURATION column space/padding is here
# 2025-12-07 notion of missing chars might be irrelevant here as I'm now purposfully printing out all the spacing along the way to add the padding
                my $missing_chars = ( length( $bucket_time_str ) + $graph_column_padding_all + $legend_length + $graph_width{1} ) - $printed_chars;
#print "\ngraph_width_1: $graph_width{1} missing chars column 2: $missing_chars printed_chars: $printed_chars timestamp_legend_length: $timestamp_legend_length\n";
                # Fill in empty characters to the start of the second graph space
                print " " x $missing_chars;    # this is the +2 referred to in printed_chars increment
                $printed_chars += $missing_chars;

                foreach my $key ( @populated_graph_columns ) {		# loop through available data columns to print
                    next if $key =~ /^count$/;					# the counts have already been printed, so should skip this entry even if it is legitimate
                    my $scaled_trend_key = "scaled_${key}";
                    my $scaled_trend_key_highlight = "${scaled_trend_key}-HL";
                    my $scaled_trend_value = $log_stats{$bucket}{$scaled_trend_key};
                    my $trend_value = $log_stats{$bucket}{$key};

# TO DO: Need to check if the value to be plotted exists for this section; should be done in normalization stage
                    #next unless defined $trend_value;
#                    print " ";

if( defined $log_stats{$bucket}{$key} ) {

                    if( $key =~ /^(time|duration)$/i ) {
                        $trend_value = " " . format_time( $log_stats{$bucket}{$key}, 'ms', 'long', ' ' );
                        push @csv_data, ltrim( $trend_value ), $log_stats{$bucket}{$key};				# push trend value to CSV data list
                    } elsif( $key =~ /^bytes$/i ) {
                        $trend_value = " " . format_bytes( $log_stats{$bucket}{$key}, 'B' );
                        push @csv_data, ltrim( $trend_value ), $log_stats{$bucket}{$key};				# push trend value to CSV data list
                    } else {
                        $trend_value = defined $log_stats{$bucket}{$key} ? " $log_stats{$bucket}{$key}" : "";
                        push @csv_data, ltrim( $trend_value );								# push trend value to CSV data list
                    }

# bookmark7
                    # SECONDARY TREND Print the secondary trend and associated value
                    #print "\033[93;43m";					# 93 is dark yellow foreground, 43 is light yellow background
                    # Blue background 104m, Blue Foreground 94m
                    # Yellow background 103m, Yellow Foreground 93m       184 medium yellow (nice!)  190 pale yellow  226 bright yellow   (184 + 190 are the winners)
                    # Cyan background 103m, Cyan Foreground 36m, bright Cyan 96m   46 Cyan BG   30 Deep Cyan  44 Bright Cyan 36 Darker Cyan 37 Vibrant Cyan 45 Cyan 106 Bright Cyan BG  51 bright cyan    123 medium cyan   159 light cyan  195 pale cyan
                    # Green                          32 Green FG    42 Green BG     92 Bright Green FG   102  Bright Green BG     34 Medium Green  46 Ultramarine Green  120  Light Green  121  Pale Green
                    # Blue                           34 Blue FG     44 Blug BG     94 Bright Blue FG   20 Ultramarine Blue   104 Bright Blue BG    20 Medium Blue   117 Light Blue   159  Pale Blue
                    # Magenta                        35 FG Magenta     45 BG Magenta      105 Bright Magenta    127 Medium magenta   201 Ultramarine Magenta   225 Light Magenta     219 Pale Magenta

#print "$scaled_trend_key_highlight $log_stats{$bucket}{$scaled_trend_key_highlight}";
                    # Start the background color with the brighter highlight value if there is anything to highlight
                    #print $key =~ /^duration$/i ? "\033[48;5;226m\033[38;5;0m" : "\033[48;5;123m\033[38;5;0m";

                    my ( $highlighted_bg_black_fg, $plain_bg_black_fg, $black_bg_plain_fg );

                    if( $column_number == 2 ) {						# Yellow
                        $highlighted_bg_black_fg = "\033[48;5;226m\033[38;5;0m";
                        $plain_bg_black_fg = "\033[48;5;184m\033[38;5;0m";
                        $black_bg_plain_fg = "\033[0m\033[93m";
                    #} elsif( $key =~ /^bytes$/i ) {
                    } elsif( $column_number == 3 ) {					# Green
                        $highlighted_bg_black_fg = "\033[48;5;46m\033[38;5;0m";
                        $plain_bg_black_fg = "\033[48;5;34m\033[38;5;0m";
                        $black_bg_plain_fg = "\033[0m\033[32m";
                    } elsif( $column_number == 4 ) {					# Cyan
                        $highlighted_bg_black_fg = "\033[48;5;36m\033[38;5;0m";
                        $plain_bg_black_fg = "\033[48;5;30m\033[38;5;0m";
                        $black_bg_plain_fg = "\033[0m\033[36m";
                    } elsif( $column_number == 5 ) {					# Blue
                        $highlighted_bg_black_fg = "\033[48;5;21m\033[38;5;0m";
                        $plain_bg_black_fg = "\033[48;5;20m\033[38;5;0m";
                        $black_bg_plain_fg = "\033[0m\033[34m";
                    } elsif( $column_number == 6 ) {					# Magenta
                        $highlighted_bg_black_fg = "\033[48;5;201m\033[38;5;0m";
                        $plain_bg_black_fg = "\033[48;5;127m\033[38;5;0m";
                        $black_bg_plain_fg = "\033[0m\033[35m";
                    }


		    print " " x $graph_column_padding_other;				# if stated, this is the BEFORE column padding specific to these columns
                    print $highlighted_bg_black_fg;

# 2025-12-07 think need to remove these hardcoded spaces and move to a global padding value which is subtracted from column widths
		    my $character_delta = $graph_column_padding_all + $graph_column_padding_other + 2;		# padding, plus the 1 array offset
                    for my $i ( 0 .. $graph_width{$column_number} - $character_delta) {
                        my $value_char = (split //, $trend_value )[$i];

                        # Switch over to the standard foreground/background colors once we have printed the required number of highlighted bars
                        if( defined $log_stats{$bucket}{$scaled_trend_key_highlight} && $log_stats{$bucket}{$scaled_trend_key_highlight} == $i ) {
                            #print $key =~ /^duration$/i ? "\033[48;5;184m\033[38;5;0m" : "\033[48;5;45m\033[38;5;0m";
                            print $plain_bg_black_fg;
                        }

                        # Switch over the graphs standard foreground color with black background once all bars are printed
                        if( $i == $scaled_trend_value ) {
                            #print $key =~ /^duration$/i ? "$colors{'NC'}\033[93m" : "$colors{'NC'}\033[36m";
                            print "$black_bg_plain_fg";
                        }

                        print length( $value_char ) ? $value_char : " ";
                    }

                    print "$colors{'NC'}\033[0m";						# clear the foreground color

                } else {
		    # This is the special condition where a column has no values/data for a particular interval, in which case we just need to print the column width in spaces
                    print " " x ( $padding + ( $graph_width{$column_number} - $padding ) );
                }

                    #$printed_chars += $missing_chars + $scaled_trend_value;
# 123columnWidth
                  #  $printed_chars += $padding + ( $graph_width{$column_number} - $padding );		# +2 for space before and after the sparkline
                  #  $printed_chars += $graph_width{$column_number};		# +2 for space before and after the sparkline

		    print " " x $graph_column_padding_all;				# if stated, this is the AFTER column padding for ALL columns
                    $column_number++;
                }
            }
            
            # DURATION STATISTICS print duration statistics table
            if( $print_durations && !$omit_durations && !$omit_stats ) {
                my $missing_chars;
                $missing_chars =  $terminal_width - $printed_chars - $durations_graph_width;		# 2 is the magic number to get 1 space after the tallest bar 
#$missing_chars -= 4;
#print "\nterminal_width: $terminal_width printed_chars: $printed_chars durations_graph_width: $durations_graph_width missing_chars: $missing_chars\n";
                print " " x $missing_chars if $missing_chars > 0;
                print "$colors{'bright-black'}│$colors{'NC'}  ";
                if( defined $log_stats{$bucket}{bytes} || defined $log_stats{$bucket}{p50} || defined $log_stats{$bucket}{p90} || defined $log_stats{$bucket}{p95} || defined $log_stats{$bucket}{cv} || defined $log_stats{$bucket}{z_score} ) {

                    my $cv_color = defined $log_stats{$bucket}{cv} && $log_stats{$bucket}{cv} >= 20 ? 'WARN-HL' : 'white-underline';
                    my $zscore_color = defined $log_stats{$bucket}{z_score} && $log_stats{$bucket}{z_score} >= 5 ? 'WARN-HL' : 'NC';

                    defined $log_stats{$bucket}{p50} ? printf( "$colors{'bright-blue'}P50:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p50} ) >= 4 ? format_time( $log_stats{$bucket}{p50}, 'ms' ) : $log_stats{$bucket}{p50} ) ) : printf( " " x 6 );
                    defined $log_stats{$bucket}{p90} ? printf( "$colors{'yellow'}P90:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p90} ) >= 4 ? format_time( $log_stats{$bucket}{p90}, 'ms' ) : $log_stats{$bucket}{p90} ) ) : printf( " " x 6 ); 
                    defined $log_stats{$bucket}{p95} ? printf( "$colors{'red'}P95:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p95} ) >= 4 ? format_time( $log_stats{$bucket}{p95}, 'ms' ) : $log_stats{$bucket}{p95} ) ) : printf( " " x 6 );
                    defined $log_stats{$bucket}{cv} ? printf( "$colors{$cv_color}CV:%5s$colors{'NC'} ", $log_stats{$bucket}{cv} ) : printf ( " " x 9 );
                    defined $log_stats{$bucket}{z_score} ? printf( "$colors{$zscore_color}Z:%5s$colors{'NC'}", ( $log_stats{$bucket}{z_score} >= 100 ? format_number( $log_stats{$bucket}{z_score} =~ /(\d+)\.\d*/, undef, 0 ) : $log_stats{$bucket}{z_score} ) ) : printf( " " x 5 );

# bookmark23
                    foreach my $stat ( qw( min mean max std_dev p1 p50 p75 p90 p95 p99 p999 cv z_score ) ) {				# push statistics data to the CSV data list
                        push @csv_data, $log_stats{$bucket}{$stat};
                    }
                }
            }

# bookmark22
            # Print details to time-window statistics CSV file
            if( $write_messages_to_csv && defined $csv_fh ) {
                $csv->print($csv_fh, [ $bucket_time_str, @csv_data ]);
            }

            undef @csv_data;

            print "\n";
    # BUG - if using pause, the summary table won't be paused as it isn't implementing the next line
            pause_for_keypress() if( $pause_output && $lines_printed++ > 1 && $lines_printed % ( $terminal_height - 1 ) == 0 );
        }

        print "$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";

    } else {
        printf "Read $total_lines_read lines, however no lines matched any of the patterns within the timeframe.\n";
    }
    return;
}

sub print_summary_table {
    my $category_column_width = 30;
    my $count_column_width = 10;
    my $table_padding = 2;
    my $padding = " " x $table_padding;
    my $column_padding = " " x 1;
    my $table_format = "$padding%-${category_column_width}s %${count_column_width}d$padding\n";
    my $summary_table_width = $table_padding + $category_column_width + 1 + $count_column_width + $table_padding;
    my $file_detail_width = $terminal_width - ( $summary_table_width + $table_padding * 2 );
    my ( @summary_table, @file_details );
    my ( @match_char ) = ( "$colors{'red'}χ", "$colors{'green'}√", "$colors{'green-HL'}√" );

    ## FORMAT MIN/MAX LOG TIMESTAMPS FOR THE SUMMARY ##
    my $min_timestamp_str = strftime($output_timestamp_format, gmtime($output_timestamp_min));
    my $max_timestamp_str = strftime($output_timestamp_format, gmtime($output_timestamp_max));
    $min_timestamp_str .= sprintf ".%03d", ($output_timestamp_min-int($output_timestamp_min))*1000 if $print_milliseconds;
    $max_timestamp_str .= sprintf ".%03d", ($output_timestamp_max-int($output_timestamp_max))*1000 if $print_milliseconds;

    ## PRINT COMMAND AND ARGUMENTS ##
# TO DO: Will need to carve this out for full setup pagination

    print "\n$colors{'bright-black'}options: ";
    my %argv_hash = map { $_ => 1 } @ARGV;
    foreach my $arg (@ORIGINAL_ARGV) {
        unless (exists $argv_hash{$arg}) {
            print "$arg ";
        }
    }
    print "$colors{'NC'}\n";

    return if $omit_summary;

    ## START SUMMARY STATISTIC TABLE ##
    push @summary_table, sprintf( "\n  " . "─" x ( $category_column_width + $count_column_width + 1 ) . "$padding\n" );
    push @summary_table, sprintf( "  " . "%-${category_column_width}s %${count_column_width}s$padding\n", "Category", "Total" ); 
    push @summary_table, sprintf( "  " . "─" x ( $category_column_width + $count_column_width + 1 ) . "$padding\n" );

    foreach my $category_bucket (@log_levels) {
        next if $category_bucket =~ /^(empty|err-rate|msg-rate)$/;
        next unless $category_totals{$category_bucket};
	
        my ( $legend_title ) =  "$category_bucket:" . " " x ( 14 - length( $category_bucket ) );
        #print "$legend_title$category_totals{$category_bucket}\n"; 
        #printf "%-${category_column_width}s %${count_column_width}d\n", $category_bucket, $category_totals{$category_bucket}; 
        push @summary_table, sprintf( $table_format, $category_bucket, $category_totals{$category_bucket} ); 

    }

    push @summary_table, sprintf( "$padding" . "─" x ( $category_column_width + $count_column_width + 1 ) . "$padding\n" );
    push @summary_table, sprintf( $table_format, "HIGHLIGHTED", $total_lines_highlighted ) if defined $highlight_regex;
    push @summary_table, sprintf( $table_format, "LINES INCLUDED", $total_lines_included ); 
    push @summary_table, sprintf( $table_format, "LINES READ", $total_lines_read ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "FILE PROCESSING TIME", format_time( $elapsed_read_files, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "INITIALIZE EMPTY BUCKETS", format_time( $elapsed_initialize_empty_time_windows, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "GROUP SIMILAR MESSAGES", format_time( $elapsed_group_similar_messages, 's', 'medium', " " ) ) unless $group_similar_sensitivity =~ /^none$/;
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "CALCULATE STATISTICS", format_time( $elapsed_calculate_statistics, 's', 'medium', " " ) ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "SCALE DATA TO TERMINAL", format_time( $elapsed_normalize_data, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "TOTAL TIME", format_time( $elapsed_total, 's', 'medium', " " ) ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${count_column_width}s$padding\n", "MEMORY USED", format_bytes( $max_memory_usage, 'kB' ) ) if $track_memory;
    push @summary_table, sprintf( "$padding" . "─" x ( $category_column_width + $count_column_width + 1 ) . "$padding\n" );



    push @file_details, "\n";
    push @file_details, sprintf( "$column_padding$padding$colors{'white-underline'}These file(s) were processed with analysis including results between $min_timestamp_str and $max_timestamp_str$colors{'NC'}\n" );
    push @file_details, "\n";
    foreach my $in_file (@files_processed) {
         my $filename_max_length = $file_detail_width - length( $column_padding ) - 3 - 4; 
         my $filename = length( $in_file ) > $filename_max_length ? "..." . substr( $in_file, length( $in_file ) - $filename_max_length ) : $in_file;  # -3 for '...', -4 for '[x] '
         push @file_details, sprintf( "$column_padding$padding$colors{'white'}\[%s$colors{'NC'}$colors{'white'}\] %-${filename_max_length}s$colors{'NC'}\n", $match_char[$in_files_matched{$in_file}], $filename );
    }

    for (my $i = 0; $i < max(scalar @summary_table, scalar @file_details); $i++) {
        if( $i >= scalar @summary_table ) {
            print " " x $summary_table_width . $column_padding;
        } else {
            chomp $summary_table[$i];
            print "$summary_table[$i]$column_padding";
        }

        if( $i >= scalar @file_details ) {
            print "\n";
        } else {
            print $file_details[$i];
        }
    }

    return;
}

sub print_message_summary {
    # Define the relative size of each column as a percentage
    my %col_relative_size;

    print "\n";

    if( $print_durations && !$omit_durations ) {
        %col_relative_size = (
            1 => 65,
            2 => 6,
            3 => 5,
            4 => 5,
            5 => 5,
            6 => 5,
            7 => 9,
        );
    } else {
        %col_relative_size = (
            1 => 94,
            2 => 6,
        );
    }

    # Initialize the hash to store the character width of each column
    my %col_width;

    # Define the terminal width and padding values
    my $table_padding_outer = 1;  # Example outer padding
    my $table_padding_inner = 1;  # Example inner padding

    # Calculate the total table width after applying outer padding
    my $table_width = $terminal_width - (2 * $table_padding_outer);

    # Calculate the absolute width for each column based on the relative size and inner padding
    foreach my $column (keys %col_relative_size) {
        $col_width{$column} = int($table_width * $col_relative_size{$column} / 100) - (2 * $table_padding_inner);
    }

    ### DETERMINE CUT OF HIGHLIGHTED VS PLAIN MESSAGES TO PRINT ###
    # Step 1: Sort and store available messages for each category in a hash of arrays
#    my %sorted_keys = (
#        'highlight' => [ sort { $log_messages{'highlight'}{$b}{$sort_key} <=> $log_messages{'highlight'}{$a}{$sort_key} } keys %{$log_messages{'highlight'}} ],
#        'plain' => [ sort { $log_messages{'plain'}{$b}{$sort_key} <=> $log_messages{'plain'}{$a}{$sort_key} } keys %{$log_messages{'plain'}} ],
#    );

    my %sorted_keys = ( 'highlight' => [], 'plain' => [] );
    foreach my $grouping ( qw( highlight plain ) ) {
        my @sorted_keys = sort {
            my $count_a = $log_messages{$grouping}{$a}{$sort_key} // 0;
            my $count_b = $log_messages{$grouping}{$b}{$sort_key} // 0;
            $count_b <=> $count_a; 
        } keys %{$log_messages{$grouping}};

        $sorted_keys{$grouping} = \@sorted_keys;
    }

    # Initialize the hash to store top message counts
    my %top_message_count = (
        'highlight' => 0,
        'plain' => 0,
    );

    foreach my $grouping ( qw( highlight plain ) ) {
        for my $i (0 .. $#{$sorted_keys{$grouping}}) {
            last if $i >= $top_n_messages;
            $top_message_count{$grouping}++;
        }
    }

    # Step 2: Determine how many messages to print from each category
    my $half_top_n = int($top_n_messages / 2);

    # Initialize the hash to store the number of messages to print
    my %messages_to_print = (
        'highlight' => $half_top_n,
        'plain' => $half_top_n,
    );

    $messages_to_print{'highlight'}++ if $top_n_messages % 2 != 0;		# if halving doesn't equate to Top N, then add another row to highlighted messages

    # Step 3: Adjust if one category has fewer messages than needed, ensuring the total remains $top_n_messages
    if ($top_message_count{'highlight'} < $messages_to_print{'highlight'}) {
        $messages_to_print{'highlight'} = $top_message_count{'highlight'};
        $messages_to_print{'plain'} = $top_n_messages - $messages_to_print{'highlight'};
    } elsif ($top_message_count{'plain'} < $messages_to_print{'plain'}) {
        $messages_to_print{'plain'} = $top_message_count{'plain'};
        $messages_to_print{'highlight'} = $top_n_messages - $messages_to_print{'plain'};
    }

    foreach my $grouping ( qw( highlight plain ) ) {
        my $messages_printed = 0;

        # Ensure the grouping exists and is a hash reference
        if (exists $log_messages{$grouping} && ref($log_messages{$grouping}) eq 'HASH') {
            #my @top_keys = (sort { $log_messages{$grouping}{$b}{count} <=> $log_messages{$grouping}{$a}{count} } keys %{$log_messages{$grouping}})[0..($top_n_messages-1)];
            my @top_keys = @{$sorted_keys{$grouping}}[0..($top_n_messages-1)] if scalar( @{$sorted_keys{$grouping}} ) > 0;

            next unless scalar(@top_keys) > 0;			# skip to the next category if their are no top message keys

            my $header_title = " ";

            if( $grouping eq "highlight" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-yellow-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP HIGHLIGHTED MESSAGES (highlighted based on RegEx pattern match)" ) . " " x $table_padding_inner;

                if( $print_durations && !$omit_durations ) {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", "Min" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", "P50" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", "P99.9" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", "CV" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", "Time" ) . " " x $table_padding_inner; 
                } else {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                }

                $header_title .= "$colors{'NC'}$colors{'bright-yellow'}";
            } elsif( $grouping eq "plain" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-cyan-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP OVERALL MESSAGES (retained for after inclusion, exclusion, time range, and duration filters)" ) . " " x $table_padding_inner;

                if( $print_durations && !$omit_durations ) {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", "Min" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", "P50" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", "P99.9" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", "CV" ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", "Time" ) . " " x $table_padding_inner; 
                } else {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                }

                $header_title .= "$colors{'NC'}$colors{'bright-cyan'}";
            }

            print "$header_title\n";
            print " " x $table_padding_outer . "─" x $table_width . "$colors{'NC'}\n";

            # Print the top messages
            foreach my $key (@top_keys) {
                next if $messages_printed++ >= $messages_to_print{$grouping};
 
                my $row = " " x $table_padding_outer;

                if (defined $key && exists $log_messages{$grouping}{$key}) {
                    my $message = substr( $key, 0, $col_width{1} );
                    my $count = $log_messages{$grouping}{$key}{count};

                    if( $print_durations && !$omit_durations && ( defined $log_messages{$grouping}{$key}{p50} || defined $log_messages{$grouping}{$key}{cv} || defined $log_messages{$grouping}{$key}{total_duration} ) ) {
                        my $total_bytes_num = $log_messages{$grouping}{$key}{total_bytes};
                        my $total_bytes = format_bytes( $total_bytes_num,'B' );
                        my $mean_bytes = round( $total_bytes_num / $count ) if defined $total_bytes_num; 
                        my $min = $log_messages{$grouping}{$key}{min};
                        my $mean = $log_messages{$grouping}{$key}{mean};
                        my $max = $log_messages{$grouping}{$key}{max};
                        my $std_dev = $log_messages{$grouping}{$key}{std_dev};
                        my $impact = $log_messages{$grouping}{$key}{impact};
                        my $p1 = $log_messages{$grouping}{$key}{p1};
                        my $p50 = $log_messages{$grouping}{$key}{p50};
                        my $p75 = $log_messages{$grouping}{$key}{p75};
                        my $p90 = $log_messages{$grouping}{$key}{p90};
                        my $p95 = $log_messages{$grouping}{$key}{p95};
                        my $p99 = $log_messages{$grouping}{$key}{p99};
                        my $p999 = $log_messages{$grouping}{$key}{p999};
                        my $cv = $log_messages{$grouping}{$key}{cv};
                        my $total_duration_num = $log_messages{$grouping}{$key}{total_duration_num};
                        my $total_duration = $log_messages{$grouping}{$key}{total_duration};

                        $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $count ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", defined $min ? ( length( $min ) >= 4 ? format_time( $min, 'ms', 'short' ) : $min ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", defined $p50 ? ( length( $p50 ) >= 4 ? format_time( $p50, 'ms', 'short' ) : $p50 ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", defined $p999 ? ( length( $p999 ) >= 4 ? format_time( $p999, 'ms', 'short' ) : $p999 ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", defined $cv ? $cv : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", defined $total_duration ? $total_duration : "" ) . " " x $table_padding_inner; 

                        if( $write_messages_to_csv && defined $csv_fh ) {
                            $csv->print($csv_fh, [ $grouping, $key, $count, $mean_bytes, $total_bytes_num, $total_bytes, $min, $mean, $max, $std_dev, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $cv, $total_duration_num, $total_duration, $impact ]);
                        }
                    } else {
                        $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $count ) . " " x $table_padding_inner; 

                        if( $write_messages_to_csv && defined $csv_fh ) {
                            $csv->print($csv_fh, [ $grouping, $key, $count, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef, undef ]);
                        }
                    }

                    #print "$log_messages{$grouping}{$key}{count} | $key | P1: $p1 P50: $p50 P99: $p99 CV: $cv Total: $total_duration\n";
                    print "$row\n";

                }
            }

            print "\n";
        }
    }

    return;
}

sub print_threadpool_summary {
    # Define the relative size of each column as a percentage
    my %col_relative_size;

    print "\n";

    %col_relative_size = (
       1 => 94,
       2 => 6,
    );

    # Initialize the hash to store the character width of each column
    my %col_width;

    # Define the terminal width and padding values
    my $table_padding_outer = 1;  # Example outer padding
    my $table_padding_inner = 1;  # Example inner padding

    # Calculate the total table width after applying outer padding
    my $table_width = $terminal_width - (2 * $table_padding_outer);

    # Calculate the absolute width for each column based on the relative size and inner padding
    foreach my $column (keys %col_relative_size) {
        $col_width{$column} = int($table_width * $col_relative_size{$column} / 100) - (2 * $table_padding_inner);
    }

    ### DETERMINE CUT OF HIGHLIGHTED VS PLAIN MESSAGES TO PRINT ###
    # Step 1: Sort and store available messages for each category in a hash of arrays
    my %sorted_keys = ( 'highlight' => [], 'plain' => [] );
    foreach my $grouping ( qw( highlight plain ) ) {
        my @sorted_keys = sort {
            my $count_a = scalar keys %{$threadpool_activity{$grouping}{$a}} // 0;
            my $count_b = scalar keys %{$threadpool_activity{$grouping}{$b}} // 0;
            $count_b <=> $count_a; 
        } keys %{$threadpool_activity{$grouping}};

        $sorted_keys{$grouping} = \@sorted_keys;
    }

    # Initialize the hash to store top message counts
    my %top_message_count = (
        'highlight' => 0,
        'plain' => 0,
    );

    foreach my $grouping ( qw( highlight plain ) ) {
        for my $i (0 .. $#{$sorted_keys{$grouping}}) {
            last if $i >= $top_n_messages;
            $top_message_count{$grouping}++;
        }
    }

    # Step 2: Determine how many messages to print from each category
    my $half_top_n = int($top_n_messages / 2);

    # Initialize the hash to store the number of messages to print
    my %messages_to_print = (
        'highlight' => $half_top_n,
        'plain' => $half_top_n,
    );

    $messages_to_print{'highlight'}++ if $top_n_messages % 2 != 0;		# if halving doesn't equate to Top N, then add another row to highlighted messages

    # Step 3: Adjust if one category has fewer messages than needed, ensuring the total remains $top_n_messages
    if ($top_message_count{'highlight'} < $messages_to_print{'highlight'}) {
        $messages_to_print{'highlight'} = $top_message_count{'highlight'};
        $messages_to_print{'plain'} = $top_n_messages - $messages_to_print{'highlight'};
    } elsif ($top_message_count{'plain'} < $messages_to_print{'plain'}) {
        $messages_to_print{'plain'} = $top_message_count{'plain'};
        $messages_to_print{'highlight'} = $top_n_messages - $messages_to_print{'plain'};
    }

    foreach my $grouping ( qw( highlight plain ) ) {
        my $messages_printed = 0;

        # Ensure the grouping exists and is a hash reference
        if (exists $threadpool_activity{$grouping} && ref($threadpool_activity{$grouping}) eq 'HASH') {
            my @top_keys = @{$sorted_keys{$grouping}}[0..($top_n_messages-1)] if scalar( @{$sorted_keys{$grouping}} ) > 0;

            next unless scalar(@top_keys) > 0;			# skip to the next category if their are no top message keys

            my $header_title = " ";

            if( $grouping eq "highlight" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-yellow-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP HIGHLIGHTED THREAD POOLS ─ ACTIVE THREADS" ) . " " x $table_padding_inner;
                $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                $header_title .= "$colors{'NC'}$colors{'bright-yellow'}";
            } elsif( $grouping eq "plain" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-magenta-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP OVERALL THREAD POOLS ─ ACTIVE THREADS" ) . " " x $table_padding_inner;
                $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                $header_title .= "$colors{'NC'}$colors{'bright-magenta'}";
            }

            print "$header_title\n";
            print " " x $table_padding_outer . "─" x $table_width . "$colors{'NC'}\n";

            # Print the top thread pools
            foreach my $key (@top_keys) {
                next if $messages_printed++ >= $messages_to_print{$grouping};
 
                my $row = " " x $table_padding_outer;

                if (defined $key && exists $threadpool_activity{$grouping}{$key}) {
                    my $message = substr( $key, 0, $col_width{1} );
                    my $count = scalar keys %{$threadpool_activity{$grouping}{$key}};
#print "$threadpool_activity{$grouping}{$key} $count\n";

                    $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                    $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $count ) . " " x $table_padding_inner; 

                    print "$row\n";
                }
            }

            print "\n";
        }
    }

    return;
}


## MAIN ##

print_title();
adapt_to_terminal_settings(); 
adapt_to_command_line_options();

# READ AND PROCESS LOGS #
$start_time = [gettimeofday];
read_and_process_logs();
$end_time = [gettimeofday];
$elapsed_read_files = tv_interval($start_time, $end_time);

# INITIALIZE EMPTY TIME BUCKETS #
$start_time = [gettimeofday];
initialize_empty_time_windows();
$end_time = [gettimeofday];
$elapsed_initialize_empty_time_windows = tv_interval($start_time, $end_time);

# GROUP SIMILAR MESSAGES TOGETHER #
unless( $group_similar_sensitivity eq "none" ) {
    $start_time = [gettimeofday];

    $end_time = [gettimeofday];
    $elapsed_group_similar_messages = tv_interval($start_time, $end_time);
}

# CALCULATE STATISTICS #
$start_time = [gettimeofday];
print "Calculate statistics...";
calculate_all_statistics();
$end_time = [gettimeofday];
$elapsed_calculate_statistics = tv_interval($start_time, $end_time);


# NORMALIZE DATA FOR CONSOLE OUTPUT #
$start_time = [gettimeofday];
normalize_data_for_output();
$end_time = [gettimeofday];
$elapsed_normalize_data = tv_interval($start_time, $end_time);

$elapsed_total = $elapsed_read_files + $elapsed_initialize_empty_time_windows + $elapsed_calculate_statistics + $elapsed_normalize_data + $elapsed_group_similar_messages;

if( $write_messages_to_csv ) {														# If write to CSV enabled, open filehandles
    $csv = Text::CSV->new({ binary => 1, eol => $/ });											# Create a new CSV object
    my ($sec, $min, $hour, $mday, $mon, $year) = localtime();
    my $timestamp = sprintf( "%04d-%02d-%02d_%02d%02d%02d", $year + 1900, $mon + 1, $mday, $hour, $min, $sec );
    $csv_file_args =~ tr/!@#\$%\^&*()_+{}|:"<>?[\];',.\/\\`~ /_/;
    my $csv_file_name = "${timestamp}-LTL-STATS-${csv_file_args}.csv";
    open $csv_fh, '>', $csv_file_name or die "Could not open file: $!";									# Open a file for writing, then print the header/column names
    $csv->print($csv_fh, [ @output_columns ] );
}

print_bar_graph();
close $csv_fh or die "Could not close file: $!" if( $write_messages_to_csv && defined $csv_fh );					# Close the file handle

print_summary_table();

if( $write_messages_to_csv ) {														# If write to CSV enabled, open filehandles
    $csv = Text::CSV->new({ binary => 1, eol => $/ });											# Create a new CSV object
    my ($sec, $min, $hour, $mday, $mon, $year) = localtime();
    my $timestamp = sprintf( "%04d-%02d-%02d_%02d%02d%02d", $year + 1900, $mon + 1, $mday, $hour, $min, $sec );
#    $csv_file_args =~ tr/!@#\$%\^&*()_+{}|:"<>?[\];',.\/\\`~ /_/;
    my $csv_file_name = "${timestamp}-LTL-MESSAGES-${csv_file_args}.csv";
    open $csv_fh, '>', $csv_file_name or die "Could not open file: $!";									# Open a file for writing, then print the header/column names
    $csv->print($csv_fh, [qw(Category Message Count MeanBytes TotalBytes TotalBytesNice MinDuration MeanDuration MaxDuration StdDev P1 P50 P75 P90 P95 P99 P99.9 CV TotalDuration TotalDurationNice Impact)]);
}

print_message_summary();														# Print and write message summaries
close $csv_fh or die "Could not close file: $!" if( $write_messages_to_csv && defined $csv_fh );					# Close the file handle

print_threadpool_summary() if $include_threadpool_summary;										# Print threadpool summaries


print "\n";
exit;
