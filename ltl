#!/opt/homebrew/bin/perl

# TO DO
# - adjust sorting to appropriately handle messages with missing sort metric values when they are missing
# - [Prototyping] group similar messages together with unique part replacement mask #### based on memory used >50MB and messages where count is 1 (only group the lower ones) option to change the number considered which would essetially create different sets of message groups
# - Adapt message field widths based on terminal width (object field and thread pool)
# - Figure out how to try to auto-detect the duration units (milliseconds, microseconds, seconds) and adapt accordingly line by line in a file
# - Add Integration Runtime log parsing pattern
# - Add message parse pattern for AkkaCommunications logs
# - Filter options for min/max impact (count*duration)
# - Work in a "Test Mode" which would output a number of parameters and values during the run which could then be tested against for automated testing
# - investigate moving extraction and processing of bytes out of each of the conditions and put into a common section (be careful of log formats where bytes is implied by column and should not be overwritten)
# - I'd like a way to change the normalization of messages per minute to second
# - new command line options for "show-bytes and show-counts" to add these columns to the message table instead of the duration statistics (plan forward for unknown custom metric as well)
# - add total counts for duration and bytes; what makes this harder to fit in is that there should obviously also be seperate counters for "highlight" (bottom of table makes sense, also summary table, or both)
# - Add AND match possibility for include and exclude using RegEx lookahead (?=.*word)
# - Add the ability to highlight based on numerical condition matching example -dmin => -hdmin would keep rows smaller, but highlight rows above or something like that.  Need to think carefully about the terminology and naming so that there is coherence between the include/exclude/minimum/maximum/highlight concepts across the tool.
# - Second graph (stats): line chart showing evolution of some of the percentile stats in different colors (with points) 
# - Second graph (throughput): outbound throughput based on bytes returned
# - need to save X-axis charaters with all the information - when terminal width < X and all time windows on same day, omit printing the date on each line (instead print it at the start or end) - this saves 10 chars
# - add a soft memory limit (after having made most of the tweaks) to avoid accidents in production reading large files with 100k's of different messages - will need to optimize performance of memory checking
# - Similar to JMC, percentile calculations should include the representative counts (perhaps this is in a summary chart at the end or specified to be added)
#    - three graphs across the bottom, same colors as bytes, duration, count.  auto-centers and scales if there are 1, 2, 3.   shows percentiles, 50% value, 100% value in Y-Axis - give overall population representation in a glance of size, records, time
#    - above could be optional (takes a lot of space), however a smaller one just for duration like in JMC could go next to file names
# - rejig the overall totals in the section with the file names to show a table with the headings and counts per file, with overall totals at the bottom.  Would be tighter with far more information density.
# - move execution times to the "options" line on the right side to show execution times discretely without taking up so much space (coded for easy testing/extraction)

# BUGS
# - message based sorting and statistics seems to be occurring after the timeline is printed, not during all of the calculation and reading stages
# - Line printing that heatmap calculation is being processed is not overwritten with a green message stating that it is complete like the other stages (it dissappears)
# - when using the -o flag, combined with the -ov flag (and possibly others), metrics are not written to the CSV file as the sections are skipped in print bar chart column (needs refactoring)
# - when using the -o flag, the provided command line options are used in the file name, however when using a long list of filters, the filename can be too long causing error - need to truncate the filename
# - on very narrow terminals, the "processed files" heading and potentially file names will wrap and mess up the table
# - FIXED v0.9.1: progress indicator now based on total lines read (not per-file), shows lines/sec rolling average
# - print_durations=0 initiated by --omit-stats should not impeed statistical calculation of statistics for CSV output file
# BUG 2026-01-04 : stats calculations and output need to be decoupled from what is printed to the console.  Here, specifying to not print duration stats will not output them either.


# NOT PRIORITY BACKLOG
# - refactor thread pool summary and message summary views to use common code base for printing tables
# - add pagination support for the summary overview and the top messages - when using the -p (pause) option, the summary table and message lists do not pause for keypresses
# - add feature to auto-calculate time window bucket based on terminal height and min and max time range in file (this would be based on previous file reads, or better filesize) - would have to go thought all input files
# - reading duration should have a variable which will determine what the units are and this will depend on the detected log file.  For example nginx uses seconds, most other use milliseconds.  Then convert to MS before adding to the stats map so that you can mix and match files with different units.
# - add a feature to include/exclude HTTP status codes which would need to be converted to RegEx as 4xx isn't going to be matched to the actual line text from what the user enters
# - add a feature to allow for grouping of various other log categories like ThreadPool or Object context (instead of errors)
# - performance improvement: leverage a temp file with cached file stats (log start/end times, num lines, ...) to start/stop reading the file when provided start/end time ranges based on guesses around filesize


use strict;
use warnings;
use POSIX qw(strftime floor);
use Math::Round;
use Time::Piece;
use DateTime;
use Term::ReadKey;
use Getopt::Long qw(:config no_ignore_case);
use Term::ANSIColor;
use Time::HiRes qw(gettimeofday tv_interval);
# Proc::ProcessTable is loaded conditionally in get_memory_usage() based on platform
# On Windows, Win32::Process::Info is used instead
use List::Util qw(min max);
use File::Spec;
use Text::CSV;
use Text::CSV_PP;


if ($^O eq 'MSWin32') {                                                             # Change code page to UTF-8 on Windows to support UTF-8 characters in terminal
	system("chcp 65001 > nul");
}

## GLOBALS ##
my $version_number = "0.9.0";
my $start_time = [gettimeofday];
my $log_base = 2;
my ( @rolling_window, @ORIGINAL_ARGV, @files_processed );
my $rolling_window_size = 5;					# Adjust this value as needed - more time buckets included in the rolling window will give better sample for Z-score
my $impact_time_exponent = 7;		            # it was 5, and was weighting a few slow executions too heavily compared to frequent faster executions
my ( $bucket_size_minutes, $bucket_size_seconds, $print_seconds, $print_milliseconds, $print_version, $omit_empty, $omit_summary, $omit_rate, $omit_stats, $omit_durations, $omit_bytes, $omit_count ) = 0;
my ( $include_query_string, $include_session, $include_threadpool_summary, $include_count ) = ( 0, 0, 0, 0 );
my ( $current_memory_usage, $max_memory_usage, $end_time, $elapsed_total, $elapsed_read_files, $elapsed_initialize_empty_time_windows, $elapsed_calculate_statistics, $elapsed_normalize_data, $elapsed_group_similar_messages ) = ( 0,0,0,0,0,0,0,0,0 );
# this is where the counts of log entries are tallied across the time buckets
my ( %log_occurrences, %category_totals, %log_analysis, %log_messages, %log_stats, %log_threadpools, %threadpool_activity, %log_userdefinedmetrics );
my $max_log_message_length = 0;				    # used to define the maximum key length of the log message bucket counts
my $mask_uuid;									# temporary command line option to mask UUIDs with HASH characters for grouping purposes (to be replaced by more generic group similar feature)
my $durations_graph_width = 0;
my ( $graph_count, $graph_count_max, $max_graph_width ) = ( 1, 6, 0 );
my ( $graph_column_padding_all, $graph_column_padding_timestamp, $graph_column_padding_legend, $graph_column_padding_count, $graph_column_padding_other, $graph_column_padding_latency ) = ( 1, 1, 0, 2, 1, 3 );	# used to add padding (removed from width) in normalize data function
my %graph_width;
my $column_count_pre_graph = 2;		            # timestamp + legend is the default
my @graph_columns = qw( duration bytes count );
my ( @printed_column_widths, @printed_column_spacing, @printed_column_names );
my ( @populated_graph_columns, @graph_threadpools_activity, @graph_user_defined_metrics );
my ( $print_durations, $track_memory ) = ( 0, 0 );
my ( $filter_duration_min, $filter_duration_max );
my ( $filter_bytes_min, $filter_bytes_max );
my ( $filter_count_min, $filter_count_max );
my $top_n_messages = 10;
my ( $write_messages_to_csv, $csv, $csv_fh, $csv_file_args ) = ( 0, undef, undef, "" );
my $total_lines_read = 0;
my $total_lines_included = 0;
my @progress_history = ();                                                      # rolling history for lines/sec calculation: [ [timestamp, lines_read], ... ]
my $total_lines_highlighted = 0;
my $legend_length = 0;
my $timestamp_length = 0;
my $filter_range_start = "";
my $filter_range_end = "";
my $filter_range_start_epoch = 0;
my $filter_range_end_epoch = 0;
my %filter_range_epoch = ( 'start' => 0, 'end' => 2521843200 );
my %result_range_epoch = ( 'start' => 0, 'end' => 2521843200 );
my %filter_range;
my $output_timestamp_format = "%Y-%m-%d %H:%M";
my $output_timestamp_min = 0;
my $output_timestamp_max = 0;
my( $exclude_regex, $include_regex, $highlight_regex, $threadpool_activity_regex, $user_defined_metrics, $user_defined_metrics_regex, $user_defined_metrics_pre_regex, $user_defined_metrics_post_regex );

# Pattern file filter options (Issue #19)
my (@include_files, @exclude_files, @highlight_files);   # File paths from command line (arrays for multiple files)
my $verbose = 0;                                         # Verbose mode flag (-V)
my $pattern_file_max_size = 10 * 1024;                   # 10KB file size limit
my $pattern_file_max_patterns = 1000;                    # Max patterns per file (warn if exceeded)
my $pattern_regex_max_length = 10240;                    # 10KB regex length warning threshold
my %pattern_file_status;                                 # {filter_type}{filename} => { status => 'ok'|'empty'|'error', count => N }

# Duration unit override (Issue #17)
my $duration_unit_override = undef;                      # User-specified unit via -du (ns, us, ms, s)

my $pause_output = 0;
my $omit_values = 0;
my ( $sort_type, $sort_key, $sort_ascending ) = ( "occurrences", "occurrences", 0 );
my ( $group_similar_sensitivity, $trend_value ) = ( "none" );
my ( @in_files, @output_columns );
my %in_files_matched;
my ($terminal_width, $terminal_height);
{
    local *STDERR;
    open(STDERR, '>', '/dev/null') or open(STDERR, '>', 'NUL');
    ($terminal_width, $terminal_height) = eval { GetTerminalSize() };
}
if ($@ || !$terminal_width) {
    ($terminal_width, $terminal_height) = (120, 24);
}
my %timestamp_cache;

# Heatmap data structures
my $heatmap_enabled = 0;                    # Flag: heatmap mode active
my $heatmap_metric;                         # Metric: duration|bytes|count (undef until set by CLI)
my $heatmap_width = 52;                     # Number of histogram buckets (default matches latency stats width)
my $heatmap_light_bg = 0;                   # Flag: use light background color gradients (set by -lbg or auto-detect)
my $heatmap_light_bg_auto = 1;              # Flag: auto-detect terminal background (disabled if -lbg explicitly set)
my %heatmap_data;                           # {$bucket}{$range_index} = count
my %heatmap_data_hl;                        # {$bucket}{$range_index} = highlighted count
my %heatmap_raw;                            # {$bucket} = [raw values] - temporary
my %heatmap_raw_hl;                         # {$bucket} = [highlighted raw values] - temporary
my @heatmap_boundaries;                     # Pre-calculated bucket boundaries
my ($heatmap_min, $heatmap_max) = (undef, undef);   # Global min/max for normalization (undef = not yet set)
my $heatmap_max_density = 0;                # Maximum density across all cells
my %heatmap_percentiles;                    # {$bucket} = { p50 => index, p95 => index, p99 => index, p999 => index } - percentile marker positions

# Heatmap color gradients (8 steps from dim to bright)
# Index 0 = lowest density (dim), Index 7 = highest density (bright)
# Dark background gradients: visible colors only (no near-black grays)
my %heatmap_colors = (
    'yellow'  => [58, 94, 136, 142, 178, 184, 220, 226],     # Duration (column 2)
    'green'   => [22, 28, 34, 40, 46, 82, 118, 154],         # Bytes (column 3)
    'cyan'    => [23, 30, 37, 44, 51, 80, 86, 123],          # Count (column 4)
    'blue'    => [17, 18, 19, 20, 21, 27, 33, 39],           # Future metrics
    'magenta' => [53, 89, 125, 161, 162, 163, 199, 200],     # Future metrics
    'red'     => [52, 88, 124, 160, 196, 197, 203, 209],     # Future metrics
    'white'   => [238, 240, 242, 244, 246, 248, 252, 255],   # Future metrics
);

# Light background gradients: fade from light/pale shades to bright saturated color
my %heatmap_colors_light = (
    'yellow'  => [230, 229, 228, 227, 220, 214, 208, 202],   # Duration: pale yellow to saturated
    'green'   => [194, 157, 120, 84, 48, 42, 36, 35],        # Bytes: pale green to saturated
    'cyan'    => [195, 159, 123, 87, 51, 44, 37, 30],        # Count: pale cyan to saturated
    'blue'    => [189, 153, 117, 81, 45, 39, 33, 27],        # Future: pale blue to saturated
    'magenta' => [225, 219, 213, 207, 201, 165, 129, 93],    # Future: pale magenta to saturated
    'red'     => [224, 218, 212, 206, 200, 196, 160, 124],   # Future: pale red to saturated
    'white'   => [255, 254, 253, 250, 247, 244, 241, 238],   # Future: white to gray
);

# Map metric names to column numbers and colors
my %heatmap_metric_map = (
    'duration' => { column => 2, color => 'yellow' },
    'bytes'    => { column => 3, color => 'green' },
    'count'    => { column => 4, color => 'cyan' },
);

# Defines the log level/type buckets and their order for printing and processing
my @log_levels = (
    'FORCE-HL', 'FORCE',
    'ERROR-HL', 'ERROR', 'WARN-HL', 'WARN', 'INFO-HL', 'INFO', 
    'DEBUG-HL', 'DEBUG', 'TRACE-HL', 'TRACE', '5xx-HL', '5xx', 
    '4xx-HL', '4xx', '3xx-HL', '3xx', '2xx-HL', '2xx', '1xx-HL', 
    '1xx', 'Pause Young-HL', 'Pause Young', 'Pause Full-HL', 'Pause Full',
    'err-rate', 'msg-rate', 'empty'
);

# Characters selected and usable for drawing the bar charts
my %blocks = (
    'A' => '█',    # Full block
    'B' => '▓',    # Heavy shading
    'C' => '▒',    # Medium shading
    'D' => '░',    # Light shading
    'E' => '▪',    # Black Square
    'F' => '▫',    # White Square
    'G' => '☰',    # Menu
    'H' => '•',    # Bullet Point
    'I' => '■',    # Black Very Heavy
    'J' => '□'     # White square
);

my $default_chart_block = "A";

# Load in ANSI color codes and configure presets for various log levels/types
my %colors = (
    'FORCE' => "\033[0;35m",
    'ERROR' => "\033[0;31m",
    'WARN'  => "\033[0;33m",
    'INFO'  => "\033[0;32m",
    'DEBUG' => "\033[0;34m",
    'TRACE' => "\033[0;35m",
    '1xx'  => "\033[0;34m",
    '2xx'  => "\033[0;32m",
    '3xx'  => "\033[0;35m",
    '4xx'  => "\033[0;33m",
    '5xx'  => "\033[0;31m",
    'Pause Young' => "\033[0;35m",
    'Pause Full' => "\033[0;31m",
    'err-rate' => "\033[91m\033[109m",
    'msg-rate'    => "\033[0m",
    'NC'    => "\033[0m",
    'black' => "\033[30m\033[49m",
    'red' => "\033[0;31m",
    'green'  => "\033[0;32m",
    'yellow'  => "\033[0;33m",
    'blue'  => "\033[0;34m",
    'magenta' => "\033[35m\033[49m",
    'cyan' => "\033[36m\033[49m",
    'white' => "\033[36m\033[37m",
    'bright-black' => "\033[90m\033[109m",
    'bright-red' => "\033[91m\033[109m",
    'bright-green' => "\033[92m\033[109m",
    # 'bright-yellow' => "\033[93m\033[109m",
    'bright-yellow' => "\033[93m",
    'bright-blue' => "\033[94m\033[109m",
    'bright-magenta' => "\033[95m\033[109m",
    # 'bright-cyan' => "\033[96m\033[109m",
    'bright-cyan' => "\033[96m",
    'bright-white' => "\033[97m\033[109m",
    'black-underline' => "\033[4;30m",
    'red-underline' => "\033[4;31m",
    'green-underline' => "\033[4;32m",
    'yellow-underline' => "\033[4;33m",
    'blue-underline' => "\033[4;34m",
    'magenta-underline' => "\033[4;35m",
    'cyan-underline' => "\033[4;36m",
    'white-underline' => "\033[4;37m"
);

# Standard 8 Colors: Uses codes like \e[30m for black, \e[31m for red, etc.
# Bright 8 Colors: Uses codes like \e[90m for bright black (grey), \e[91m for bright red, etc.
# 256 Colors: Uses codes like \e[38;5;<color_code>m for foreground and \e[48;5;<color_code>m for background.
# True Color (24-bit): Uses codes like \e[38;2;<r>;<g>;<b>m for foreground and \e[48;2;<r>;<g>;<b>m for background.

# Dynamically create new keys with -HL for highlighted versions of each color
foreach my $key (keys %colors) {
    next if $key eq 'NC';
    my $new_key = "$key-HL";
    my $original_fg_color = $colors{$key};
    $original_fg_color =~ s/^\e\[(.*?)m/$1/g;

    my $bg_color_256;
    my $has_background = 0;
    if ($original_fg_color eq "0;31") {    # Red
        $bg_color_256 = "196";            # 256-color code for Red
        $has_background = 1;
    } elsif ($original_fg_color eq "0;33") { # Yellow
        $bg_color_256 = "226";            # 256-color code for Yellow
        $has_background = 1;
    } elsif ($original_fg_color eq "0;32") { # Green
        $bg_color_256 = "46";             # 256-color code for Green
        $has_background = 1;
    } elsif ($original_fg_color eq "0;34") { # Blue
        $bg_color_256 = "21";             # 256-color code for Blue
        $has_background = 1;
    } elsif ($original_fg_color eq "0;35") { # Magenta
        $bg_color_256 = "201";            # 256-color code for Magenta
        $has_background = 1;
    }

    $colors{$new_key} = $has_background ? "$colors{$key}\033[48;5;${bg_color_256}m" : "$colors{$key}\033[49m";       # allows specifying background for some highlighted colors only
}

## SUBS ##

sub print_title {
    my $title = <<"END";
\033[0;37m \033[90m\033[109m
──────────────────────────────────────────────────────────────────────────────────────────────
   ,:: ltl ::' log timeline [$version_number] --  by Greg Eva // geva\@ptc.com // gregeva\@gmail.com
──────────────────────────────────────────────────────────────────────────────────────────────
\033[0m
END
    print $title;
    return;
}

sub print_usage {
    my ( $error_reason ) = @_;
    print "Usage: $0 [--bucket-size|-bs <time block>] [--pause|-p] [--start|-st <YYYY-MM-DD HH:MM:SS>] [--end|-et <HH:MM>] [--exclude|-e <RegEx>] [--include|-i <RegEx>] [--highlight|-h <RegEx>] [--exclude-file|-ef <file>] [--include-file|-if <file>] [--highlight-file|-hf <file>] [--verbose|-V] [--heatmap|-hm [duration|bytes|count]] [--heatmap-width|-hmw <N>] [--light-background|-lbg] [--seconds|-s] [--milliseconds|-ms] [--output-csv|-o] [--omit-values|-ov] [--omit-stats|-os] [--omit-empty|-oe] [--omit-summary|-osum] [--omit-rate|-or] [--omit-durations|-od] [--omit-bytes|-ob] [--omit-count|-oc] [--include-count|-ic] [--include-query-string|-iqs] [--include-session|-is] [--duration-min|-dmin <value>] [--duration-max|-dmax <value>] [--duration-unit|-du <ns|us|ms|s>] [--bytes-min|-bmin <value>] [--bytes-max|-bmax <value>] [--count-min|-cmin <value>] [--count-max|-cmax <value>] [--sort-on|-so occurrences/total,duration/time,min,mean/avg,max,stddev,bytes,count,count_min,count_mean/count_avg,count_max,count_occurrences/count_total,impact,cv] [--sort-ascending|-sa] [--threadpool-activity-summary|-tpas] [--threadpool-activity|-tpa <RegEx>] [--mask-uuid|-uuid] [--version|-v] <file1> <file2> ...\n";

    print "\n  $colors{'red'}Error: $error_reason$colors{'NC'}\n\n" if defined $error_reason;
    return;
}

sub print_version {
    print "Version: $version_number\n\n";
    return;
}

# Pattern file functions (Issue #19)
sub read_pattern_file {
    my ($filename, $filter_type) = @_;
    my @patterns;

    # Use File::Spec for cross-platform path handling
    my $canonical_filename = File::Spec->canonpath($filename);

    # Validate file exists
    unless (-e $canonical_filename) {
        print STDERR "Warning: Pattern file not found: $filename\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'error', count => 0 };
        return ();
    }

    # Check file size
    my $size = -s $canonical_filename;
    if ($size > $pattern_file_max_size) {
        print STDERR "Warning: Pattern file exceeds maximum size (10KB): $filename\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'error', count => 0 };
        return ();
    }

    # Check for binary (null bytes in first 8KB)
    my $fh;
    unless (open $fh, '<:raw', $canonical_filename) {
        print STDERR "Warning: Cannot read pattern file: $filename ($!)\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'error', count => 0 };
        return ();
    }
    my $header;
    read($fh, $header, 8192);
    if (defined $header && $header =~ /\x00/) {
        close $fh;
        print STDERR "Warning: Pattern file appears to be binary: $filename\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'error', count => 0 };
        return ();
    }
    close $fh;

    # Read file as text
    unless (open $fh, '<:encoding(UTF-8)', $canonical_filename) {
        print STDERR "Warning: Cannot read pattern file: $filename ($!)\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'error', count => 0 };
        return ();
    }
    while (<$fh>) {
        s/\r?\n$//;               # Remove line endings (handles LF, CRLF)
        next if /^#/;             # Skip comment lines
        next if /^$/;             # Skip empty lines
        next if /^\s+$/;          # Skip whitespace-only lines
        # Whitespace within content is preserved - no trimming
        push @patterns, $_;
    }
    close $fh;

    if (@patterns == 0) {
        print STDERR "Warning: Pattern file is empty: $filename\n";
        $pattern_file_status{$filter_type}{$filename} = { status => 'empty', count => 0 };
        return ();
    }

    # Warn if pattern count exceeds limit (but use all patterns)
    if (@patterns > $pattern_file_max_patterns) {
        print STDERR "Warning: Pattern file contains " . scalar(@patterns) .
                     " patterns (exceeds recommended limit of $pattern_file_max_patterns): $filename\n";
    }

    $pattern_file_status{$filter_type}{$filename} = { status => 'ok', count => scalar(@patterns) };
    return @patterns;
}

sub build_merged_regex {
    my ($cli_regex, @file_patterns) = @_;

    # Escape file patterns using quotemeta
    my @escaped = map { quotemeta($_) } @file_patterns;

    # Build merged regex
    my $file_regex = join('|', @escaped);

    my $merged;
    if (defined $cli_regex && $cli_regex ne '') {
        $merged = "$cli_regex|$file_regex";
    } else {
        $merged = $file_regex;
    }

    # Warn if merged regex exceeds length threshold
    if (length($merged) > $pattern_regex_max_length) {
        print STDERR "Warning: Merged regex pattern is " . length($merged) .
                     " characters (exceeds recommended limit of $pattern_regex_max_length)\n";
    }

    return $merged;
}

sub get_pattern_file_indicator {
    my ($filter_type, $filename) = @_;
    return '' unless exists $pattern_file_status{$filter_type}{$filename};
    my $status = $pattern_file_status{$filter_type}{$filename}{status};
    return '' if $status eq 'ok';
    return '!' if $status eq 'empty';
    return '!!' if $status eq 'error';
    return '';
}

# Duration unit autodetection functions (Issue #17)
sub convert_duration_to_ms {
    my ($value, $unit) = @_;
    return undef unless defined $value;
    return $value * 1000         if $unit eq 's';
    return $value                if $unit eq 'ms';
    return $value / 1000         if $unit eq 'us';
    return $value / 1000000      if $unit eq 'ns';
    return $value;  # default: assume milliseconds
}

sub detect_light_terminal_background {
    # Detect if terminal has a light background using OSC 11 query
    # Returns 1 if light background detected, 0 otherwise
    # Uses xterm-compatible escape sequence: \e]11;?\e\\
    # Terminal responds with: \e]11;rgb:RRRR/GGGG/BBBB\e\\
    #
    # References:
    # - https://jwodder.github.io/kbits/posts/term-fgbg/
    # - https://dystroy.org/blog/terminal-light/
    #
    # Note: On Windows, OSC 11 query is not reliably supported (only works in
    # Windows Terminal 1.22+, not in legacy conhost or cmd.exe). The stty command
    # used for terminal raw mode is also Unix-only. Users on Windows should use
    # the -lbg flag explicitly if they have a light background terminal.

    # Skip auto-detection on Windows - use -lbg flag instead
    return 0 if $^O eq 'MSWin32';

    return 0 unless -t STDIN && -t STDOUT;  # Only works on interactive terminals

    my $response = '';
    my $is_light = 0;

    eval {
        # Save terminal settings
        my $old_settings = `stty -g 2>/dev/null`;
        chomp $old_settings if $old_settings;

        # Set terminal to raw mode with timeout
        system('stty', '-icanon', '-echo', 'min', '0', 'time', '1') == 0 or die "stty failed";

        # Send OSC 11 query (background color)
        # Using BEL (0x07) as terminator for wider compatibility
        print STDOUT "\e]11;?\a";
        STDOUT->flush();

        # Read response with timeout (using select)
        my $rin = '';
        vec($rin, fileno(STDIN), 1) = 1;

        my $timeout = 0.1;  # 100ms timeout
        my $start = time();

        while ((time() - $start) < $timeout) {
            if (select(my $rout = $rin, undef, undef, 0.01)) {
                my $char;
                if (sysread(STDIN, $char, 1)) {
                    $response .= $char;
                    # Response ends with BEL (0x07) or ST (\e\\)
                    last if $response =~ /\a$/ || $response =~ /\e\\$/;
                }
            }
        }

        # Restore terminal settings
        system('stty', $old_settings) if $old_settings;

        # Parse response: expect format like \e]11;rgb:RRRR/GGGG/BBBB\a
        if ($response =~ /rgb:([0-9a-fA-F]+)\/([0-9a-fA-F]+)\/([0-9a-fA-F]+)/) {
            my ($r, $g, $b) = ($1, $2, $3);

            # Normalize to 0-1 range (values can be 2 or 4 hex digits)
            my $max_val = (length($r) == 4) ? 65535 : 255;
            my $r_norm = hex($r) / $max_val;
            my $g_norm = hex($g) / $max_val;
            my $b_norm = hex($b) / $max_val;

            # Calculate luma (perceived brightness)
            # Using ITU-R BT.709 coefficients
            my $luma = 0.2126 * $r_norm + 0.7152 * $g_norm + 0.0722 * $b_norm;

            # Light background if luma > 0.5
            $is_light = ($luma > 0.5) ? 1 : 0;
        }
    };

    # If anything fails, default to dark background (0)
    return $is_light;
}

sub get_memory_usage {
    my $memory_usage;

    if ($^O eq 'darwin' || $^O eq 'linux') {                    # For Mac OS and Debian (Linux)
        eval {
            require Proc::ProcessTable;
            my $t = Proc::ProcessTable->new();
            ($memory_usage) = map { $_->rss } grep { $_->pid == $$ } @{$t->table};
        };
        if ($@) {
            die "Failed to load Proc::ProcessTable: $@";
        }
    } elsif ($^O eq 'MSWin32') {                                # For Windows
        eval {
            require Win32::Process::Info;
            Win32::Process::Info->import();  # Explicitly call import
            my $pi = Win32::Process::Info->new();
            my $info = $pi->GetProcInfo();
            ($memory_usage) = map { $_->{WorkingSetSize} } grep { $_->{ProcessId} == $$ } @$info;
        };
        if ($@) {
            die "Failed to load Win32::Process::Info: $@";
        }
    } else {
        die "Unsupported operating system: $^O";
    }

    return $memory_usage;
}

sub convert_bytes {
    my ($input_value, $input_unit) = @_;
    my ($value, $unit);

    if( defined( $input_unit ) ) {
        $value = $input_value;
        $unit = $input_unit;
    } else {
        ( $value, $unit ) = $input_value =~ /^(\d+)[ ]?(\w+)$/;
    }

    my %units = (
        'B'  => 1,
        'b'  => 1,
        'kB' => 1024,
        'KB' => 1024,
        'k' => 1024,
        'K' => 1024,
        'MB' => 1024**2,
        'M' => 1024**2,
        'GB' => 1024**3,
        'G' => 1024**3,
        'TB' => 1024**4,
        'T' => 1024**4,
    );

    my $bytes = $value * $units{$unit};

    return $bytes;
}

sub format_bytes {
    my ($value, $unit) = @_;
    my %units = (
        'b'  => 1,
        'B'  => 1,
        'kB' => 1024,
        'MB' => 1024**2,
        'GB' => 1024**3,
        'TB' => 1024**4,
    );

    return undef unless defined $value;

    my $bytes = $value * $units{$unit};
    my $bytes_int = int($bytes);  # Use integer for unit comparison to avoid float string length issues

    my @unit_order = ('B', 'kB', 'MB', 'GB', 'TB');
    my $formatted_value = $bytes;
    my $formatted_unit = 'B';

    foreach my $u (@unit_order) {                                           # Determine the most relevant unit
        if( length( $bytes_int ) >= length( $units{$u} ) ) {
# TO DO: 1000kB should convert to MB
        #if ($bytes >= $units{$u}) {
            $formatted_value = $bytes / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    $formatted_value = sprintf("%.1f", $formatted_value);
    $formatted_value =~ s/\.[0]+(\s|\w|$)/$1/;                                                        # remove trailing .0 if present

    return "$formatted_value $formatted_unit";
}

sub format_number {
    my ($value, $space, $decimals) = @_;
    my %units = (
        '1'  => 1,
        'k' => 1000,
        'Mil' => 1000**2,
        'Bil' => 1000**3,
        'Tril' => 1000**4,
    );

    my @unit_order = ('1', 'k', 'Mil', 'Bil', 'Tril');
    my $formatted_value = $value;
    my $formatted_unit = '';
    $decimals = 1 if !defined $decimals;

    foreach my $u (@unit_order) {                                                                   # Determine the most relevant unit
        if ($value >= $units{$u}) {
            $formatted_value = $value / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    $formatted_value = sprintf("%.${decimals}f%s%s", $formatted_value, defined($space) ? " " : "", $formatted_unit eq "1" ? "" : $formatted_unit );
    $formatted_value =~ s/\.[0]+(\s|\w|$)/$1/;                                                        # remove trailing .0 if present

    return $formatted_value;
}

sub format_time {
    my ($value, $unit, $format, $space) = @_;
    my %units = (
        'us' => 1,                      # Microseconds
        'ms' => 1000,                   # Milliseconds
        's'  => 1000000,                # Seconds
        'm'  => 60 * 1000000,           # Minutes
        'h'  => 60 * 60 * 1000000,      # Hours
        'D'  => 24 * 60 * 60 * 1000000, # Days
    );

    my %unit_names = (
        'us' => { short => 'us', medium => 'usec', long => 'microseconds' },
        'ms' => { short => 'ms', medium => 'msec', long => 'milliseconds' },
        's'  => { short => 's',  medium => 'sec',      long => 'seconds' },
        'm'  => { short => 'm',  medium => 'min',      long => 'minutes' },
        'h'  => { short => 'h',  medium => 'hr',       long => 'hours' },
        'D'  => { short => 'd',  medium => 'day',      long => 'days' },
    );

    $format = "short" if !defined $format;

    my $microseconds = $value * $units{$unit};


    my @unit_order = ('us', 'ms', 's', 'm', 'h', 'D');
    my $formatted_value = $microseconds;
    my $formatted_unit = 'us';

    foreach my $u (@unit_order) {                                                           # Determine the most relevant unit
        if ($microseconds >= $units{$u}) {
            $formatted_value = $microseconds / $units{$u};
            $formatted_unit = $u;
        } else {
            last;
        }
    }

    $formatted_value = sprintf("%.1f", $formatted_value);
    $formatted_value =~ s/\.[0]+(\s|\w|$)/$1/;                                              # remove trailing .0 if present
    

    my $unit_name = $unit_names{$formatted_unit}{$format};                                  # Get the appropriate unit name based on format
    $unit_name =~ s/s$// if $formatted_value == 1 && $format eq 'long';                     # Singular units for long format
    $unit_name = " " . $unit_name if defined( $space );

    return defined $value ? "$formatted_value$unit_name" : undef;
}

# Utility function to visualize control characters as caret notation to show non-printable characters present in log messages
sub visualize_carets {
    my ($s) = @_;
    $s =~ s/([\x00-\x1F])/'^' . chr(ord($1) + 64)/eg;  # ^@ .. ^_
    $s =~ s/\x7F/^?/g;                                 # DEL
    return $s;
}

# utility function for formating numbers to normal format
sub normalize { $_[0] =~ s/\.0+$//r }

# utility functions for trimming spaces off of a string
sub ltrim { my $s = shift; $s =~ s/^\s+//; return $s }
sub rtrim { my $s = shift; $s =~ s/\s+$//; return $s }
sub trim  { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s }

sub adapt_to_command_line_options {
    @ORIGINAL_ARGV = @ARGV;

    GetOptions(
        'bucket-size|bs=i' => \$bucket_size_minutes,
        'pause|p' => \$pause_output,
        'start|st=s' => \$filter_range_start,
        'end|et=s' => \$filter_range_end,
        'exclude|e=s' => \$exclude_regex,
        'include|i=s' => \$include_regex,
        'highlight|h=s' => \$highlight_regex,
        'exclude-file|ef=s' => \@exclude_files,
        'include-file|if=s' => \@include_files,
        'highlight-file|hf=s' => \@highlight_files,
        'verbose|V' => \$verbose,
        'top-messages|n=i' => \$top_n_messages,
        'omit-values|ov' => \$omit_values,
        'omit-stats|os' => \$omit_stats,
        'omit-empty|oe' => \$omit_empty,
        'omit-summary|osum' => \$omit_summary,
        'omit-rate|or' => \$omit_rate,
        'omit-durations|od' => \$omit_durations,
        'omit-bytes|ob' => \$omit_bytes,
        'omit-count|oc' => \$omit_count,
        'include-count|ic' => \$include_count,
        'include-query-string|iqs' => \$include_query_string,
        'include-session|is' => \$include_session,
        'seconds|s' => \$print_seconds,
        'milliseconds|ms' => \$print_milliseconds,
        'version|v' => \$print_version,
        'duration-min|dmin=i' => \$filter_duration_min,
        'duration-max|dmax=i' => \$filter_duration_max,
        'duration-unit|du=s' => \$duration_unit_override,
        'bytes-min|bmin=i' => \$filter_bytes_min,
        'bytes-max|bmax=i' => \$filter_bytes_max,
        'count-min|cmin=i' => \$filter_count_min,
        'count-max|cmax=i' => \$filter_count_max,
	    'memory-usage|mem' => \$track_memory,
        'output-csv|o' => \$write_messages_to_csv,
        'sort-on|so=s' => \$sort_type,
        'sort-ascending|sa' => \$sort_ascending,
        'threadpool-activity-summary|tpas' => \$include_threadpool_summary,
        'threadpool-activity|tpa=s' => \$threadpool_activity_regex,
        'user-defined-metrics|udm=s' => \$user_defined_metrics,
        'mask-uuid|uuid' => \$mask_uuid,
        'group-similar|g=s' => \$group_similar_sensitivity,
        'heatmap|hm:s' => \$heatmap_metric,
        'heatmap-width|hmw=i' => \$heatmap_width,
        'light-background|lbg' => sub { $heatmap_light_bg = 1; $heatmap_light_bg_auto = 0; }
    ) or die print_usage( "required options not provided" );

    $filter_range{'start'} = $filter_range_start if defined( $filter_range_start );
    $filter_range{'end'} = $filter_range_end if defined(  $filter_range_end );

    # Heatmap option processing
    if (defined $heatmap_metric) {
        $heatmap_enabled = 1;
        # Handle case where -hm is followed by a filename (GetOptions captures it as optional value)
        if ($heatmap_metric eq '' || !grep { $_ eq $heatmap_metric } qw(duration time bytes count)) {
            # If the value doesn't match a valid metric, it's likely a filename
            # Push it back to @ARGV and use default metric
            if ($heatmap_metric ne '' && $heatmap_metric !~ /^(duration|time|bytes|count)$/) {
                unshift @ARGV, $heatmap_metric;
            }
            $heatmap_metric = 'duration';  # Default metric
        } elsif( $heatmap_metric =~ /^time$/i ) {
            $heatmap_metric = 'duration';  # time is allowed for consistency, but what is really meant is duration
        }

        # Auto-detect light terminal background if -lbg wasn't explicitly set
        if ($heatmap_light_bg_auto) {
            $heatmap_light_bg = detect_light_terminal_background();
        }
    }

    # Duration unit option validation (Issue #17)
    if (defined $duration_unit_override) {
        die print_usage("Invalid duration unit '$duration_unit_override'. Valid values: ns, us, ms, s")
            unless $duration_unit_override =~ /^(ns|us|ms|s)$/;
    }

    # Process pattern files (Issue #19) - supports multiple files per filter type
    foreach my $file (@include_files) {
        my @patterns = read_pattern_file($file, 'include');
        $include_regex = build_merged_regex($include_regex, @patterns) if @patterns;
    }
    foreach my $file (@exclude_files) {
        my @patterns = read_pattern_file($file, 'exclude');
        $exclude_regex = build_merged_regex($exclude_regex, @patterns) if @patterns;
    }
    foreach my $file (@highlight_files) {
        my @patterns = read_pattern_file($file, 'highlight');
        $highlight_regex = build_merged_regex($highlight_regex, @patterns) if @patterns;
    }

    # Verbose output (Issue #19)
    if ($verbose) {
        print "=== Verbose ===\n";
        print "include: " . (defined $include_regex ? $include_regex : "(not set)") . "\n";
        print "exclude: " . (defined $exclude_regex ? $exclude_regex : "(not set)") . "\n";
        print "highlight: " . (defined $highlight_regex ? $highlight_regex : "(not set)") . "\n";
        print "\n";
    }

    if( $print_version ) {
        print_version();
        exit;
    }

    foreach my $pattern (@ARGV) {									# do in process file globbing for common experience across environments (Windows doesn't glob in the shell, passes in the parameters)
        push @in_files, glob($pattern);
    }

	@in_files = grep { -f $_ } @in_files;								# only accept files in list to be read (remove anything else in the globbed directory list)

    die print_usage( "unable to open any files" ) unless @in_files;
    die print_usage( "invalid sort type used" ) unless grep { $_ eq $sort_type } qw( occurrences total duration time bytes size impact cv count count_occurrences count_total count_sum count_min count_mean count_avg count_max std_dev stddev min mean avg max);

    if( $sort_type =~ /^duration|time$/i ) {
        $sort_key = "total_duration_num";
    } elsif( $sort_type =~ /^min$/i ) {
        $sort_key = "min";
    } elsif( $sort_type =~ /^mean|avg$/i ) {
        $sort_key = "mean";
    } elsif( $sort_type =~ /^max$/i ) {
        $sort_key = "max";
    } elsif( $sort_type =~ /^std_dev|stddev$/i ) {
        $sort_key = "std_dev";
    } elsif( $sort_type =~ /^occurrences|total$/i ) {
        $sort_key = "occurrences";
    } elsif( $sort_type =~ /^bytes|size$/i ) {
        $sort_key = "total_bytes";
    } elsif( $sort_type =~ /^impact$/i ) {
        $sort_key = "impact";
    } elsif( $sort_type =~ /^cv$/i ) {
        $sort_key = "cv";
    } elsif( $sort_type =~ /^count_occurrences|count_total$/i ) {
        $sort_key = "count_occurrences";
    } elsif( $sort_type =~ /^count|count_sum$/i ) {
        $sort_key = "count_sum";
    } elsif( $sort_type =~ /^count_min$/i ) {
        $sort_key = "count_min";
    } elsif( $sort_type =~ /^count_mean|count_avg$/i ) {
        $sort_key = "count_mean";
    } elsif( $sort_type =~ /^count_max$/i ) {
        $sort_key = "count_max";
    }

    if( defined $user_defined_metrics ) {
        my $separator = qr/\s*[=:]?\s*/;
        #my $number = qr/-?\d{1,3}(?:[ ,]?\d{3})*(?:\.\d+)?/;								# Number pattern with optional negative, thousands separators, and decimals
        my $number = qr/-?\d+(?:\.\d+)?/;								# Number pattern with optional negative, thousands separators, and decimals
        $user_defined_metrics_regex = join( '|', split( ',', $user_defined_metrics ) );

        foreach my $user_metric ( split( ',', $user_defined_metrics ) ) {
            my $metric = quotemeta($user_metric);  # Escape special characters

            $user_defined_metrics_pre_regex .= qr/\s+$metric$separator(?<$metric>$number)/x;
            $user_defined_metrics_post_regex .= qr/(?<$metric>$number)$separator$metric\s+/x;
            #$user_defined_metrics_post_regex .= qr/(?<${metric}>-?\d+(?:\.\d+)?)\s*[=:]?\s*${metric}\s+/;
            #$user_defined_metrics_post_regex = qr/(?<rows>-?\d+(?:\.\d+)?)\s*[=:]?\s*rows/;


#            $user_defined_metrics_regex .= "${metric}[ =:](<${metric}>?[0-9.])";
        }

#print "udm: $user_defined_metrics\t\tudm regex: $user_defined_metrics_regex udm: metrics post regex: $user_defined_metrics_post_regex\n";

    }

    $output_timestamp_format .= ":%S" if $print_seconds || $print_milliseconds;
    #$bucket_size_seconds = $print_seconds ? $bucket_size_minutes : $bucket_size_minutes * 60;		# if they say they want milliseconds, we're going to assume that their bucket sizes are in seconds instead
    if( $print_seconds ) {
        $bucket_size_seconds = $bucket_size_minutes;
    } elsif( $print_milliseconds ) {
        $bucket_size_seconds = $bucket_size_minutes / 1000;
    } else {
        $bucket_size_seconds = $bucket_size_minutes * 60;
    }

    my %argv_hash = map { $_ => 1 } @ARGV;
    foreach my $arg (@ORIGINAL_ARGV) {
        unless (exists $argv_hash{$arg}) {
            $csv_file_args .= "$arg" if $write_messages_to_csv;
        }
    }

    return;
}

# Parse various possible formats for input of start and end times and set associated filter variables
sub calculate_start_end_filter_timestamps {
    my ( $log_time ) = @_;
    my $log_date = $log_time->epoch() - ( $log_time->hour * ( 60 * 60 ) + $log_time->minute * 60 + $log_time->second );

    foreach my $key (keys %filter_range) {
        my $value = $filter_range{$key};                                                        # Get the value (either $filter_range_start or $filter_range_end)
        next unless length( $filter_range{$key} ) > 0;
        my $epoch_value;  # Variable to store the epoch time

        # Convert timestamp to epoch seconds using Time::Piece -- WARNING -- use of strptime can cause timezone problems, it appears to work here as I've manually set TZ to UTC on input
        if ( $value =~ /^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{2}:\d{2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d %H:%M:%S" )->epoch;
        } elsif ( $value =~ /^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d %H:%M" )->epoch;
        } elsif ( $value =~ /^\d{4}-\d{1,2}-\d{1,2}/ ) {
            $epoch_value = Time::Piece->strptime( $value, "%Y-%m-%d" )->epoch;
        } elsif ( $value =~ /^\d{1,2}:\d{2}:\d{2}/ ) {
            $epoch_value = $log_date + Time::Piece->strptime( $value, "%H:%M:%S" )->epoch;
        } elsif ( $value =~ /^\d{1,2}:\d{2}/ ) {
            $epoch_value = $log_date + Time::Piece->strptime( $value, "%H:%M" )->epoch;
        } else {
            print "Warning: unhandled date/time format - option not taken into account\n";
        }

        $filter_range_epoch{$key} = $epoch_value if defined( $epoch_value );
    }
    return 1;
}

sub adapt_to_terminal_settings {
    $terminal_width //= 80;                                             # Default to 80 if terminal width cannot be determined
    $terminal_height //= 24;                                            # Default to 24 if terminal height cannot be determined

    # Auto-adjust the bucket size based on the terminal height (larger terminal can handle more rows)
    if( $terminal_height <= 30 ) {
        $bucket_size_minutes = 120;
    } elsif( $terminal_height <= 45 ) {
        $bucket_size_minutes = 90;
    } elsif( $terminal_height <= 65 ) {
        $bucket_size_minutes = 60;
    } elsif( $terminal_height <= 85 ) {
        $bucket_size_minutes = 30;
    } elsif( $terminal_height > 85 ) {
        $bucket_size_minutes = 10;
    } else {
        $bucket_size_minutes = 60;
    }

    $max_log_message_length = $terminal_width;		# this is the max that we can print without wrapping, depends on the summary table width, and terminal width 
    return;
}

sub pause_for_keypress {
    my ($prompt) = @_;                              # Get the optional prompt message
    $prompt = "Press any key to continue (or Q to quit)..." unless defined $prompt;
    print "\033[0;44m$prompt\033[0m";

    ReadMode 4;                                     # Turn off line buffering
    my $key = ReadKey(0);
    ReadMode 0;                                     # Restore normal input mode

    if (defined $key) {
        if ($key eq "q" || $key eq "Q") {
            print "\r";
            print " " x length( $prompt );
            print "\r\033[0;35mExiting program.\033[0m\n";
            exit 0;
        } else {
            print "\r";
            print " " x length( $prompt );
            print "\r";
            return 1;                               # Return a value indicating "continue"
        }
    } else {
        print "\r";
        print " " x length( $prompt );
        print "\r";
        return 1;
    }
}

# Parse logs, bucket by time, and count log levels
sub read_and_process_logs {
    %in_files_matched = map { $_ => 0 } @in_files;			# set hash key per file to match boolean = false

    foreach my $in_file (@in_files) {
        open my $fh, '<', $in_file or die "Cannot open file: $in_file";
        push @files_processed, $in_file;
        my $line_number = 0;
        my $filter_range_filter_initialized = 0;
        my %month_map = ( Jan => 1, Feb => 2, Mar => 3, Apr => 4, May => 5, Jun => 6, Jul => 7, Aug => 8, Sep => 9, Oct => 10, Nov => 11, Dec => 12 );
        my( $file_name ) = $in_file =~ /(.+)(\W\d{4,}).+$/;

        while (<$fh>) {
            s/[\r\n]+$//;                                   # Remove Windows line endings (CRLF) or Unix line endings (LF) if present
            $line_number++;
            my ( $timestamp_str, $log_level, $category_bucket, $category, $object, $instance, $user, $platform, $thread, $threadpool, $session, $message ) = ("") x 12;
            my ( $is_line_match, $is_access_log, $match_type, $status_code, $heap_from, $heap_to, $heap_size ) = ( 0, 0, 0, 0, 0, 0, 0 );
            my ( $bytes, $duration, $occurrences, $count ) = ( undef, undef, undef, undef );
            my ( $timestamp, $threadname );
            $total_lines_read++;

            if ($total_lines_read % 4999 == 0) {             # print progress based on total lines read (not per-file) to handle many small files
                my $now = Time::HiRes::time();
                push @progress_history, [ $now, $total_lines_read ];
                shift @progress_history if @progress_history > 50;          # keep last 50 samples for rolling average

                my $lines_per_sec = "";
                if (@progress_history >= 2) {
                    my $time_diff = $progress_history[-1][0] - $progress_history[0][0];
                    my $lines_diff = $progress_history[-1][1] - $progress_history[0][1];
                    if ($time_diff > 0) {
                        $lines_per_sec = " - " . format_number($lines_diff / $time_diff) . " lines/sec";
                    }
                }

                printf("\rProcessing line %d in file %s (%s overall%s)", $line_number, $in_file, format_number($total_lines_read), $lines_per_sec);
                $| = 1;                                     # Flush output to stdout
            }

            if ($track_memory && $line_number % 100000 == 0) {						    # only collect memory in use around every 100000 lines processed
                $current_memory_usage = get_memory_usage();								# track maximum memory usage
                if ($current_memory_usage > $max_memory_usage) {
                    $max_memory_usage = $current_memory_usage;
                }
            }

            ## ThingWorx Standard Log Format (ApplicationLog, ErrorLog, ScriptLog, ...) ##
            if ( ($timestamp_str, $category_bucket, $object, $instance, $user, undef, $platform, $thread, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3})[\+\-]\d{4} \[L: ([^\]]*)\] \[O: ([^\]]*)] \[I: ([^\]]*)] \[U: ([^\]]*)] \[S: ([^\]]*)] \[P: ([^\]]*)] \[T: ([^\]]*)] (.*)/) {
                $is_line_match = 1;
                $match_type = 1;			# this is matching ThingWorx standard log format 2025-02-04 12:05:57.481+0000 [L: DEBUG] 

                # this section is optional, for cases where log line has included additional context which should be interpretted (row count, execution duration, result size)
                ( $bytes ) = $message =~ / bytes\s*=\s*(\d+)/;								# 2025-04-22 remove the trailing whitespace as same as below
                ( $duration ) = $message =~ / durationM[sS]\s*=\s*(\d+)/;						# 2025-04-17 remove the trailing white space as it was not picking up the variable if it was at the end of the line
                $is_access_log = 1 if defined $bytes || defined $duration;
                $message =~ s/ ((bytes|durationM[sS])\s*=\s*)(\d+)/ $1?/g;		# mask out bytes and duration values for grouping purposes (but leave others for later processing)


# [elapsed 39ms]
#  [elapsed 20m 47s 399ms] Import completed successfully
# ApplicationLog.2025-04-29.135.log:2025-04-29 09:07:04.340+0000 [L: INFO] [O: c.t.c.ImportProcessor] [I: ] [U: Administrator] [S: ] [P: ] [T: https-jsse-nio-8443-exec-1] ***  [elapsed 20m 47s 399ms] Import completed successfully
#( $duration ) = $message =~ /\[elapsed (\d+)ms\]/;
#$message =~ s/\[elapsed (\d+)ms\]/\[duration ??ms\]/g;


# START TEMPORARY the following are temporary
                $message =~ s/(session id: )\d+/$1\?\?/g;
                $message =~ s/(\w+_)+\d{14}-/ModelFamily_CustomerPC_DateString-/g;
                
                $message =~ s/Successfully added for import \/.+$/Successfully added for import \/ThingworxStorage\/repository\/SystemRepository\/\.\.\./g;
                $message =~ s/Setting visibility permissions for (.+)$/Setting visibility permissions for \.\.\./g;
                $message =~ s/Ancestors for Entity(.+)$/Ancestors for Entity \.\.\./g;
                $message =~ s/input document: (.+)$/input document: \.\.\./g;
                $message =~ s/Transaction was successfully ended for request (.+)$/Transaction was successfully ended for request \.\.\./g;
                $message =~ s/Ending transaction for request (.+)$/Ending transaction for request \.\.\./g;
                $message =~ s/(TimerEventHandler|TimerThing)\@(\S+)/$1\@/g;
                $message =~ s/correspond to sent message (\S+) \]/correspond to sent message ###################### \]/g;
# END TEMPORARY

            ## ThingWorx Connection Server Standard Log Format ##
            } elsif ( ($timestamp_str, $thread, $category_bucket, $object, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \[([^\]]*)\] ([^ ]*)\s+([^ ]*) - (.*)/) {
                $is_line_match = 1;
                # for some reason needed to move this before other more generic patterns which shouldn't be matching this, or are valid
                $match_type = 10;                       # 2025-08-14 21:00:34.633 [vert.x-eventloop-thread-12] INFO  c.t.c.a.AlwaysOnHttpServerVerticle - Enabled fix for WebSocket compression sometimes causing frames to exceed maximum WebSocket frame size

                ( $duration ) = $message =~ / (\d+) milliseconds/;
                $message =~ s/ (\d+) milliseconds/ ? millseconds/g;

                $message =~ s/(from \d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:)\d{4,5} /${1}XXXXX /;	# remove the ephemeral port in order to group common messages
                $is_access_log = 1 if defined $bytes || defined $duration;

            ## Generic Java/Logback Pattern with timestamp and level ##
            } elsif ( ($timestamp_str, $category_bucket) = $_ =~ /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3})\+\d{4} \[L: ([^\]]*)\]/) {
                $is_line_match = 1;
                $match_type = 1;			# this is matching ThingWorx standard log format 2025-02-04 12:05:57.481+0000 [L: DEBUG] 

            ## ThingWorx Remote Access Client Log Format ##
            } elsif ( ($timestamp_str, $category_bucket ) = $_ =~ /^[\[]?(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}\.\d{3}).*? \[[L: ]*([^\]]*)\]/ ) {
                $is_line_match = 1;
                $match_type = 2;			# this is matching RAC client log format [2025-02-04T12:06:22.784] [TRACE]
                $timestamp_str =~ tr/T/ /;

            ## Apache Tomcat Access Log with CodeBeamer format for Service Execution Time in ms ([%Dms]) and seconds ([%Ts])  ##
            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, $duration, undef) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-)[ ]?\[([0-9.])ms\] \[(.+)s\]/ ) {
                $is_line_match = 1;
                $match_type = 12;			# matching Tomcat access log CodeBeamer format 192.168.223.1 - - [29/Oct/2025:08:52:11 +0000] "GET /urlversioned/202510290803/images/newskin/login_page/icon_qa.png HTTP/1.1" 200 20097 [5ms] [0.005s]

                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset
                undef $bytes if $bytes eq "-";

                $message =~ s/ HTTP\/\d\.\d$//;							# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;				# chop off the query string from the URI
                $message = "[$session] $message" if defined $session && $include_session;	# include session if we found it in the logs

            ## Apache Tomcat Access Log with Service Execution Time (%D), and optionally thread (%I) and session (%S) ##
            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, $duration, $thread, $session) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-)[ ]?([0-9.]+)?[ ]?(\S+)?[ ]?(\S+)?/ ) {
                $is_line_match = 1;
                $match_type = 3;			# this is matching Tomcat access log format with service execution time 43.52.82.172 - - [02/Feb/2025:00:00:11 +0000] "GET /Thingworx/Metrics?x-thingworx-session=false HTTP/1.1" 200 17626 295
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset
                undef $bytes if $bytes eq "-";

                $message =~ s/ HTTP\/\d\.\d$//;							# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;				# chop off the query string from the URI
                $message = "[$session] $message" if defined $session && $include_session;	# include session if we found it in the logs

            ## Apache Tomcat Standard/Common Access Log Format ##
            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+|-)$/ ) {    # added $ to end to differentiate from later pattern
                $is_line_match = 1;
                $match_type = 4;			# this is matching Tomcat access log format with service execution time 43.52.82.172 - - [02/Feb/2025:00:00:11 +0000] "GET /Thingworx/Metrics?x-thingworx-session=false HTTP/1.1" 200 17626
                					# this is matching Nginx ingress access log format 3.133.31.181 - - [18/Nov/2024:14:19:55 +0000] "GET / HTTP/1.1" 404 431 "-" "WizDynamicScanner/1.0"
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset
                undef $bytes if $bytes eq "-";

                $message =~ s/ HTTP\/\d\.\d$//;					# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;		# chop off the query string from the URI
# TO DO - update RegEx to pull out message, thread name (2025-04-23 not sure what this implies as match type 3 picks up thread name and session if present)

            ## ThingWorx Connection Server JSON Formatted Logs ##
            } elsif ( ($timestamp_str, $category_bucket) = $_ =~ /^{"\@timestamp":"([^"]*).*"level":"([^"]*)/ ) {
                $is_line_match = 1;
                $match_type = 5;			# this matches Connection Server JSON formatted logs : {"@timestamp":"2025-02-02T21:03:06.725+00:00","@version":1,"message":"Error encountered, closing WebSocket: endpointId=2608459","logger_name":"com.thingworx.connectionserver.alwayson.AbstractClientEndpoint","thread_name":"vert.x-eventloop-thread-16","level":"WARN","level_value":30000,"stack_trace":"io.vertx.core.http.HttpClosedException: Connection was closed\n"}
                $timestamp_str =~ s/\+\d{2}:\d{2}$//;	# chop off the timezone offset
                $timestamp_str =~ tr/T/ /;
# TO DO: Pull out thread name

            ## Java 11 GC Log Format with Timestamps Enabled ##
            } elsif ( ( $timestamp_str, $category_bucket, $message, $heap_from, $heap_to, $heap_size, $duration ) = $_ =~ /^[\[]?(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}\.\d{3})[+-]\d{4}.*?\[info\]\[gc\s*\] GC\(\d+\) (.+?) (\(.+?\)) (\d[^-]+)->(\d[^(]+)\((\d[^)]+)\) (\d.*)ms/ ) {
                $is_line_match = 1;
                $match_type = 6;			# this matches Java GC log info level pause
                $is_access_log = 1;			# need this to have statistics calculated
                $default_chart_block = 'C' unless $default_chart_block ne 'C';

                $bytes = convert_bytes( $heap_from ) - convert_bytes( $heap_to );
                $bytes = $bytes < 0 ? 0 : $bytes;

            ## ThingWorx Analytics Log Formats ##
            } elsif ( ( $category_bucket, $timestamp_str, $message ) = $_ =~ /^([^ ]+)\s+\[(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[.,]\d{3})\] (.*)$/ ) {  
            # adaptor     # ERROR [2025-02-19 18:31:00,284] com.thingworx.sdk.impl.transport.netty.NettyChannelHandler: [ClientHandler: 76b37675] WebSocket error: An existing connection was forcibly closed by the remote host, closing connection!
            # sync        # INFO  [2025-02-20 04:49:11,450] org.ehcache.core.EhcacheManager: Cache 'scorefunc_cachex' created in EhcacheManager.
            # async       # WARN  [2025-02-19 18:30:01,437] org.apache.zookeeper.ClientCnxnSocketNetty: future isn't success.
                $is_line_match = 1;
                $match_type = 7;			# this matches ThingWorx Analytics V2 types for adaptor, sync, async
                $timestamp_str =~ tr/,/./;
                $timestamp_str =~ tr/T/ /;
                $message =~ s/\s+$//g;

            } elsif ( ( $timestamp_str, $thread, $category_bucket, $message ) = $_ =~ /^(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[^ ]*)\s+\[([^]]+)\]\s+(\w+)\s+(.*)$/ ) {  
            # worker      # 2025-02-20 10:06:10 [nioEventLoopGroup-2-1] WARN  io.netty.channel.ChannelInitializer - Failed to initialize a channel. Closing: [id: 0x8171dc41]
                $is_line_match = 1;
                $match_type = 8;			# this matches ThingWorx Analytics worker type
                $timestamp_str =~ tr/,/./;
                $timestamp_str =~ tr/T/ /;
                $message =~ s/\s+$//g;

            } elsif ( (undef, $timestamp_str, $message, $category_bucket, $bytes, undef, undef, $duration) = $_ =~ /^(.+? ){3}[\[]([^\]]+)[\]] "([^"]+)" (\d{3}) (\d+) "([^"]+)" "([^"]+)" (\d+)$/ ) {
            # access logs # 127.0.0.1 - - [13/Mar/2025:09:02:41 +0000] "GET /async/prediction/evaluation?limit=99999 HTTP/1.1" 200 51 "-" "Jersey/2.37 (HttpUrlConnection 11.0.22)" 651
                $is_line_match = 1;
                $match_type = 9;			# this is matching Jboss access log format with service execution time 127.0.0.1 - - [13/Mar/2025:09:02:41 +0000] "GET /async/prediction/evaluation?limit=99999 HTTP/1.1" 200 51 "-" "Jersey/2.37 (HttpUrlConnection 11.0.22)" 651
                $is_access_log = 1;
                $status_code = $category_bucket;
                $category_bucket =~ s/(\d)\d{2}/$1xx/;	# bucket HTTP status codes into their primary families
                $timestamp_str =~ s/ \+\d{4}$//;	# chop off the timezone offset

                $message =~ s/ HTTP\/\d\.\d$//;					# chop off the HTTP protocol and version
                $message =~ s/\?.+$// unless $include_query_string;		# chop off the query string from the URI

            } elsif ( ( $category_bucket, $timestamp_str, $message ) = $_ =~ /^([^ ]+) (\d{4}-\d{2}-\d{2} \d{1,2}:\d{2}:\d{2}[,.]\d+) (.*)/ ) {  
                $is_line_match = 1;
                $match_type = 11;			# this is matching ThingWorx Edge C SDK format # FORCE 2025-08-09 18:27:18,40 8012 twx_connection.cpp:246 Run Error in the TWX processor thread, have to reinitialize. Error was [sdk_wrapper_->IsConnected() failed]
                chop $message;

                # INFO 2025-08-09 18:19:04,479 libremotesession::RemoteConnectionManager::ReloadAllowList : Attempting to load the allowlist.
                # INFO 2025-08-09 18:19:04,479 8012 change_notification_source.cpp:11 OnProvisioningChanged provisioning change update received
                # ERROR 2025-08-09 18:27:18,38 TW_SSL_READ: Error reading from SSL stream
                # WARN 2025-08-09 18:19:04,729 getCurrentPropertyValuesForEachHandler -  startType parameter is missing but optional. Assumed to be useDefaultValue
                # INFO 2025-08-09 18:27:18,128 8012 twx_app_executor.cpp:83 Detach Detach requested

                $message =~ s/\d+ (.*)$/$1/;			# remove process ID if log messages contains it
                if( $message =~ /\w+\.cpp:\d+ / ) {
                    $message =~ s/(\w+\.cpp:\d+) (.*)$/$2/;
                    $object = $1;
                }
            
            }

            ## COUNT METRICS # capture count metrics unless explicitly omitted
            if( !$omit_count && defined $message ) {
                ( $count ) = $message =~ / count\s*=\s*(\d+)/;
                if( defined $count ) {
                    $message =~ s/ count\s*=\s*\d+/ count=?/g;                  # mask out actual count values for grouping purposes
                    $is_access_log = 1;
                }
            }

            ## THREAD POOL # populate if thread name was found
            if( defined $thread && $thread ne "" ) {
                ( $threadpool ) = $thread =~ /(.*)-\d+$/;
                $threadname = defined $threadpool ? $threadpool : $thread;
            }

            ## USER DEFINED METRICS CAPTURE ##
            if( defined $user_defined_metrics && /$user_defined_metrics_regex/ ) {
                if( /$user_defined_metrics_post_regex/g ) {
                    foreach my $user_metric ( split( ',', $user_defined_metrics ) ) {
                        my $metric = quotemeta( $user_metric );
                        my $regex = qr/(?<$metric>-?\d+(?:\.\d+)?)\s*[=:]?\s*$metric\s+/x;
                    #foreach my $metric ( keys %+ ) {
                        my $value = defined $+{$metric} ? normalize( $+{$metric} ) : "N/A"; 
                        print "$metric=$value ";
                    }
                }
            }

            if( $is_line_match ) {
                $bytes = 0 if( defined( $bytes ) && $bytes < 0 );

                # Duration unit conversion (Issue #17) - convert to milliseconds if user specified a unit
                if (defined $duration && defined $duration_unit_override) {
                    $duration = convert_duration_to_ms($duration, $duration_unit_override);
                }

                $timestamp_str =~ s/(:\d{2}:\d{2})\.\d{3}/$1/;                      # remove the milliseconds if present, as the code does not presently support them

                unless (grep { $_ eq $category_bucket } @log_levels) {				# this condition importantly only continues if the read/parsed log category is one of the ones defined
                    next;
                } elsif( $match_type == 1 || $match_type == 2 || $match_type == 5 || $match_type == 6 || $match_type == 7 || $match_type == 8 || $match_type == 10 || $match_type == 11 ) {
                    if (exists $timestamp_cache{$timestamp_str}) {
                        $timestamp = $timestamp_cache{$timestamp_str};
                    } else {
                        $timestamp = DateTime->new(
                            year      => substr($timestamp_str, 0, 4),
                            month     => substr($timestamp_str, 5, 2),
                            day       => substr($timestamp_str, 8, 2),
                            hour      => substr($timestamp_str, 11, 2),
                            minute    => substr($timestamp_str, 14, 2),
                            second    => substr($timestamp_str, 17, 2),
                            time_zone => 'UTC',
                        );
                        $timestamp_cache{$timestamp_str} = $timestamp;
                    }
                } elsif( $match_type == 3 || $match_type == 4 || $match_type == 9 || $match_type == 12 ) {
                    if (exists $timestamp_cache{$timestamp_str}) {
                        $timestamp = $timestamp_cache{$timestamp_str};
                    } else {
                        my ($day, $month_str, $year, $hour, $minute, $second) = $timestamp_str =~ m/(\d{2})\/([A-Za-z]+)\/(\d{4}):(\d{2}):(\d{2}):(\d{2})/;
                        my $month = $month_map{$month_str};
                        $timestamp = DateTime->new(
                            year      => $year,
                            month     => $month,
                            day       => $day,
                            hour      => $hour,
                            minute    => $minute,
                            second    => $second,
                            time_zone => 'UTC',
                        );
                        $timestamp_cache{$timestamp_str} = $timestamp;
                    }
                }

                $filter_range_filter_initialized = calculate_start_end_filter_timestamps( $timestamp ) unless $filter_range_filter_initialized;

                ## FILTERING CONDITIONS ##
                next if( $timestamp->epoch() < $filter_range_epoch{'start'} || $timestamp->epoch() >= $filter_range_epoch{'end'} );
                next if( defined( $exclude_regex )          && /$exclude_regex/ );
                next if( defined( $include_regex )          && !/$include_regex/ );
                next if( defined( $filter_duration_min )    && ( !defined( $duration )  || $duration <= $filter_duration_min ));		# skip if duration value is below specified minimum filter
                next if( defined( $filter_duration_max )    && ( !defined( $duration )  || $duration >= $filter_duration_max ));		# skip if duration value is above specified maximum filter
                next if( defined( $filter_bytes_min )       && ( !defined( $bytes )     || $bytes < $filter_bytes_min ));				# skip if bytes value is below specified minimum filter
                next if( defined( $filter_bytes_max )       && ( !defined( $bytes )     || $bytes > $filter_bytes_max ));				# skip if bytes value is above specified maximum filter
                next if( defined( $filter_count_min )       && ( !defined( $count )     || $count < $filter_count_min ));				# skip if count value is below specified minimum filter
                next if( defined( $filter_count_max )       && ( !defined( $count )     || $count > $filter_count_max ));				# skip if count value is above specified maximum filter

                # take note if any results were found in this file
                $in_files_matched{$in_file} = 1 unless $in_files_matched{$in_file};

                # determine if this line should be highlighted (matches in result search)
                if( defined( $highlight_regex ) && /$highlight_regex/ ) {
                    $category_bucket .= '-HL';
                    $category = 'highlight';
                    $in_files_matched{$in_file} = 2 unless $in_files_matched{$in_file} == 2;
                } else {
                    $category = 'plain';
                }
                
                # sets earliest and latest timestamp values being displayed (after the range filtering selection)
                $output_timestamp_min = $timestamp->epoch() if $output_timestamp_min == 0 || $output_timestamp_min > $timestamp->epoch();
                $output_timestamp_max = $timestamp->epoch() if $output_timestamp_max == 0 || $output_timestamp_max < $timestamp->epoch();

                my $bucket = int($timestamp->epoch() / $bucket_size_seconds) * $bucket_size_seconds;

                $log_occurrences{$bucket}{$category_bucket}{occurrences}++;
                $total_lines_included++;

                if( defined( $message ) ) {
                    my $log_key = "";
                    my $max_object_length = 25;
                    my $log_level = $status_code > 0 ? $status_code : $category_bucket;			# If we received an actual HTTP status code, use that for the message statistic data model
                    $log_level =~ s/-HL$//;

                    # Substitute UUID with HASH if command line option to do so is present (temporary feature to be eclipsed by group similar feature)
                    $message =~ s/\S{8}-\S{4}-\S{4}-\S{4}-\S{12}+/########-####-####-####-############/g if defined $mask_uuid && $mask_uuid;
                    $message = visualize_carets( $message );                            # render non-printable characters visually

                    if( defined( $threadname ) && defined( $object ) ) {				# ThingWorx log line parsed and usable for additional analysis
                        my $truncated_thread = substr( $threadname, 0, 20 );
                        my $truncated_object = substr( $object, length($object) > $max_object_length ? length($object)-$max_object_length : 0, $max_object_length );
                        # truncate the log message key to either the screen width or hardcoded value if writing to output to CSV file
                        $log_key = substr("[$log_level] [$truncated_thread] [$truncated_object] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } elsif( defined( $object ) ) {
                        my $truncated_object = substr( $object, length($object) > $max_object_length ? length($object)-$max_object_length : 0, $max_object_length );
                        $log_key = substr("[$log_level] [$truncated_object] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } elsif( defined( $threadname ) ) {
                        my $truncated_thread = substr( $threadname, 0, 20 );
                        $log_key = substr("[$log_level] [$truncated_thread] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    } else {
                        $log_key = substr("[$log_level] $message", 0, ( $write_messages_to_csv == 1 ? 350 : $max_log_message_length ) );
                    }

                    ## CAPTURE MESSAGE BASED STATISTICS DATA AND PREPARE FOR SORTING ##
                    if( $is_access_log ) {

                        # Initialize the hash if not already done (don't initialize it all, allowing for lazy population of only the fields we need)
                        $log_messages{$category}{$log_key} //= {
                            occurrences => 0,
                            total_bytes => 0,
                            total_duration => 0,
                            # count_occurrences => 0,
                            # count_min => undef,
                            # count_mean => undef,
                            # count_max => undef,
                            # count_sum => 0,
                            sum_of_squares => 0,
                            durations => [],
                        };

                        $log_messages{$category}{$log_key}{occurrences}++;
                        $log_messages{$category}{$log_key}{total_bytes} += $bytes if defined $bytes;

                        if( defined $count ) {
                            $log_messages{$category}{$log_key}{count_sum} += $count if defined $count;
                            $log_messages{$category}{$log_key}{count_occurrences}++;
                            $log_messages{$category}{$log_key}{count_min} = $count if !defined $log_messages{$category}{$log_key}{count_min} || $count < $log_messages{$category}{$log_key}{count_min};
                            $log_messages{$category}{$log_key}{count_max} = $count if !defined $log_messages{$category}{$log_key}{count_max} || $count > $log_messages{$category}{$log_key}{count_max};
                        }

                        if( defined $duration && !$omit_durations ) {
                            $log_messages{$category}{$log_key}{total_duration} += $duration;
                            $log_messages{$category}{$log_key}{total_duration_num} += $duration;

                            # Accumulate the sum of squares for variance calculation
                            $log_messages{$category}{$log_key}{sum_of_squares} += $duration ** 2;
                            push @{$log_messages{$category}{$log_key}{durations}}, $duration;

                            # by calculating impact as the numbers build, it will be ready to use for sorting without having to go through the whole dataset
                            if( $duration > 0 ) {
                                my $mean = $log_messages{$category}{$log_key}{total_duration} / $log_messages{$category}{$log_key}{occurrences}; 
                                $log_messages{$category}{$log_key}{impact} = round( log( $mean ** $impact_time_exponent * $log_messages{$category}{$log_key}{occurrences} ) * 100 ) / 100;
                            }
                        }
                    } else {
                        $log_messages{$category}{$log_key}{occurrences}++;
                    }
                }

                ## CAPTURE TIME-WINDOWS BASED STATISTICS DATA ##
                if( $is_access_log  ) {
                    $print_durations = 1 if $print_durations != 1;

                    ## STATISTICAL DATA CAPTURE ##
                    $duration = 0 if !defined( $duration );
                    $bytes = 0 if !defined( $bytes );
    
                    # Initialize the hash if not already done (don't initialize it all, allowing for lazy population of only the fields we need)
                    $log_analysis{$bucket} //= {
                        occurrences => 0,
                        total_bytes => 0,
                        total_duration => 0,
                        # count_sum => 0,
                        # count_occurrences => 0,
                        # count_min => undef,
                        # count_max => undef,
                        sum_of_squares => 0,
                        durations => [],
                    };

                    $log_analysis{$bucket}{occurrences}++;

                    if( defined $duration && !$omit_durations && $duration >= 0 ) {
                        $log_analysis{$bucket}{total_duration} += $duration;

                        $log_analysis{$bucket}{'total_duration-HL'} += $duration if $category_bucket =~ /-HL$/;
                        $log_analysis{$bucket}{sum_of_squares} += $duration ** 2;
                        push @{$log_analysis{$bucket}{durations}}, $duration;
                    }

                    if( defined $bytes && $bytes ) {
                        $log_analysis{$bucket}{total_bytes} += $bytes;
                        $log_analysis{$bucket}{'total_bytes-HL'} += $bytes if $category_bucket =~ /-HL$/;
                    }

                    if( defined $count ) {
                        $log_analysis{$bucket}{count_sum} += $count;
                        $log_analysis{$bucket}{count_occurrences}++;
                        $log_analysis{$bucket}{'count_sum-HL'} += $count if $category_bucket =~ /-HL$/;
                        $log_analysis{$bucket}{'count_occurrences-HL'}++ if $category_bucket =~ /-HL$/;

                        # Track min/max incrementally (needed for comparison, but not calculating statistics here)
                        $log_analysis{$bucket}{count_min} = $count if !defined $log_analysis{$bucket}{count_min} || $count < $log_analysis{$bucket}{count_min};
                        $log_analysis{$bucket}{count_max} = $count if !defined $log_analysis{$bucket}{count_max} || $count > $log_analysis{$bucket}{count_max};
                    }

                    ## HEATMAP RAW VALUE CAPTURE ##
                    if ($heatmap_enabled) {
                        my $heatmap_value;
                        if ($heatmap_metric eq 'duration' && defined $duration && $duration >= 0) {
                            $heatmap_value = $duration;
                        } elsif ($heatmap_metric eq 'bytes' && defined $bytes && $bytes > 0) {
                            # bytes > 0 (not >= 0) to exclude "-" values converted to 0
                            $heatmap_value = $bytes;
                        } elsif ($heatmap_metric eq 'count' && defined $count && $count >= 0) {
                            $heatmap_value = $count;
                        }

                        if (defined $heatmap_value && $heatmap_value > 0) {
                            # Track global min/max for boundary calculation
                            # Note: Using !defined for initial state check since 0 can be a valid value
                            $heatmap_min = $heatmap_value if !defined $heatmap_min || $heatmap_value < $heatmap_min;
                            $heatmap_max = $heatmap_value if !defined $heatmap_max || $heatmap_value > $heatmap_max;

                            # Store raw values for later bucketing (after min/max known)
                            push @{$heatmap_raw{$bucket}}, $heatmap_value;
                            push @{$heatmap_raw_hl{$bucket}}, $heatmap_value if $category_bucket =~ /-HL$/;
                        }
                    }
                }

                ## CAPTURE THREAD AND THREAD POOL BASED STATISTICS DATA ##
                if( ( defined $threadpool && $threadpool ne "" ) && ( ( defined $threadpool_activity_regex && $threadpool =~ /$threadpool_activity_regex/ ) || ( !defined $threadpool_activity_regex && $include_threadpool_summary ) ) ) {
                    # Thread Pool Based Statistics Capture (Overall Summary) #
                    $threadpool_activity{$category}{$threadpool}{$thread} = 0 if !defined $threadpool_activity{$category}{$threadpool}{$thread};
                    $threadpool_activity{$category}{$threadpool}{$thread} += 1;

                    # Time Window Based Statistics Capture (Time Window Graphs) #
                    $log_threadpools{$bucket}{$threadpool}{plain}{$thread} += 1;

                    if( $category_bucket =~ /-HL$/ ) {                  # capture total duration and bytes for highlighted rows
                        $log_threadpools{$bucket}{$threadpool}{highlight}{$thread} += 1;
                    }
                }
            }
        }

        close $fh;

        print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    }
    print "\r$colors{'bright-green'}Processing completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Processing completed." ) );
    print "\n";

    return;
}

sub find_heatmap_bucket {
    my ($value, $bucket_count) = @_;
    for my $i (0 .. $#heatmap_boundaries - 1) {
        return $i if $value >= $heatmap_boundaries[$i] && $value < $heatmap_boundaries[$i + 1];
    }
    return $bucket_count - 1;  # Last bucket catches max values
}

sub calculate_heatmap_buckets {
    return unless $heatmap_enabled;
    return unless defined $heatmap_min && defined $heatmap_max && $heatmap_max > $heatmap_min && $heatmap_max > 0;

    print "\rCalculating heatmap buckets...";

    # Clear any previous boundary values
    @heatmap_boundaries = ();

    # Use $heatmap_width (default 52, or set via --heatmap-width)
    my $heatmap_bucket_count = $heatmap_width;

    # Handle edge case where min equals max or min is zero
    my $effective_max = $heatmap_max > $heatmap_min ? $heatmap_max : $heatmap_min + 1;

    # LOGARITHMIC bucket boundaries
    # Formula: boundary[i] = min * (max/min)^(i/num_buckets)
    # Log scale provides better resolution at low values where most latency data clusters
    my $effective_min = $heatmap_min > 0 ? $heatmap_min : 1;
    my $ratio = $effective_max / $effective_min;
    for my $i (0 .. $heatmap_bucket_count) {
        $heatmap_boundaries[$i] = $effective_min * ($ratio ** ($i / $heatmap_bucket_count));
    }

    # Distribute raw values into histogram buckets and calculate percentiles
    foreach my $bucket (keys %heatmap_raw) {
        # Sort values to calculate percentiles
        my @sorted_values = sort { $a <=> $b } @{$heatmap_raw{$bucket}};
        my $count = scalar @sorted_values;

        if ($count > 0) {
            # Calculate percentile values (P50, P95, P99, P99.9)
            my $p50_value  = $sorted_values[int($count * 0.50)];
            my $p95_value  = $sorted_values[int($count * 0.95)];
            my $p99_value  = $sorted_values[int($count * 0.99)];
            my $p999_value = $sorted_values[int($count * 0.999)] // $sorted_values[-1];

            # Convert percentile values to bucket indices
            $heatmap_percentiles{$bucket} = {
                p50  => find_heatmap_bucket($p50_value, $heatmap_bucket_count),
                p95  => find_heatmap_bucket($p95_value, $heatmap_bucket_count),
                p99  => find_heatmap_bucket($p99_value, $heatmap_bucket_count),
                p999 => find_heatmap_bucket($p999_value, $heatmap_bucket_count),
            };
        }

        foreach my $value (@sorted_values) {
            my $range_index = find_heatmap_bucket($value, $heatmap_bucket_count);
            $heatmap_data{$bucket}{$range_index}++;

            # Track max density for color normalization
            $heatmap_max_density = $heatmap_data{$bucket}{$range_index}
                if $heatmap_data{$bucket}{$range_index} > $heatmap_max_density;
        }

        # Process highlighted values
        if (exists $heatmap_raw_hl{$bucket}) {
            foreach my $value (@{$heatmap_raw_hl{$bucket}}) {
                my $range_index = find_heatmap_bucket($value, $heatmap_bucket_count);
                $heatmap_data_hl{$bucket}{$range_index}++;
            }
        }

        # Free memory
        delete $heatmap_raw{$bucket};
        delete $heatmap_raw_hl{$bucket};
    }

    return;
}

sub calculate_all_statistics {

    print "\rCalculating statistics...";

    foreach my $bucket (sort { $a <=> $b } keys %log_analysis) {
        my $aggregated_data = {
            occurrences         => 0,
            total_duration      => 0,
            'total_duration-HL' => 0,
            total_bytes         => 0,
            'total_bytes-HL'    => 0,
            count_sum           => 0,
            'count_sum-HL'      => 0,
            count_occurrences   => 0,
            'count_occurrences-HL' => 0,
            count_min           => undef,
            count_max           => undef,
            sum_of_squares      => 0,
            durations           => [],
        };

# TO DO: shouldn't check memory on each pass; use approach like reading lines
        if( $track_memory ) {
            $current_memory_usage = get_memory_usage();								# track maximum memory usage
            if ($current_memory_usage > $max_memory_usage) {
                $max_memory_usage = $current_memory_usage;
            }
        }
   
        next if !defined( $log_analysis{$bucket}{occurrences} );

# TO DO: I think that I can get rid of aggregate_data now that I've simplified the data model
        $aggregated_data->{occurrences} += $log_analysis{$bucket}{occurrences};
        $aggregated_data->{total_duration} += $log_analysis{$bucket}{total_duration};
        $aggregated_data->{total_bytes} += $log_analysis{$bucket}{total_bytes};
        $aggregated_data->{sum_of_squares} += $log_analysis{$bucket}{sum_of_squares};
        push @{$aggregated_data->{durations}}, @{$log_analysis{$bucket}{durations}};

        # Aggregate min/max across buckets
        $aggregated_data->{count_min} = $log_analysis{$bucket}{count_min} if defined $log_analysis{$bucket}{count_min} && ( !defined $aggregated_data->{count_min} || $log_analysis{$bucket}{count_min} < $aggregated_data->{count_min} );
        $aggregated_data->{count_max} = $log_analysis{$bucket}{count_max} if defined $log_analysis{$bucket}{count_max} && ( !defined $aggregated_data->{count_max} || $log_analysis{$bucket}{count_max} > $aggregated_data->{count_max} );

        # free up the memory from the data structure as it is no longer needed
        undef $log_analysis{$bucket}{durations};
        delete $log_analysis{$bucket}{durations};
    
        # The duration based statistics won't catch the counts if there are no durations (see else condition below)
        if( $print_durations && !$omit_durations ) {
            my ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv) = calculate_statistics($aggregated_data);

            $log_stats{$bucket} = {
                occurrences   => $aggregated_data->{occurrences},
                bytes         => $log_analysis{$bucket}{total_bytes},
                'bytes-HL'    => $log_analysis{$bucket}{'total_bytes-HL'},
                duration      => $log_analysis{$bucket}{total_duration},
                'duration-HL' => $log_analysis{$bucket}{'total_duration-HL'},
                count         => $log_analysis{$bucket}{count_sum},
                'count-HL'    => $log_analysis{$bucket}{'count_sum-HL'},
                count_occurrences => $log_analysis{$bucket}{count_occurrences},
                count_min     => $log_analysis{$bucket}{count_min},
                count_max     => $log_analysis{$bucket}{count_max},
                count_mean    => ( defined $log_analysis{$bucket}{count_sum} && defined $log_analysis{$bucket}{count_occurrences} && $log_analysis{$bucket}{count_occurrences} > 0 ) ? round( $log_analysis{$bucket}{count_sum} / $log_analysis{$bucket}{count_occurrences} ) : undef,
                count_sum     => $log_analysis{$bucket}{count_sum},
                min           => $min,
                mean          => $mean,
                max           => $max,
                p1            => $p1,
                p50           => $p50,
                p75           => $p75,
                p90           => $p90,
                p95           => $p95,
                p99           => $p99,
                p999          => $p999,
                std_dev       => $std_dev,
                cv            => $cv,
                z_score       => undef
            };
    
            # Calculate rolling mean and std_dev
            my $rolling_mean = 0;
            my $rolling_sum_of_squares = 0;
            my $rolling_count = 0;
            foreach my $prev_bucket (@rolling_window) {
                $rolling_mean += $prev_bucket->{mean};
                $rolling_sum_of_squares += $prev_bucket->{sum_of_squares};
                $rolling_count++;
            }
            if ($rolling_count > 0) {
                $rolling_mean /= $rolling_count;
                my $rolling_variance = ($rolling_sum_of_squares / $rolling_count) - ($rolling_mean ** 2);
                my $rolling_std_dev = sqrt($rolling_variance);
                my $z_score = calculate_z_score($mean, $rolling_mean, $rolling_std_dev);
               $log_stats{$bucket}{z_score} = $z_score;
            }

            # Update rolling window logic
            push @rolling_window, { mean => $mean, sum_of_squares => $aggregated_data->{sum_of_squares} };
            shift @rolling_window if @rolling_window > $rolling_window_size;

        } else {
            # This will catch the situation where there are no durations, printing them has been disabled, or they were not captured.
            $log_stats{$bucket} = {
                occurrences   => $aggregated_data->{occurrences},
                bytes         => $log_analysis{$bucket}{total_bytes},
                'bytes-HL'    => $log_analysis{$bucket}{'total_bytes-HL'},
                duration      => $log_analysis{$bucket}{total_duration},
                'duration-HL' => $log_analysis{$bucket}{'total_duration-HL'},
                count         => $log_analysis{$bucket}{count_sum},
                'count-HL'    => $log_analysis{$bucket}{'count_sum-HL'},
                count_occurrences => $log_analysis{$bucket}{count_occurrences},
                count_min     => $log_analysis{$bucket}{count_min},
                count_max     => $log_analysis{$bucket}{count_max},
                count_mean    => ( defined $log_analysis{$bucket}{count_sum} && defined $log_analysis{$bucket}{count_occurrences} && $log_analysis{$bucket}{count_occurrences} > 0 ) ? round( $log_analysis{$bucket}{count_sum} / $log_analysis{$bucket}{count_occurrences} ) : undef,
                count_sum     => $log_analysis{$bucket}{count_sum}
            }
        }
    }

    ## STATS FOR TOP LOG MESSAGES ##
    # if( $print_durations ) {
        foreach my $category (keys %log_messages) {
            # Collect and sort the log keys based on the count within each log_key
            my (@sorted_log_keys, @top_keys);

            if( $sort_key !~ /min|mean|max|p1|p50|p75|p90|p95|p99|p999|sdt_dev|cv/ ) {
                @sorted_log_keys = sort {
                    my $occurrences_a = $log_messages{$category}{$a}{$sort_key} // 0;
                    my $occurrences_b = $log_messages{$category}{$b}{$sort_key} // 0;
                    if( $sort_ascending ) {
                        $occurrences_a <=> $occurrences_b;
                    } else {
                        $occurrences_b <=> $occurrences_a;
                    }
                } keys %{$log_messages{$category}};
                # Capture only the top N log keys for calculations if possible
                @top_keys = @sorted_log_keys[0 .. min($#sorted_log_keys, $top_n_messages - 1)]; 
            } else {
                # Sort by statistical metric which first needs to be calculated for all messages (will inevitably take longer)   
                @top_keys = keys %{$log_messages{$category}}
            }

            foreach my $log_key (@top_keys) {
                my $aggregated_data = {};

                # TO DO: Shouldn't check memory usage on each pass, only every few
                if( $track_memory ) {
                    $current_memory_usage = get_memory_usage();								# track maximum memory usage
                    if ($current_memory_usage > $max_memory_usage) {
                        $max_memory_usage = $current_memory_usage;
                    }
                } 

                next if !defined( $log_messages{$category}{$log_key}{occurrences} );

                $aggregated_data->{occurrences} += $log_messages{$category}{$log_key}{occurrences};
                $aggregated_data->{total_bytes} += $log_messages{$category}{$log_key}{total_bytes} if defined $log_messages{$category}{$log_key}{total_bytes};

                if( defined $log_messages{$category}{$log_key}{total_duration} && !$omit_durations ) {
                    $aggregated_data->{total_duration} += $log_messages{$category}{$log_key}{total_duration};
                    $aggregated_data->{sum_of_squares} += $log_messages{$category}{$log_key}{sum_of_squares};
                    push @{$aggregated_data->{durations}}, @{$log_messages{$category}{$log_key}{durations}};
                }

                if( defined $aggregated_data->{total_duration} && !$omit_durations ) {
                    my ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv) = calculate_statistics($aggregated_data);

                    $log_messages{$category}{$log_key}{min} = $min;
                    $log_messages{$category}{$log_key}{mean} = $mean;
                    $log_messages{$category}{$log_key}{max} = $max;
                    $log_messages{$category}{$log_key}{std_dev} = $std_dev;
                    $log_messages{$category}{$log_key}{p1} = $p1;
                    $log_messages{$category}{$log_key}{p50} = $p50;
                    $log_messages{$category}{$log_key}{p75} = $p75;
                    $log_messages{$category}{$log_key}{p90} = $p90;
                    $log_messages{$category}{$log_key}{p95} = $p95;
                    $log_messages{$category}{$log_key}{p99} = $p99;
                    $log_messages{$category}{$log_key}{p999} = $p999;
                    $log_messages{$category}{$log_key}{cv} = $cv;
                    $log_messages{$category}{$log_key}{total_duration_num} = $aggregated_data->{total_duration} if defined $aggregated_data->{total_duration};
                    $log_messages{$category}{$log_key}{total_duration} = format_time( $aggregated_data->{total_duration}, 'ms', 'medium', 'space' ) if defined $aggregated_data->{total_duration};
                }

                $log_messages{$category}{$log_key}{total_bytes} = $aggregated_data->{total_bytes} if defined $aggregated_data->{total_bytes};

                $log_messages{$category}{$log_key}{count_occurrences} = $log_messages{$category}{$log_key}{count_occurrences} if defined $log_messages{$category}{$log_key}{count_occurrences};
                $log_messages{$category}{$log_key}{count_min} = $log_messages{$category}{$log_key}{count_min} if defined $log_messages{$category}{$log_key}{count_min};
                $log_messages{$category}{$log_key}{count_mean} = ( defined $log_messages{$category}{$log_key}{count_sum} && defined $log_messages{$category}{$log_key}{count_occurrences} && $log_messages{$category}{$log_key}{count_occurrences} > 0 ) ? round( $log_messages{$category}{$log_key}{count_sum} / $log_messages{$category}{$log_key}{count_occurrences} ) : undef if defined $log_messages{$category}{$log_key}{count_occurrences};
                $log_messages{$category}{$log_key}{count_max} = $log_messages{$category}{$log_key}{count_max} if defined $log_messages{$category}{$log_key}{count_max};
                $log_messages{$category}{$log_key}{count_sum} = $log_messages{$category}{$log_key}{count_sum} if defined $log_messages{$category}{$log_key}{count_sum};
                
                # 2026-01-04 TO DO: free up the memory from the data structure as it is no longer needed (don't think that below logic was actually working as intended)
                # undef $log_messages{$category}{$log_key}{durations};
                # delete $log_messages{$category}{$log_key}{durations};
            }
        # }
    }

    ## STATS FOR THREAD POOL ACTIVITY ##
    my %threadpools;
    my ( @ordered_threadpools );
    my $threadpools_included = 0;

    foreach my $category ( qw( highlight plain ) ) {
        foreach my $threadpool ( keys %{$threadpool_activity{$category}} ) {
            $threadpools{$threadpool}{threads} += scalar keys %{$threadpool_activity{$category}{$threadpool}};
            foreach my $thread ( keys %{$threadpool_activity{$category}{$threadpool}} ) {
                $threadpools{$threadpool}{occurrences} += $threadpool_activity{$category}{$threadpool}{$thread};
            }
        }
    }

    @ordered_threadpools = sort { $threadpools{$b}{occurrences} <=> $threadpools{$a}{occurrences} } keys %threadpools;

# TO DO - If I built up the max_totals while going through the files, by the time we calculate the statistics I could removed empty graph fields like duration and bytes,
#         then we'd be OK to add more custom columns in order to still fit within the 6 column limit.
    foreach my $threadpool ( @ordered_threadpools ) {
        last if $threadpools_included++ > 3;
        push( @graph_threadpools_activity, $threadpool ) if( $include_threadpool_summary || $threadpool =~ /${threadpool_activity_regex}/i );
    }

    push @graph_columns, @graph_threadpools_activity;			# add matched thread pools to the list of data points to be graphed

    # Capture Relevant Thread Pool Stats for Graphing
    foreach my $bucket (keys %log_threadpools) {
        foreach my $threadpool (@graph_threadpools_activity) {
            my $threadpool_highlight = "$threadpool-HL";
        
            # Ensure the keys exist before accessing them
            if (exists $log_threadpools{$bucket}{$threadpool}{plain} ) {
                $log_stats{$bucket}{$threadpool} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{plain}};
                $log_stats{$bucket}{$threadpool_highlight} = scalar keys %{$log_threadpools{$bucket}{$threadpool}{highlight}};
            } else {
                 $log_stats{$bucket}{$threadpool} = 0;
            }
            # 2026-01-04 TO DO: Free up no longer needed memory (likely not working as intended)
            undef $log_threadpools{$bucket}{$threadpool};
            delete $log_threadpools{$bucket}{$threadpool};
        }
    }

    print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    print "\r$colors{'bright-green'}Calculating statistics completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Calculating statistics completed." ) );
    print "\n";

    return;
}

# Function to calculate the log scale bucket
sub log_bucket {
    my ($value, $base) = @_;
    $value = 0 if !defined( $value );
    return $value > 0 ? floor(log($value) / log($base)) : 0;
}

# Function to calculate Z-score
sub calculate_z_score {
    my ($current_mean, $rolling_mean, $rolling_std_dev) = @_;
    return undef if $rolling_std_dev == 0;
    return sprintf("%.2f", ($current_mean - $rolling_mean) / $rolling_std_dev);
}

# Function to calculate statistical metrics
sub calculate_statistics {
    my ($bucket_data) = @_;
    my $occurrences = $bucket_data->{occurrences};
    return unless $occurrences > 0;

    # Guard against empty durations array - not all entries may have duration data
    return unless defined $bucket_data->{durations} && @{$bucket_data->{durations}};

    my @sorted = sort { $a <=> $b } @{$bucket_data->{durations}};
    my $duration_count = scalar @sorted;

    # Use duration_count (entries with duration data) for statistics, not occurrences (total entries)
    my $min = min(@sorted);
    my $mean = int($bucket_data->{total_duration} / $duration_count);
    my $max = max(@sorted);
    my $variance = ($bucket_data->{sum_of_squares} / $duration_count) - ($mean ** 2);
    my $std_dev = round( sqrt($variance) * 1000 ) / 1000;
    my $cv = $mean != 0 ? sprintf("%.2f", $std_dev / $mean ) : undef;

    # Percentile calculations must use duration_count, not occurrences
    # to correctly index into the sorted durations array
    my $p1   = int($sorted[int($duration_count * 0.01)]);
    my $p50  = int($sorted[int($duration_count * 0.5)]);
    my $p75  = int($sorted[int($duration_count * 0.75)]);
    my $p90  = int($sorted[int($duration_count * 0.9)]);
    my $p95  = int($sorted[int($duration_count * 0.95)]);
    my $p99  = int($sorted[int($duration_count * 0.99)]);
    my $p999 = int($sorted[int($duration_count * 0.999)]);

    return ($min, $mean, $max, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $std_dev, $cv);
}

sub initialize_empty_time_windows {

    # Go through all of the buckets between the earliest and latest times and ensure that they have empty data to print time buckets with no data
    unless( $omit_empty ) {
        my $start_bucket = int($output_timestamp_min / $bucket_size_seconds) * $bucket_size_seconds;

        print "\rInitializing empty time windows...";

        for (my $bucket = $start_bucket; $bucket <= $output_timestamp_max; $bucket += $bucket_size_seconds) {
            $log_occurrences{$bucket}{'empty'}{'occurrences'} = 0;
        }

        print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
        print "\r$colors{'bright-green'}Initializing empty time windows completed.$colors{'NC'}";
        print " " x ( $terminal_width - length( "Initializing empty time windows completed." ) );
        print "\n";
    }

    return;
}

sub cumulative_round_widths {
    my ($w_ref, $M) = @_;
    my @w = @$w_ref;

    # 1) cumulative sums
    my @cum;
    my $acc = 0.0;
    for my $x (@w) {
        $acc += $x;
        push @cum, $acc;
    }

    # 2) rounded boundaries (nearest), and force the last to M
    my @b = map { int($_ + 0.5) } @cum;
    $b[-1] = $M;

    # 3) widths from boundary differences
    my @widths;
    $widths[0] = $b[0];
    for my $i (1 .. $#b) {
        $widths[$i] = $b[$i] - $b[$i - 1];
    }

    return @widths;
}

# Key function used to normalize data for output, graphing, and data scaling.
sub normalize_data_for_output {

    my %max_total = (
        occurrences => 0,
        bytes => 0,
        duration => 0,
        count => 0,
    );
    my %output_columns;

# TO DO : user defined value will need to have a max total determined for scaling and printing

    print "\rScaling and normalizing data...";

    push @output_columns, "timestamp";

    foreach my $bucket (keys %log_occurrences) {
        my $total_occurrences = 0;
        my $total_bytes = $log_stats{$bucket}{bytes};
        my $error_occurrences = 0;

        foreach my $category_bucket (keys %{$log_occurrences{$bucket}}) {
            my $occurrences = $log_occurrences{$bucket}{$category_bucket}{occurrences};
            next unless $occurrences > 0 && $category_bucket !~ /^empty|err-rate|msg-rate$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
            $total_occurrences += $occurrences;
            $error_occurrences += $occurrences if $category_bucket =~ /^ERROR|5xx|4xx$/i;
        }

        # this part takes the time windows error and message counts and converts them to a per minute rate
        unless( defined( $omit_rate ) && $omit_rate ) {
            $log_occurrences{$bucket}{'err-rate'}{occurrences} = $error_occurrences / $bucket_size_seconds * 60;
            $log_occurrences{$bucket}{'msg-rate'}{occurrences} = $total_occurrences / $bucket_size_seconds * 60;
        }

        # Calculate the maximum value of the selected trend type if it is activated
        $max_total{occurrences} = $total_occurrences if !defined $max_total{occurrences} || $total_occurrences > $max_total{occurrences};
        $max_total{bytes} = $total_bytes if ( defined $total_bytes && !$omit_bytes && $total_bytes > $max_total{bytes} );
        $max_total{duration} = $log_stats{$bucket}{duration} if ( defined $log_stats{$bucket}{duration} && $log_stats{$bucket}{duration} > $max_total{duration} );
        $max_total{count} = $log_stats{$bucket}{count} if ( defined $log_stats{$bucket}{count} && !$omit_count && $log_stats{$bucket}{count} > $max_total{count} );
    }

    if( scalar @graph_threadpools_activity > 0 ) {
        foreach my $bucket ( keys %log_threadpools ) {
           foreach my $threadpool ( @graph_threadpools_activity ) {
               $max_total{$threadpool} = 0 if !defined $max_total{$threadpool};
               $max_total{$threadpool} = $log_stats{$bucket}{$threadpool} if ( defined $log_stats{$bucket}{$threadpool} && $log_stats{$bucket}{$threadpool} > $max_total{$threadpool} );
           }
        }
    }

    # Calculate the maximum character length of log level titles and counts
    foreach my $bucket (keys %log_occurrences) {
        my $bucket_legend_length = 0;

        foreach my $category_bucket (keys %{$log_occurrences{$bucket}}) {
            my $occurrences = $log_occurrences{$bucket}{$category_bucket}{occurrences};
            my $title_length = 0;
            next unless ( $occurrences > 0 || $category_bucket =~ /^(err|msg)-rate$/ ) && $category_bucket !~ /^empty$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
            next if $omit_values && $category_bucket !~ /^(err-rate|msg-rate|empty)$/;
            next if $omit_rate && $category_bucket =~ /^(err-rate|msg-rate)$/;
            next if $category_bucket =~ /^(err|msg)-rate$/ && $log_occurrences{$bucket}{'err-rate'}{occurrences} == 0 && $log_occurrences{$bucket}{'msg-rate'}{occurrences} == 0;

            if( $category_bucket =~ /-HL$/ ) {
                $title_length = length("$occurrences ");
            } elsif( $category_bucket =~ /^err-rate$/ ) {
                $title_length = length(format_number( $occurrences ) . ":");
                $title_length += length(" ") if !$omit_values;                              # need to add the spacing between values and rate if both will be printed
            } elsif( $category_bucket =~ /^msg-rate$/ ) {
                $title_length = length( format_number( $occurrences ) . "/m ");
            } else {
                $title_length = length("$category_bucket: $occurrences ");
            }
            $bucket_legend_length += $title_length;
            $output_columns{$category_bucket} = 1 if !exists $output_columns{$category_bucket};
        }

        $legend_length = $bucket_legend_length if $bucket_legend_length > $legend_length;
    }

    foreach my $category_bucket ( @log_levels ) {
        if( exists $output_columns{$category_bucket} ) {
            push @output_columns, $category_bucket;
        }
    }
    push @output_columns, "totalOccurrences"; # if $category_bucket =~ /^err-rate$/;

# Latency statistics column width: │ + 2 spaces + P50(11) + P95(11) + P99(11) + P999(11) + CV(7) = 54 chars
    # When heatmap is enabled, use $heatmap_width (which may be customized via -hmw) instead of hardcoded 52
    if ($heatmap_enabled) {
        $durations_graph_width = $graph_column_padding_latency + $heatmap_width + $graph_column_padding_all;
    } elsif ($print_durations && !$omit_durations && !$omit_stats) {
        $durations_graph_width = $graph_column_padding_latency + 52 + $graph_column_padding_all;
    } else {
        $durations_graph_width = 0;
    }

    # Normalize counts to fit terminal width - static values based on timestamp length, some white space, maybe a vertical line spacer
    # $timestamp_length = length( strftime($output_timestamp_format, gmtime(0) ) ) + 1 + ( $print_milliseconds ? 4 : 0 ) ;     # +1 for built in space after timestamp
    $timestamp_length = $graph_column_padding_timestamp + length( strftime($output_timestamp_format, gmtime(0) ) ) + ( $print_milliseconds ? 4 : 0 ) + $graph_column_padding_all;     # remove spacing from length calculation as it is seperate

    $max_graph_width = $terminal_width - $legend_length - $timestamp_length - $durations_graph_width;
# print "\nmax_graph_width: $max_graph_width terminal_width: $terminal_width legend_length: $legend_length timestamp length: " . $timestamp_length . " durations_graph_width: $durations_graph_width\n";

    push @printed_column_widths, $timestamp_length - ( $graph_column_padding_all + $graph_column_padding_timestamp );
    push @printed_column_names, "timestamp"; 
    push @printed_column_spacing, ( $graph_column_padding_all + $graph_column_padding_timestamp );

    if( !( $omit_values && $omit_rate ) ) {
        push @printed_column_widths, $legend_length;
        push @printed_column_spacing, 0;                                        # legend column does not need trailing spacing as it is last before graph columns
        push @printed_column_names, "legend";
        $column_count_pre_graph = 2;                                            # if legend column is printed, then statically sized columns will be timestamp and legend
    } else {
	    $column_count_pre_graph = 1;                                            # if legend column is omitted, then statically sized columns will only be timestamp
    }

    push @printed_column_names, "occurrences"; 									# this count column is required, not sure how to make the logic more coherent

    %graph_width = ( 1 => $max_graph_width );

    # Split the graph spacing into parts if more than one graph is to be drawn
    foreach my $graph_type ( @graph_columns ) {									# Count how many of the to be displayed data columns actually have values to be printed
        if( $graph_type eq 'count' && !$include_count && ( $max_graph_width / $graph_count < 25 ) ) {       # remove count column if not enough space to print it, unless explicitly included
            @graph_columns = grep { $_ !~ /count/ } @graph_columns;
            next;
        };
        $graph_count += ( $max_total{$graph_type} > 0 );
    }

    my %graph_relative_size;
    my $graph_column_count = 1;             # will always have count/occurrences column
    # Determine and store which of the possible columns to print have data
    foreach my $key ( @graph_columns ) {
        if( defined $max_total{$key} && $max_total{$key} != 0 ) {
            push @populated_graph_columns, $key;
            push @output_columns, "${key}Nice" if $key =~ /^(duration|bytes)$/; # presently these won't be output to CSV as processing loop to screen will stop at max columns
            if( $key =~ /^count$/ ) {
                push @output_columns, "${key}_occurrences", "${key}_min", "${key}_mean", "${key}_max", "${key}_sum" if !$omit_count;
            } else {
                push @output_columns, $key;
            }

            next if ++$graph_column_count > $graph_count_max;					# limit the number of graph columns to 6 max
            push @printed_column_names, $key;
        }
    }

    $graph_count = $graph_count_max if $graph_count > $graph_count_max;									# limit the number of graph columns to 6 max

    if( $graph_count == 2 ) {
        %graph_relative_size = (
            1 => 65,
            2 => 35,
        );
        %graph_width = (
            1 => ( $graph_relative_size{1} / 100 * $max_graph_width ),
            2 => ( $graph_relative_size{2} / 100 * $max_graph_width ),
        );
    } elsif( $graph_count == 3 ) {
        %graph_relative_size = (
            1 => 62,
            2 => 21,
            3 => 17,
        );
        %graph_width = (
            1 => ( $graph_relative_size{1} / 100 * $max_graph_width ),
            2 => ( $graph_relative_size{2} / 100 * $max_graph_width ),
            3 => ( $graph_relative_size{3} / 100 * $max_graph_width ),
        );
    } elsif( $graph_count == 4 ) {
        %graph_relative_size = (
            1 => 50,
            2 => 18,
            3 => 16,
            4 => 16,
        );
        %graph_width = (
            1 => ( $graph_relative_size{1} / 100 * $max_graph_width ),
            2 => ( $graph_relative_size{2} / 100 * $max_graph_width ),
            3 => ( $graph_relative_size{3} / 100 * $max_graph_width ),
            4 => ( $graph_relative_size{4} / 100 * $max_graph_width ),
        );
    } elsif( $graph_count == 5 ) {
        %graph_relative_size = (
            1 => 40,
            2 => 15,
            3 => 15,
            4 => 15,
            5 => 15,
        );
        %graph_width = (
            1 => ( $graph_relative_size{1} / 100 * $max_graph_width ),
            2 => ( $graph_relative_size{2} / 100 * $max_graph_width ),
            3 => ( $graph_relative_size{3} / 100 * $max_graph_width ),
            4 => ( $graph_relative_size{4} / 100 * $max_graph_width ),
            5 => ( $graph_relative_size{5} / 100 * $max_graph_width ),
        );
    } elsif( $graph_count == 6 ) {
        %graph_relative_size = (
            1 => 30,
            2 => 14,
            3 => 14,
            4 => 14,
            5 => 14,
            6 => 14,
        );
        %graph_width = (
            1 => ( $graph_relative_size{1} / 100 * $max_graph_width ),
            2 => ( $graph_relative_size{2} / 100 * $max_graph_width ),
            3 => ( $graph_relative_size{3} / 100 * $max_graph_width ),
            4 => ( $graph_relative_size{4} / 100 * $max_graph_width ),
            5 => ( $graph_relative_size{5} / 100 * $max_graph_width ),
            6 => ( $graph_relative_size{6} / 100 * $max_graph_width ),
        );
    }

    foreach my $column ( 1 .. $graph_count ) {							# capture and build up list containing width and spacing between columns
        my $column_spacing = $graph_column_padding_all;
        $column_spacing += $graph_column_padding_count if $column == 1;
        $column_spacing += $graph_column_padding_other if $column > 1;
        push @printed_column_widths, $graph_width{$column} - $column_spacing;
        push @printed_column_spacing, $column_spacing;
    }

    # BUG 2026-01-04 : stats calculations and output need to be decoupled from what is printed to the console.  Here, specifying to not print duration stats will not output them either.
    if ($heatmap_enabled) {
        # Heatmap column header replaces latency statistics
        push @output_columns, qw( min mean max std_dev p1 p50 p75 p90 p95 p99 p999 cv z_score ) if $print_durations && !$omit_durations;
        push @printed_column_widths, $durations_graph_width;
        push @printed_column_spacing, 0;
        push @printed_column_names, get_heatmap_column_header();
    } elsif( $print_durations && !$omit_durations && !$omit_stats ) {
        my $column_spacing = ( $graph_column_padding_all + $graph_column_padding_latency );
        push @output_columns, qw( min mean max std_dev p1 p50 p75 p90 p95 p99 p999 cv z_score );
        push @printed_column_widths, $durations_graph_width;
        push @printed_column_spacing, 0;
        push @printed_column_names, "latency statistics";
    }

    foreach my $column ( 0 .. $#printed_column_names ) {
        my $title = $printed_column_names[$column];
        my $max_length = $printed_column_widths[$column];
        $printed_column_names[$column] = substr( $title, 0, $max_length ) if length( $title ) > $max_length;
    }

    my @rounded_column_widths = cumulative_round_widths( \@printed_column_widths, $terminal_width - eval(join '+', @printed_column_spacing ));

    # $, = ", ";
    # print "\nPopulated graph columns:       ", @populated_graph_columns;
    # print "\nDetected and sized columns:    ", sort keys %graph_width;
    # print "\nCalculated column widths:      ", map { "$_ => $graph_width{$_}" } sort keys %graph_width;  
    # print "\nPrinted column length:          ", @printed_column_widths;
    # print " -- total=" . eval(join '+', @printed_column_widths );
    # print "\nRounded column lengths:          ", @rounded_column_widths;
    # print " -- total=" . eval(join '+', @rounded_column_widths );
    # print "\nPrinted column spacing:         ", @printed_column_spacing;
    # print " -- total=" . eval(join '+', @printed_column_spacing );
    # print "\nPrinted column names:           ", @printed_column_names;
    # print "\n";
    # $, = "";

    @printed_column_widths = @rounded_column_widths;

    foreach my $bucket (keys %log_occurrences) {
        my $processed_time_buckets //= 0;
	    my $check_memory_every = $^O ne 'MSWin32' ? 50 : 500;
		
        # scale the transferred bytes for printing the statistics table
        my $bytes = $log_stats{$bucket}{bytes};
        my $scaled_bytes = ( defined $bytes && defined $max_total{bytes} && $max_total{bytes} != 0 ) ? int(($bytes / $max_total{bytes}) * $durations_graph_width) : 0;
        $log_stats{$bucket}{scaled_bytes} = $scaled_bytes;

        # Scale the total values to the printable size
        if( $graph_count > 1 ) {
            my $column_number = $column_count_pre_graph + 1;		# start after the timestamp and possibly legend columns

            foreach my $key ( @populated_graph_columns ) {			# go through the list of possible columns and populate the scaled value for that metric for the current time bucket
                # 2025-12-07 - counts are handled separately below with additional logic which should be incorporated here in the future for coherence and performance improvements
                next if $key =~ /^occurrences$/;					# the occurrences have already been printed, so should skip this entry even if it is legitimate
                my $key_highlight = "$key-HL";
                my $scaled_key = "scaled_${key}";
                my $scaled_key_highlight = "${scaled_key}-HL";

                $log_stats{$bucket}{$scaled_key} = ( defined $log_stats{$bucket}{$key} && defined $max_total{$key} && $max_total{$key} != 0 ) ? int(( $log_stats{$bucket}{$key} / $max_total{$key} ) * $printed_column_widths[$column_number] ) : 0;
                $log_stats{$bucket}{$scaled_key_highlight} = ( defined $log_stats{$bucket}{$key_highlight} && defined $max_total{$key} && $max_total{$key} != 0 ) ? int(( $log_stats{$bucket}{$key_highlight} / $max_total{$key} ) * $printed_column_widths[$column_number] ) : 0;
                $column_number++;
            }
        }

        my $scaled_occurrences_total = 0;
        my $scaled_max_key = "";
        my $scaled_max_value = 0;

        # Scale the log message counts for printing the graph
        foreach my $category_bucket (keys %{$log_occurrences{$bucket}}) {
            next if $category_bucket =~ /^(err|msg)-rate|empty$/;
            my $occurrences = $log_occurrences{$bucket}{$category_bucket}{occurrences};
            next if !defined $occurrences;										                # skip scaling where varible was left or is undefined (ie; no error or message rate)
            my $scaled_occurrences = $max_total{occurrences} != 0 ? round(($occurrences / $max_total{occurrences}) * $printed_column_widths[$column_count_pre_graph] ) : 0;	# Adapting count scaling to multi-graph functionality
            if( $scaled_occurrences > $scaled_max_value ) {                                     # track the maximum scaled count for this time bucket to correct for rounding errors
                $scaled_max_value = $scaled_occurrences;
                $scaled_max_key = $category_bucket;
            }
            $scaled_occurrences_total += $scaled_occurrences;

            $log_occurrences{$bucket}{$category_bucket}{scaled_occurrences} = $scaled_occurrences;
            $category_totals{$category_bucket} += $occurrences;							        # tally the totals for each category bucket
            $total_lines_highlighted += $occurrences if $category_bucket =~ /-HL$/;
        }

        if ( $scaled_occurrences_total > $printed_column_widths[$column_count_pre_graph] ) {	# correct for rounding errors by reducing the largest scaled count by 1 if we went over the allowed width
            $log_occurrences{$bucket}{$scaled_max_key}{scaled_occurrences}--;
        }

        # TO DO: Establish more graceful strategy for memory tracking on Windows (with acceptable performance)
        if( $track_memory && $processed_time_buckets++ % $check_memory_every == 0 && $^O ne 'MSWin32' ) {
            $current_memory_usage = get_memory_usage();
            if ($current_memory_usage > $max_memory_usage) {
                $max_memory_usage = $current_memory_usage;
            }
        }
    }

    if( $track_memory ) {
        $current_memory_usage = get_memory_usage();								# track maximum memory usage
        if ($current_memory_usage > $max_memory_usage) {
            $max_memory_usage = $current_memory_usage;
        }
    }	

    print "\r" . " " x ($terminal_width - 1) . "\r";		# clear the line of progress messages when moving on to the next file
    print "\r$colors{'bright-green'}Scaling and normalizing data completed.$colors{'NC'}";
    print " " x ( $terminal_width - length( "Scaling and normalizing data completed." ) );

    return;
}

sub get_heatmap_highlight_bg_color {
    my ($metric) = @_;
    # Return highlight background color for heatmap
    # Uses same colors as plain_bg in bar graph columns for consistency
    my %highlight_colors = (
        'duration' => 184,  # Yellow - matches bar graph column 2 plain_bg
        'bytes'    => 34,   # Green - matches bar graph column 3 plain_bg
        'count'    => 30,   # Cyan - matches bar graph column 4 plain_bg
    );
    return $highlight_colors{$metric} // 184;
}

sub format_heatmap_value {
    my ($value, $metric) = @_;
    if ($metric eq 'duration') {
        return format_time($value, 'ms');
    } elsif ($metric eq 'bytes') {
        return format_bytes($value, 'B');
    } elsif ($metric eq 'count') {
        return format_number($value);
    } else {
        return $value;
    }
}

sub get_heatmap_column_header {
    # Returns the heatmap legend string for use as column header
    # Labels are positioned at their EXACT character positions to align with data and footer
    # Uses the same positioning logic as print_heatmap_footer_scale()
    #
    # Format: [prefix] content_area [suffix]
    # - prefix (2 chars): aligns with "│ " in data rows
    # - content_area (heatmap_width chars): labels at exact positions
    # - suffix (2 chars): trailing padding
    #
    # Labels placed at exact positions:
    # - 0% (min): left-aligned at position 0
    # - 25%: centered at 25% position (if width > 75)
    # - 50%: "heatmap [metric]" centered at 50% position
    # - 75%: centered at 75% position (if width > 75)
    # - 100% (max): right-aligned to end at last position

    my $metric = $heatmap_metric;
    my $heatmap_content_width = $heatmap_width;

    # Build character array for exact positioning (same approach as footer)
    my @header_chars = (" ") x $heatmap_content_width;

    # Define markers: for header we show 0%, [25%], 50% (label), [75%], 100%
    # 25% and 75% only shown if width > 75
    my @marker_pcts;
    if ($heatmap_width > 75) {
        @marker_pcts = (0, 0.25, 0.50, 0.75, 1.0);
    } else {
        @marker_pcts = (0, 0.50, 1.0);
    }

    # Calculate positions and values for each marker
    my @markers;  # Each element: { pct, display_pos, value_str, is_label }
    for my $pct (@marker_pcts) {
        # Calculate display position (0 to width-1)
        my $display_pos = int($pct * ($heatmap_content_width - 1));
        $display_pos = $heatmap_content_width - 1 if $display_pos >= $heatmap_content_width;

        # Calculate boundary index for the value at this display position
        # Display column i shows data from bucket i, which covers [boundaries[i], boundaries[i+1])
        # So the value at position i is boundaries[i] (start of that column's range)
        # Exception: at 100% (last position), show boundaries[width] which is the max value
        my $boundary_idx;
        if ($pct >= 1.0) {
            $boundary_idx = $heatmap_content_width;  # Show max value at 100%
        } else {
            $boundary_idx = $display_pos;  # Show start of range at display position
        }

        my $value_str;
        my $is_label = 0;
        if ($pct == 0.50) {
            # Center position gets the "heatmap [metric]" label
            $value_str = "heatmap [$metric]";
            $is_label = 1;
        } else {
            # Other positions get the boundary value
            my $value;
            if (scalar(@heatmap_boundaries) > $boundary_idx) {
                $value = $heatmap_boundaries[$boundary_idx];
            } elsif ($pct == 0) {
                $value = $heatmap_min // 0;
            } else {
                $value = $heatmap_max // 0;
            }
            $value_str = format_heatmap_value($value, $metric);
        }

        push @markers, {
            pct => $pct,
            display_pos => $display_pos,
            value_str => $value_str,
            is_label => $is_label
        };
    }

    # Place labels at exact positions, avoiding overlap
    # Same logic as footer: first left-aligned, last right-aligned, others centered
    my $last_end = -1;
    for my $i (0 .. $#markers) {
        my $marker = $markers[$i];
        my $pos = $marker->{display_pos};
        my $label = $marker->{value_str};
        my $label_len = length($label);

        # Calculate start position
        my $start;
        if ($i == 0) {
            $start = 0;  # Left-align first label (0%)
        } elsif ($i == $#markers) {
            $start = $heatmap_content_width - $label_len;  # Right-align last label (100%)
        } else {
            $start = $pos - int($label_len / 2);  # Center others at their position
        }

        # Bounds checking
        $start = 0 if $start < 0;
        $start = $last_end + 1 if $start <= $last_end;  # Avoid overlap

        # Place the label if it fits
        if ($start + $label_len <= $heatmap_content_width) {
            for my $j (0 .. $label_len - 1) {
                $header_chars[$start + $j] = substr($label, $j, 1);
            }
            $last_end = $start + $label_len - 1;
        }
    }

    # Build final string: prefix (2) + content (heatmap_width) + suffix (2)
    # This gives durations_graph_width total when heatmap_width + 4 = durations_graph_width
    my $prefix = "  ";   # 2 spaces to align with "│ " in data rows
    my $content = join("", @header_chars);
    my $suffix = "  ";   # 2 trailing spaces

    return $prefix . $content . $suffix;
}

sub print_heatmap_row {
    my ($bucket, $printed_chars) = @_;

    # Use $heatmap_width for content width
    my $heatmap_content_width = $heatmap_width;

    my $missing_chars = $terminal_width - $printed_chars - $durations_graph_width;
    print " " x $missing_chars if $missing_chars > 0;
    print "$colors{'bright-black'}│$colors{'NC'} ";

    my $color_key = $heatmap_metric_map{$heatmap_metric}{color};
    my $color_hash = $heatmap_light_bg ? \%heatmap_colors_light : \%heatmap_colors;
    my @gradient = @{$color_hash->{$color_key}};
    my $highlight_bg = get_heatmap_highlight_bg_color($heatmap_metric);

    # Get percentile positions for this bucket
    my $percentiles = $heatmap_percentiles{$bucket} // {};
    my %percentile_positions;
    $percentile_positions{$percentiles->{p50}}  = 1 if defined $percentiles->{p50};
    $percentile_positions{$percentiles->{p95}}  = 1 if defined $percentiles->{p95};
    $percentile_positions{$percentiles->{p99}}  = 1 if defined $percentiles->{p99};
    $percentile_positions{$percentiles->{p999}} = 1 if defined $percentiles->{p999};

    for my $i (0 .. $heatmap_content_width - 1) {
        my $density = $heatmap_data{$bucket}{$i} // 0;
        my $density_hl = $heatmap_data_hl{$bucket}{$i} // 0;
        my $is_percentile = exists $percentile_positions{$i};

        if ($is_percentile) {
            # Percentile marker - use | character with bright-black (gray) for differentiation from data
            if ($density_hl > 0 && defined $highlight_regex) {
                print "\033[48;5;${highlight_bg}m$colors{'bright-black'}|$colors{'NC'}";
            } else {
                print "$colors{'bright-black'}|$colors{'NC'}";
            }
        } elsif ($density == 0) {
            # Empty cell - use NC/RESET (no background color)
            print " ";
        } else {
            # Calculate color index based on density (logarithmic scaling)
            my $color_index = 0;
            if ($heatmap_max_density > 1) {
                $color_index = int(log($density) / log($heatmap_max_density) * 7);
                $color_index = 7 if $color_index > 7;
                $color_index = 0 if $color_index < 0;
            }

            my $fg_color = $gradient[$color_index];

            if ($density_hl > 0 && defined $highlight_regex) {
                # Highlighted cell: use metric's column color as background
                print "\033[48;5;${highlight_bg}m\033[38;5;${fg_color}m█\033[0m";
            } else {
                # Normal cell: foreground color only, no background
                print "\033[38;5;${fg_color}m█\033[0m";
            }
        }
    }
    print " ";
}

sub print_heatmap_footer_scale {
    # Print the footer line with embedded scale showing values at key positions
    # Integrates directly into the horizontal separator line using ─ characters
    # with value labels replacing portions of the line at marker positions

    my $metric = $heatmap_metric;
    my $heatmap_content_width = $heatmap_width;

    # Calculate width before the heatmap column
    # This must match the position where │ is printed in print_heatmap_row()
    # Total width = timestamp + legend + bar_graph_columns + heatmap_column
    # So pre_heatmap = terminal_width - durations_graph_width gives us the position
    # But we need to account for all the content before the heatmap │
    my $pre_heatmap_width = $terminal_width - $durations_graph_width;

    # Build the scale with markers at positions 0%, 25%, 50%, 75%, 100%
    my @marker_positions = (0, 0.25, 0.50, 0.75, 1.0);
    my @marker_indices;
    my @marker_values;

    for my $pct (@marker_positions) {
        # Calculate display position (0 to width-1 for the heatmap columns)
        my $display_idx = int($pct * ($heatmap_content_width - 1));
        $display_idx = $heatmap_content_width - 1 if $display_idx >= $heatmap_content_width;
        push @marker_indices, $display_idx;

        # Calculate boundary index for the value at this display position
        # Display column i shows data from bucket i, which covers [boundaries[i], boundaries[i+1])
        # So the value at position i is boundaries[i] (start of that column's range)
        # Exception: at 100% (last position), show boundaries[width] which is the max value
        my $boundary_idx;
        if ($pct >= 1.0) {
            $boundary_idx = $heatmap_content_width;  # Show max value at 100%
        } else {
            $boundary_idx = $display_idx;  # Show start of range at display position
        }

        my $value;
        if (scalar(@heatmap_boundaries) > $boundary_idx) {
            $value = $heatmap_boundaries[$boundary_idx];
        } else {
            $value = $heatmap_max // 0;
        }
        push @marker_values, format_heatmap_value($value, $metric);
    }

    # Print the leading horizontal line (before heatmap column)
    print "$colors{'bright-black'}";
    print "─" x $pre_heatmap_width;
    print "┴";  # Connection to the column separator (aligns with │ in data rows)
    print "─";  # Padding character (aligns with space after │ in data rows)

    # Build the heatmap scale section with embedded labels
    # This is exactly heatmap_content_width characters to align with the 52 data columns
    my @scale_chars = ("─") x $heatmap_content_width;

    # Place labels at marker positions, avoiding overlap
    # Labels are positioned within the 52-char content area:
    # - First label (0%) left-aligned at position 0
    # - Last label (100%) right-aligned to end at position 51
    # - Middle labels centered at their respective positions
    my $last_end = -1;
    for my $i (0 .. $#marker_indices) {
        my $pos = $marker_indices[$i];
        my $label = $marker_values[$i];
        my $label_len = length($label);

        # Position label: first one left-aligned, last one right-aligned, others centered
        my $start;
        if ($i == 0) {
            $start = 0;  # Left-align first label
        } elsif ($i == $#marker_indices) {
            $start = $heatmap_content_width - $label_len;  # Right-align last label
        } else {
            $start = $pos - int($label_len / 2);  # Center others
        }

        $start = 0 if $start < 0;
        $start = $last_end + 1 if $start <= $last_end;  # Avoid overlap

        # Place the label if it fits
        if ($start + $label_len <= $heatmap_content_width) {
            for my $j (0 .. $label_len - 1) {
                $scale_chars[$start + $j] = substr($label, $j, 1);
            }
            $last_end = $start + $label_len - 1;
        }
    }

    print join("", @scale_chars);
    print "─";  # Trailing character (aligns with trailing space in data rows)
    print "$colors{'NC'}\n";
}

sub print_bar_graph {
    my $lines_printed = 0;
    my @csv_data;

    if( $total_lines_included ) {
        print "\n$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";

        print $colors{'bright-black'};
        my $printed_chars = 0;
        my $expected_chars = 0;

        foreach my $column (0 .. $#printed_column_names) {
            my $name   = $printed_column_names[$column];
            my $width  = $printed_column_widths[$column];    
            my $padding = $width - length($name);
            my $left_pad  = round( $padding / 2 );
            my $right_pad = $padding - $left_pad;
 
            if ( $printed_column_spacing[$column] > 0 ) {
                my $num_padding_chars = ($printed_column_spacing[$column]-$graph_column_padding_all);
                print ' ' x 1 if $num_padding_chars > 1;                                                    # set this to pipe to have the column line propagate up (does not work with line in durations)
                print ' ' x ($num_padding_chars > 1 ? $num_padding_chars - 1 : $num_padding_chars);
            }
            
            if( $left_pad > 0 ) {
                # print "$colors{'green'}:$colors{'NC'}" x $left_pad;
                print ' ' x $left_pad;
                # $printed_chars += $left_pad;
            };
            print $name;
            $printed_chars += length($name);
            if( $right_pad > 0 ) {
                # print "$colors{'red'}:$colors{'NC'}" x $right_pad;
                print ' ' x $right_pad;
                # $printed_chars += $right_pad;
            };

            if( $printed_column_spacing[$column] > 0 ) {
                print ' ' x $graph_column_padding_all;
            }
        }

        print "\n$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";
        $lines_printed++;

        foreach my $bucket (sort keys %log_occurrences) {
            my $bucket_time_str = strftime($output_timestamp_format, gmtime($bucket));
            my $printed_chars = 0;
            my $total_occurrences = 0;

            ## PRINT TIMESTAMP IN CHART ROW
            $bucket_time_str .= sprintf ".%03d", ($bucket-int($bucket))*1000 if $print_milliseconds;
            my $timestamp_legend_length = $timestamp_length;                                # already includes the padding in the value $graph_column_padding_all;
            print " " x $graph_column_padding_timestamp . $bucket_time_str . " " x $graph_column_padding_all;
            $printed_chars += $printed_column_widths[0] + $printed_column_spacing[0];       # timestamp column width and spacing
            $timestamp_legend_length += $printed_column_widths[1] + $printed_column_spacing[1] if( !( $omit_values && $omit_rate ) );

            my $log_details = "";
            my $rate_metrics = "";
            my $legend_length_bucket = 0;
            my %output_columns;
            my $scaled_occurrences_total = 0;

            ## LOOP THROUGH LOG CATEGORY BUCKETS AND PRINT PER ROW LEGEND COUNTS
            foreach my $category_bucket (@log_levels) {
                if (exists $log_occurrences{$bucket}{$category_bucket}) {
                    my $occurrences = $log_occurrences{$bucket}{$category_bucket}{occurrences};
                    my $color = $colors{$category_bucket} // $colors{'NC'};
                    next if $omit_values && $category_bucket !~ /^(err-rate|msg-rate)$/;	# we don't want to count data that won't be printed
                    next if $category_bucket =~ /^(err|msg)-rate$/ && $log_occurrences{$bucket}{'err-rate'}{occurrences} == 0 && $log_occurrences{$bucket}{'msg-rate'}{occurrences} == 0; 

                    if( $category_bucket =~ /(-HL|err-rate|msg-rate)$/ ) {
                        if( $category_bucket =~ /^err-rate$/ ) {
                            $rate_metrics .= " " if !$omit_values;
                            $rate_metrics .= "${color}" . format_number( $occurrences ) . "$colors{'NC'}";
                            $rate_metrics .= "$colors{'bright-black'}:$colors{'NC'}";
                            $legend_length_bucket += length( " " ) if !$omit_values;
                            $legend_length_bucket += length( format_number( $occurrences ) . ":" );
                        } elsif( $category_bucket =~ /^msg-rate$/ ) {
                            $rate_metrics .= "${color}" . format_number( $occurrences ) . "$colors{'NC'}";
                            $rate_metrics .= "$colors{'bright-black'}/m$colors{'NC'} ";
                            $legend_length_bucket += length( format_number( $occurrences ) . "/m " );
                        } else {
                            $log_details .= "${color}$occurrences$colors{'NC'}" . " " if $category_bucket =~ /-HL$/;
                            $legend_length_bucket += length("$occurrences ");
                        }
                    } elsif( $occurrences < 1 ) {					 		# don't include the empty bucket who's purpose is to normalize the buckets represented
                        next;
                    } else {
                        $log_details .= "$color$category_bucket: $occurrences$colors{'NC'} ";
                        $legend_length_bucket += length("$category_bucket: $occurrences ");
                    }

                    $total_occurrences += $occurrences if $category_bucket !~ /^(err-rate|msg-rate)$/;
                    $output_columns{$category_bucket} = $occurrences;
# 2026-01-04 TO DO: this may not be required, test after fixing the count and byte metric collection with no duration stats
                } else {
                    $output_columns{$category_bucket} = 0;                                  # push empty value to CSV data list
                }
            }

            # Add the log level message counts to the output CSV file
            foreach my $category_bucket ( @output_columns ) {
               next if $category_bucket =~ /^timestamp$/;								# skip the first column and get to the counts
               last if $category_bucket =~ /^totalOccurrences$/;								# only fill in empty values up to the totalOccurrences

               if( exists $output_columns{$category_bucket} ) {								# if there was a count for this log level, add it to the list 
                   push @csv_data, $output_columns{$category_bucket};

# 2026-01-04 TO DO: this may not be required, test after fixing the count and byte metric collection with no duration stats
               } else {
                   push @csv_data, undef;										# if there wasn't a count for this log level, add a blank column
               }
            }

            push @csv_data, $total_occurrences;										# add the total message count to the output CSV data

            print $log_details unless $omit_values;
            my $padding = $legend_length - $legend_length_bucket;
            $printed_chars += $legend_length_bucket ;

            print " " x ($padding > 0 ? $padding : 0);
            $printed_chars += ($padding > 0 ? $padding : 0);
            print $rate_metrics unless $omit_rate;

        # 2025-12-07 - this legend width plus spacing given the possible variations is quite hard to refactor, so leaving it like this
        if( $graph_column_padding_count >= 1 ) {						# if there is a padding character, make the first one the separator
            print "$colors{'bright-black'}│$colors{'NC'}";
            $printed_chars++;
	    }

	    if( $graph_column_padding_count - 1 >= 1 ) {					# and these are the remaining padding characters
            my $padding = $graph_column_padding_count - 1;
		    print " " x $padding;
            $printed_chars += $padding;
        }

            ## PRINT STANDARD 'COUNT' BAR GRAPH ##
            foreach my $category_bucket (@log_levels) {
                next unless $category_bucket !~ /^empty|err-rate|msg-rate$/; 			# don't include the empty bucket who's purpose is to normalize the buckets represented
                if (exists $log_occurrences{$bucket}{$category_bucket}) {
                    my $scaled_occurrences = $log_occurrences{$bucket}{$category_bucket}{scaled_occurrences};
                    $scaled_occurrences = 0 if $scaled_occurrences < 0;  # Guard against negative values
                    my $color = $colors{$category_bucket} // $colors{'NC'};
                    print "$color" . ( $category_bucket =~ /^[12345]xx(-HL)?$/ ? $blocks{'A'} : $blocks{$default_chart_block} ) x $scaled_occurrences . "$colors{'NC'}";	# provide a global way to change the bar character
                    $printed_chars += $scaled_occurrences;
                    $scaled_occurrences_total += $scaled_occurrences;
                }
            }

            print " " x $graph_column_padding_all;
            $printed_chars += $graph_column_padding_all;

            ## PRINT ADDITIONAL TRENDED VALUES ##
            if( $graph_count > 1 ) {
                my $column_number = 2;		                            # start after the timestamp and possibly legend columns
                my $missing_chars = ( $printed_column_widths[$column_count_pre_graph] + $printed_column_spacing[$column_count_pre_graph] ) - ( $scaled_occurrences_total + $printed_column_spacing[$column_count_pre_graph] );
                $missing_chars = 0 if $missing_chars < 0;  # Guard against negative values
                # Fill in empty characters to the start of the second graph space
                print " " x $missing_chars;
                $printed_chars += $missing_chars;

                foreach my $key ( @populated_graph_columns ) {		    # loop through available data columns to print
                    next if $key =~ /^occurrences$/;					# the counts have already been printed, so should skip this entry even if it is legitimate
                    my $scaled_trend_key = "scaled_${key}";
                    my $scaled_trend_key_highlight = "${scaled_trend_key}-HL";
                    my $scaled_trend_value = $log_stats{$bucket}{$scaled_trend_key};
                    my $trend_value = $log_stats{$bucket}{$key};
                    my $printed_column_index = $column_count_pre_graph-1+$column_number;

                    if( defined $log_stats{$bucket}{$key} ) {
                        if( $key =~ /^(time|duration)$/i ) {
                            # Select duration unit format based on column width: long (>=15), medium (>=10), short (<10)
                            # Short format omits space between value and unit to save space
                            my $column_width = $printed_column_widths[$printed_column_index];
                            my $time_format = $column_width >= 15 ? 'long' : ($column_width >= 10 ? 'medium' : 'short');
                            my $time_space = $time_format eq 'short' ? undef : ' ';
                            $trend_value = " " . format_time( $log_stats{$bucket}{$key}, 'ms', $time_format, $time_space );
                            push @csv_data, ltrim( $trend_value ), $log_stats{$bucket}{$key};				# push trend value to CSV data list
                        } elsif( $key =~ /^bytes$/i ) {
                            $trend_value = " " . format_bytes( $log_stats{$bucket}{$key}, 'B' );
                            push @csv_data, ltrim( $trend_value ), $log_stats{$bucket}{$key};				# push trend value to CSV data list
                        } elsif( $key =~ /^count$/i ) {
                            # $trend_value = defined $log_stats{$bucket}{$key} ? " $log_stats{$bucket}{$key}" : "";
                            $trend_value = " " . format_number( $log_stats{$bucket}{$key}, ' ', 2);
                            foreach my $metric ( qw( occurrences min mean max sum ) ) {
                                my $key_metric = "${key}_${metric}";
                                push @csv_data, $log_stats{$bucket}{$key_metric};
                            }
                        } else {
                            $trend_value = defined $log_stats{$bucket}{$key} ? " $log_stats{$bucket}{$key}" : "";
                            push @csv_data, ltrim( $trend_value );								            # push trend value to CSV data list
                        }

                        # SECONDARY TREND Print the secondary trend and associated value
                        # Yellow background 103m, Yellow Foreground 93m       184 medium yellow (nice!)  190 pale yellow  226 bright yellow   (184 + 190 are the winners)
                        # Cyan background 103m, Cyan Foreground 36m, bright Cyan 96m   46 Cyan BG   30 Deep Cyan  44 Bright Cyan 36 Darker Cyan 37 Vibrant Cyan 45 Cyan 106 Bright Cyan BG  51 bright cyan    123 medium cyan   159 light cyan  195 pale cyan
                        # Green                          32 Green FG    42 Green BG     92 Bright Green FG   102  Bright Green BG     34 Medium Green  46 Ultramarine Green  120  Light Green  121  Pale Green
                        # Blue                           34 Blue FG     44 Blug BG     94 Bright Blue FG   20 Ultramarine Blue   104 Bright Blue BG    20 Medium Blue   117 Light Blue   159  Pale Blue
                        # Magenta                        35 FG Magenta     45 BG Magenta      105 Bright Magenta    127 Medium magenta   201 Ultramarine Magenta   225 Light Magenta     219 Pale Magenta

                        # Start the background color with the brighter highlight value if there is anything to highlight
                        my ( $highlighted_bg_black_fg, $plain_bg_black_fg, $black_bg_plain_fg );

                        if( $column_number == 2 ) {	                        # Yellow				
                            $highlighted_bg_black_fg = "\033[48;5;226m\033[38;5;0m";
                            $plain_bg_black_fg = "\033[48;5;184m\033[38;5;0m";
                            $black_bg_plain_fg = "\033[0m\033[93m";
                        } elsif( $column_number == 3 ) {					# Green
                            $highlighted_bg_black_fg = "\033[48;5;46m\033[38;5;0m";
                            $plain_bg_black_fg = "\033[48;5;34m\033[38;5;0m";
                            $black_bg_plain_fg = "\033[0m\033[32m";
                        } elsif( $column_number == 4 ) {					# Cyan
                            $highlighted_bg_black_fg = "\033[48;5;36m\033[38;5;0m";
                            $plain_bg_black_fg = "\033[48;5;30m\033[38;5;0m";
                            $black_bg_plain_fg = "\033[0m\033[36m";
                        } elsif( $column_number == 5 ) {					# Blue
                            $highlighted_bg_black_fg = "\033[48;5;21m\033[38;5;0m";
                            $plain_bg_black_fg = "\033[48;5;20m\033[38;5;0m";
                            $black_bg_plain_fg = "\033[0m\033[34m";
                        } elsif( $column_number == 6 ) {					# Magenta
                            $highlighted_bg_black_fg = "\033[48;5;201m\033[38;5;0m";
                            $plain_bg_black_fg = "\033[48;5;127m\033[38;5;0m";
                            $black_bg_plain_fg = "\033[0m\033[35m";
                        } else {
                            last;
                        }

                        print " " x $graph_column_padding_other;				# if stated, this is the BEFORE column padding specific to these columns
                        $printed_chars += $graph_column_padding_other;
                        print $highlighted_bg_black_fg;

                        for my $i ( 0 .. $printed_column_widths[$printed_column_index] - 1) {
                            my $value_char = (split //, $trend_value )[$i];

                            # Switch over to the standard foreground/background colors once we have printed the required number of highlighted bars
                            if( defined $log_stats{$bucket}{$scaled_trend_key_highlight} && $log_stats{$bucket}{$scaled_trend_key_highlight} == $i ) {
                                print $plain_bg_black_fg;
                            }

                            # Switch over the graphs standard foreground color with black background once all bars are printed
                            if( $i == $scaled_trend_value ) {
                                print "$black_bg_plain_fg";
                            }

                            print length( $value_char ) ? $value_char : " ";
                            $printed_chars++;
                        }

                        print "$colors{'NC'}\033[0m";						# clear the foreground color

                    } else {
                        # This is the special condition where a column has no values/data for a particular interval, in which case we just need to print the column width in spaces
                        print " " x $printed_column_widths[$printed_column_index];
                        $printed_chars += $printed_column_widths[$printed_column_index];
                    }

                    print " " x $graph_column_padding_all;				    # if stated, this is the AFTER column padding for ALL columns
                    $printed_chars += $graph_column_padding_all;
                    $column_number++;
                }
            }

            # HEATMAP OR DURATION STATISTICS - print heatmap if enabled, otherwise duration statistics table
            if ($heatmap_enabled) {
                print_heatmap_row($bucket, $printed_chars);
            } elsif( $print_durations && !$omit_durations && !$omit_stats ) {
                my $missing_chars;
                $missing_chars =  $terminal_width - $printed_chars - $durations_graph_width;
                print " " x $missing_chars if $missing_chars > 0;
                print "$colors{'bright-black'}│$colors{'NC'}  ";
                if( defined $log_stats{$bucket}{bytes} || defined $log_stats{$bucket}{p50} || defined $log_stats{$bucket}{p95} || defined $log_stats{$bucket}{p99} || defined $log_stats{$bucket}{p999} || defined $log_stats{$bucket}{cv} ) {

                    my $cv_color = defined $log_stats{$bucket}{cv} && $log_stats{$bucket}{cv} >= 20 ? 'WARN-HL' : 'white-underline';

                    defined $log_stats{$bucket}{p50} ? printf( "$colors{'cyan'}P50:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p50} ) >= 4 ? format_time( $log_stats{$bucket}{p50}, 'ms' ) : $log_stats{$bucket}{p50} ) ) : printf( " " x 11 );
                    defined $log_stats{$bucket}{p95} ? printf( "$colors{'yellow'}P95:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p95} ) >= 4 ? format_time( $log_stats{$bucket}{p95}, 'ms' ) : $log_stats{$bucket}{p95} ) ) : printf( " " x 11 );
                    defined $log_stats{$bucket}{p99} ? printf( "$colors{'bright-yellow'}P99:%-6s$colors{'NC'} ", ( length( $log_stats{$bucket}{p99} ) >= 4 ? format_time( $log_stats{$bucket}{p99}, 'ms' ) : $log_stats{$bucket}{p99} ) ) : printf( " " x 11 );
                    defined $log_stats{$bucket}{p999} ? printf( "$colors{'red'}P999:%-5s$colors{'NC'} ", ( length( $log_stats{$bucket}{p999} ) >= 4 ? format_time( $log_stats{$bucket}{p999}, 'ms' ) : $log_stats{$bucket}{p999} ) ) : printf( " " x 11 );
                    defined $log_stats{$bucket}{cv} ? printf( "$colors{$cv_color}CV:%4s$colors{'NC'}", $log_stats{$bucket}{cv} ) : printf ( " " x 7 );

                    foreach my $stat ( qw( min mean max std_dev p1 p50 p75 p90 p95 p99 p999 cv z_score ) ) {				# push statistics data to the CSV data list
                        push @csv_data, $log_stats{$bucket}{$stat};
                    }
                }
            }

            # Print statistics for time-bucket statistics to the CSV file if activated
            if( $write_messages_to_csv && defined $csv_fh ) {
                $csv->print($csv_fh, [ $bucket_time_str, @csv_data ]);
            }

            undef @csv_data;

            print "\n";
            pause_for_keypress() if( $pause_output && $lines_printed++ > 1 && $lines_printed % ( $terminal_height - 1 ) == 0 );
        }

        # Print footer line - with embedded heatmap scale if enabled
        if ($heatmap_enabled) {
            print_heatmap_footer_scale();
        } else {
            print "$colors{'bright-black'}" . "─" x $terminal_width . "$colors{'NC'}\n";
        }
    } else {
        printf "Read $total_lines_read lines, however no lines matched any of the patterns within the timeframe.\n";
    }
    return;
}

sub print_summary_table {
    my $category_column_width = 30;
    my $occurrences_column_width = 10;
    my $table_padding = 2;
    my $padding = " " x $table_padding;
    my $column_padding = " " x 1;
    my $table_format = "$padding%-${category_column_width}s %${occurrences_column_width}d$padding\n";
    my $summary_table_width = $table_padding + $category_column_width + 1 + $occurrences_column_width + $table_padding;
    my $file_detail_width = $terminal_width - ( $summary_table_width + $table_padding * 2 );
    my ( @summary_table, @file_details );
    my ( @match_char ) = ( "$colors{'red'}χ", "$colors{'green'}√", "$colors{'green-HL'}√" );

    ## FORMAT MIN/MAX LOG TIMESTAMPS FOR THE SUMMARY ##
    my $min_timestamp_str = strftime($output_timestamp_format, gmtime($output_timestamp_min));
    my $max_timestamp_str = strftime($output_timestamp_format, gmtime($output_timestamp_max));
    $min_timestamp_str .= sprintf ".%03d", ($output_timestamp_min-int($output_timestamp_min))*1000 if $print_milliseconds;
    $max_timestamp_str .= sprintf ".%03d", ($output_timestamp_max-int($output_timestamp_max))*1000 if $print_milliseconds;

    ## PRINT COMMAND AND ARGUMENTS ##
    print "\n$colors{'bright-black'}options: ";
    my %argv_hash = map { $_ => 1 } @ARGV;
    my $skip_next = 0;
    for (my $i = 0; $i < @ORIGINAL_ARGV; $i++) {
        my $arg = $ORIGINAL_ARGV[$i];
        next if exists $argv_hash{$arg};  # Skip log files

        # Handle pattern file options with indicators
        if ($arg =~ /^(-ef|--exclude-file)$/ && $i + 1 < @ORIGINAL_ARGV) {
            my $file = $ORIGINAL_ARGV[$i + 1];
            my $indicator = get_pattern_file_indicator('exclude', $file);
            print "$arg $file$indicator ";
            $i++;  # Skip the filename in next iteration
        } elsif ($arg =~ /^(-if|--include-file)$/ && $i + 1 < @ORIGINAL_ARGV) {
            my $file = $ORIGINAL_ARGV[$i + 1];
            my $indicator = get_pattern_file_indicator('include', $file);
            print "$arg $file$indicator ";
            $i++;  # Skip the filename in next iteration
        } elsif ($arg =~ /^(-hf|--highlight-file)$/ && $i + 1 < @ORIGINAL_ARGV) {
            my $file = $ORIGINAL_ARGV[$i + 1];
            my $indicator = get_pattern_file_indicator('highlight', $file);
            print "$arg $file$indicator ";
            $i++;  # Skip the filename in next iteration
        } else {
            print "$arg ";
        }
    }
    print "$colors{'NC'}\n";

    return if $omit_summary;

    ## START SUMMARY STATISTIC TABLE ##
    push @summary_table, sprintf( "\n  " . "─" x ( $category_column_width + $occurrences_column_width + 1 ) . "$padding\n" );
    push @summary_table, sprintf( "  " . "%-${category_column_width}s %${occurrences_column_width}s$padding\n", "Category", "Total" ); 
    push @summary_table, sprintf( "  " . "─" x ( $category_column_width + $occurrences_column_width + 1 ) . "$padding\n" );

    foreach my $category_bucket (@log_levels) {
        next if $category_bucket =~ /^(empty|err-rate|msg-rate)$/;
        next unless $category_totals{$category_bucket};
	
        my ( $legend_title ) =  "$category_bucket:" . " " x ( 14 - length( $category_bucket ) );
        push @summary_table, sprintf( $table_format, $category_bucket, $category_totals{$category_bucket} ); 
    }

    push @summary_table, sprintf( "$padding" . "─" x ( $category_column_width + $occurrences_column_width + 1 ) . "$padding\n" );
    push @summary_table, sprintf( $table_format, "HIGHLIGHTED", $total_lines_highlighted ) if defined $highlight_regex;
    push @summary_table, sprintf( $table_format, "LINES INCLUDED", $total_lines_included ); 
    push @summary_table, sprintf( $table_format, "LINES READ", $total_lines_read ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "FILE PROCESSING TIME", format_time( $elapsed_read_files, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "INITIALIZE EMPTY BUCKETS", format_time( $elapsed_initialize_empty_time_windows, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "GROUP SIMILAR MESSAGES", format_time( $elapsed_group_similar_messages, 's', 'medium', " " ) ) unless $group_similar_sensitivity =~ /^none$/;
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "CALCULATE STATISTICS", format_time( $elapsed_calculate_statistics, 's', 'medium', " " ) ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "SCALE DATA TO TERMINAL", format_time( $elapsed_normalize_data, 's', 'medium', " " ) );
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "TOTAL TIME", format_time( $elapsed_total, 's', 'medium', " " ) ); 
    push @summary_table, sprintf( "$padding%-${category_column_width}s %${occurrences_column_width}s$padding\n", "MEMORY USED", format_bytes( $max_memory_usage, 'kB' ) ) if $track_memory;
    push @summary_table, sprintf( "$padding" . "─" x ( $category_column_width + $occurrences_column_width + 1 ) . "$padding\n" );

    push @file_details, "\n";
    push @file_details, sprintf( "$column_padding$padding$colors{'white-underline'}These file(s) were processed with analysis including results between $min_timestamp_str and $max_timestamp_str$colors{'NC'}\n" );
    push @file_details, "\n";
    foreach my $in_file (@files_processed) {
         my $filename_max_length = $file_detail_width - length( $column_padding ) - 3 - 4; 
         my $filename = length( $in_file ) > $filename_max_length ? "..." . substr( $in_file, length( $in_file ) - $filename_max_length ) : $in_file;  # -3 for '...', -4 for '[x] '
         push @file_details, sprintf( "$column_padding$padding$colors{'white'}\[%s$colors{'NC'}$colors{'white'}\] %-${filename_max_length}s$colors{'NC'}\n", $match_char[$in_files_matched{$in_file}], $filename );
    }

    for (my $i = 0; $i < max(scalar @summary_table, scalar @file_details); $i++) {
        if( $i >= scalar @summary_table ) {
            print " " x $summary_table_width . $column_padding;
        } else {
            chomp $summary_table[$i];
            print "$summary_table[$i]$column_padding";
        }

        if( $i >= scalar @file_details ) {
            print "\n";
        } else {
            print $file_details[$i];
        }
    }

    return;
}

sub print_message_summary {
    # Define the relative size of each column as a percentage
    my %col_relative_size;

    print "\n";

    if( $print_durations && !$omit_durations ) {
        %col_relative_size = (
            1 => 65,
            2 => 6,
            3 => 5,
            4 => 5,
            5 => 5,
            6 => 5,
            7 => 9,
        );
    } else {
        %col_relative_size = (
            1 => 94,
            2 => 6,
        );
    }

    # Initialize the hash to store the character width of each column
    my %col_width;
    my %col_names = (
        "message" => "Message",
        "occurrences" => "Occurrences",
        "min" => "Min",
        "p50" => "P50",
        "p999" => "P99.9",
        "cv" => "CV %",
        "time" => "Duration",
    );
    my $truncate_chars = 2;
    my @column_list = ( "message", "occurrences", "min", "p50", "p999", "cv", "time" );
    my @header_title_text = (
        "TOP HIGHLIGHTED MESSAGES (highlighted based on RegEx pattern match)",
        "TOP OVERALL MESSAGES (retained for after inclusion, exclusion, time range, and duration filters)"
    );

    my $table_padding_outer = 1;
    my $table_padding_inner = 1;

    # Calculate the total table width after applying outer padding
    my $table_width = $terminal_width - (2 * $table_padding_outer);

    # Calculate the absolute width for each column based on the relative size and inner padding and truncate where necessary
    foreach my $column (keys %col_relative_size) {
        $col_width{$column} = int($table_width * $col_relative_size{$column} / 100) - (2 * $table_padding_inner);
        if ( length( $col_names{$column_list[$column-1]} ) > $col_width{$column} - $truncate_chars ) {
            $col_names{$column_list[$column-1]} = substr( $col_names{$column_list[$column-1]}, 0, $col_width{$column} - $truncate_chars);
            $col_names{$column_list[$column-1]} .= "." unless $col_names{$column_list[$column-1]} =~ /\.$/;
        } elsif ( $column == "1" ) {
            foreach my $i ( 0 .. $#header_title_text ) {
                my $title_text_length = length( $header_title_text[$i] );
                if ( $title_text_length > $col_width{$column} - ( $truncate_chars + 2 ) ) {
                    my $target_length = $col_width{$column} - ( $truncate_chars + 2 );
                    $header_title_text[$i] = substr( $header_title_text[$i], 0, $target_length );
                    $header_title_text[$i] .= " ...";
                }
            }
        }
    }

    ### DETERMINE CUT OF HIGHLIGHTED VS PLAIN MESSAGES TO PRINT ###
    # Step 1: Sort and store available messages for each category in a hash of arrays
    my %sorted_keys = ( 'highlight' => [], 'plain' => [] );

    foreach my $grouping ( qw( highlight plain ) ) {
        my @sorted_keys = sort {
            my $occurrences_a = $log_messages{$grouping}{$a}{$sort_key} // 0;
            my $occurrences_b = $log_messages{$grouping}{$b}{$sort_key} // 0;
            if( $sort_ascending ) {
                $occurrences_a <=> $occurrences_b;
            } else {
                $occurrences_b <=> $occurrences_a;
            }
        } keys %{$log_messages{$grouping}};

        $sorted_keys{$grouping} = \@sorted_keys;
    }

    # Initialize the hash to store top message counts
    my %top_message_occurrences = (
        'highlight' => 0,
        'plain' => 0,
    );

    foreach my $grouping ( qw( highlight plain ) ) {
        for my $i (0 .. $#{$sorted_keys{$grouping}}) {
            last if $i >= $top_n_messages;
            $top_message_occurrences{$grouping}++;
        }
    }

    # Step 2: Determine how many messages to print from each category
    my $half_top_n = int($top_n_messages / 2);

    # Initialize the hash to store the number of messages to print
    my %messages_to_print = (
        'highlight' => $half_top_n,
        'plain' => $half_top_n,
    );

    $messages_to_print{'highlight'}++ if $top_n_messages % 2 != 0;		# if halving doesn't equate to Top N, then add another row to highlighted messages

    # Step 3: Adjust if one category has fewer messages than needed, ensuring the total remains $top_n_messages
    if ($top_message_occurrences{'highlight'} < $messages_to_print{'highlight'}) {
        $messages_to_print{'highlight'} = $top_message_occurrences{'highlight'};
        $messages_to_print{'plain'} = $top_n_messages - $messages_to_print{'highlight'};
    } elsif ($top_message_occurrences{'plain'} < $messages_to_print{'plain'}) {
        $messages_to_print{'plain'} = $top_message_occurrences{'plain'};
        $messages_to_print{'highlight'} = $top_n_messages - $messages_to_print{'plain'};
    }

    foreach my $grouping ( qw( highlight plain ) ) {
        my $messages_printed = 0;

        # Ensure the grouping exists and is a hash reference
        if (exists $log_messages{$grouping} && ref($log_messages{$grouping}) eq 'HASH') {
            my @top_keys = @{$sorted_keys{$grouping}}[0..($top_n_messages-1)] if scalar( @{$sorted_keys{$grouping}} ) > 0;
            next unless scalar(@top_keys) > 0;			# skip to the next category if their are no top message keys
            my $header_title = " ";

            if( $grouping eq "highlight" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-yellow-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $header_title_text[0] ) . " " x $table_padding_inner;

                if( $print_durations && !$omit_durations ) {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $col_names{'occurrences'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", $col_names{'min'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", $col_names{'p50'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", $col_names{'p999'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", $col_names{'cv'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", $col_names{'time'} ) . " " x $table_padding_inner; 
                } else {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $col_names{'occurrences'} ) . " " x $table_padding_inner; 
                }

                $header_title .= "$colors{'NC'}$colors{'bright-yellow'}";
            } elsif( $grouping eq "plain" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-cyan-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $header_title_text[1] ) . " " x $table_padding_inner;

                if( $print_durations && !$omit_durations ) {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $col_names{'occurrences'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", $col_names{'min'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", $col_names{'p50'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", $col_names{'p999'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", $col_names{'cv'} ) . " " x $table_padding_inner; 
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", $col_names{'time'} ) . " " x $table_padding_inner; 
                } else {
                    $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $col_names{'occurrences'} ) . " " x $table_padding_inner; 
                }

                $header_title .= "$colors{'NC'}$colors{'bright-cyan'}";
            }

            print "$header_title\n";
            print " " x $table_padding_outer . "─" x $table_width . "$colors{'NC'}\n";

            # Print the top messages
            foreach my $key (@top_keys) {
                next if $messages_printed++ >= $messages_to_print{$grouping};
                next if !defined $key;
                my $row = " " x $table_padding_outer;

                if (defined $key && exists $log_messages{$grouping}{$key}) {
                    my $message = substr( $key, 0, $col_width{1} );                         # truncate message for printing if too long to fit in column
                    my $occurrences = $log_messages{$grouping}{$key}{occurrences};
                    my $count_occurrences = $log_messages{$grouping}{$key}{count_occurrences};
                    my $count_min = $log_messages{$grouping}{$key}{count_min};
                    my $count_mean = $log_messages{$grouping}{$key}{count_mean};
                    my $count_max = $log_messages{$grouping}{$key}{count_max};
                    my $count_sum = $log_messages{$grouping}{$key}{count_sum};
                    my $total_bytes_num = $log_messages{$grouping}{$key}{total_bytes};
                    my $total_bytes = format_bytes( $total_bytes_num,'B' );
                    # BUG/ WRONG!!! below assumes all lines have bytes, but not really
                    my $mean_bytes = round( $total_bytes_num / $occurrences ) if defined $total_bytes_num; 
                    my $min = $log_messages{$grouping}{$key}{min};
                    my $mean = $log_messages{$grouping}{$key}{mean};
                    my $max = $log_messages{$grouping}{$key}{max};
                    my $std_dev = $log_messages{$grouping}{$key}{std_dev};
                    my $impact = $log_messages{$grouping}{$key}{impact};
                    my $p1 = $log_messages{$grouping}{$key}{p1};
                    my $p50 = $log_messages{$grouping}{$key}{p50};
                    my $p75 = $log_messages{$grouping}{$key}{p75};
                    my $p90 = $log_messages{$grouping}{$key}{p90};
                    my $p95 = $log_messages{$grouping}{$key}{p95};
                    my $p99 = $log_messages{$grouping}{$key}{p99};
                    my $p999 = $log_messages{$grouping}{$key}{p999};
                    my $cv = $log_messages{$grouping}{$key}{cv};
                    my $total_duration_num = $log_messages{$grouping}{$key}{total_duration_num};
                    my $total_duration = $log_messages{$grouping}{$key}{total_duration};

                    if( $print_durations && !$omit_durations && ( defined $log_messages{$grouping}{$key}{p50} || defined $log_messages{$grouping}{$key}{cv} || defined $log_messages{$grouping}{$key}{total_duration} ) ) {
                        $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $occurrences ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{3}s", defined $min ? ( length( $min ) >= 4 ? format_time( $min, 'ms', 'short' ) : $min ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{4}s", defined $p50 ? ( length( $p50 ) >= 4 ? format_time( $p50, 'ms', 'short' ) : $p50 ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{5}s", defined $p999 ? ( length( $p999 ) >= 4 ? format_time( $p999, 'ms', 'short' ) : $p999 ) : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{6}s", defined $cv ? $cv : "" ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{7}s", defined $total_duration ? $total_duration : "" ) . " " x $table_padding_inner; 
                    } else {
                        $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                        $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $occurrences ) . " " x $table_padding_inner; 
                    }

                    # Separated conditions for CSV output from printed column data
                    if( $write_messages_to_csv && defined $csv_fh ) {
                        $csv->print($csv_fh, [ $grouping, $key, $occurrences, $mean_bytes, $total_bytes_num, $total_bytes, $count_occurrences, $count_min, $count_mean, $count_max, $count_sum, $min, $mean, $max, $std_dev, $p1, $p50, $p75, $p90, $p95, $p99, $p999, $cv, $total_duration_num, $total_duration, $impact ]);
                    }

                    print "$row\n";
                }
            }

            print "\n";
        }
    }

    return;
}

sub print_threadpool_summary {
    # Define the relative size of each column as a percentage
    my %col_relative_size;

    print "\n";

    %col_relative_size = (
       1 => 94,
       2 => 6,
    );

    # Initialize the hash to store the character width of each column
    my %col_width;

    # Define the terminal width and padding values
    my $table_padding_outer = 1;
    my $table_padding_inner = 1;

    # Calculate the total table width after applying outer padding
    my $table_width = $terminal_width - (2 * $table_padding_outer);

    # Calculate the absolute width for each column based on the relative size and inner padding
    foreach my $column (keys %col_relative_size) {
        $col_width{$column} = int($table_width * $col_relative_size{$column} / 100) - (2 * $table_padding_inner);
    }

    ### DETERMINE CUT OF HIGHLIGHTED VS PLAIN MESSAGES TO PRINT ###
    # Step 1: Sort and store available messages for each category in a hash of arrays
    my %sorted_keys = ( 'highlight' => [], 'plain' => [] );
    foreach my $grouping ( qw( highlight plain ) ) {
        my @sorted_keys = sort {
            my $occurrences_a = scalar keys %{$threadpool_activity{$grouping}{$a}} // 0;
            my $occurrences_b = scalar keys %{$threadpool_activity{$grouping}{$b}} // 0;
            if( $sort_ascending ) {
                $occurrences_a <=> $occurrences_b;
            } else {
                $occurrences_b <=> $occurrences_a;
            }
        } keys %{$threadpool_activity{$grouping}};

        $sorted_keys{$grouping} = \@sorted_keys;
    }

    # Initialize the hash to store top message counts
    my %top_message_occurrences = (
        'highlight' => 0,
        'plain' => 0,
    );

    foreach my $grouping ( qw( highlight plain ) ) {
        for my $i (0 .. $#{$sorted_keys{$grouping}}) {
            last if $i >= $top_n_messages;
            $top_message_occurrences{$grouping}++;
        }
    }

    # Step 2: Determine how many messages to print from each category
    my $half_top_n = int($top_n_messages / 2);

    # Initialize the hash to store the number of messages to print
    my %messages_to_print = (
        'highlight' => $half_top_n,
        'plain' => $half_top_n,
    );

    $messages_to_print{'highlight'}++ if $top_n_messages % 2 != 0;		# if halving doesn't equate to Top N, then add another row to highlighted messages

    # Step 3: Adjust if one category has fewer messages than needed, ensuring the total remains $top_n_messages
    if ($top_message_occurrences{'highlight'} < $messages_to_print{'highlight'}) {
        $messages_to_print{'highlight'} = $top_message_occurrences{'highlight'};
        $messages_to_print{'plain'} = $top_n_messages - $messages_to_print{'highlight'};
    } elsif ($top_message_occurrences{'plain'} < $messages_to_print{'plain'}) {
        $messages_to_print{'plain'} = $top_message_occurrences{'plain'};
        $messages_to_print{'highlight'} = $top_n_messages - $messages_to_print{'plain'};
    }

    foreach my $grouping ( qw( highlight plain ) ) {
        my $messages_printed = 0;

        # Ensure the grouping exists and is a hash reference
        if (exists $threadpool_activity{$grouping} && ref($threadpool_activity{$grouping}) eq 'HASH') {
            my @top_keys = @{$sorted_keys{$grouping}}[0..($top_n_messages-1)] if scalar( @{$sorted_keys{$grouping}} ) > 0;

            next unless scalar(@top_keys) > 0;			# skip to the next category if their are no top message keys

            my $header_title = " ";

            if( $grouping eq "highlight" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-yellow-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP HIGHLIGHTED THREAD POOLS ─ ACTIVE THREADS" ) . " " x $table_padding_inner;
                $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                $header_title .= "$colors{'NC'}$colors{'bright-yellow'}";
            } elsif( $grouping eq "plain" ) {
                $header_title = " " x $table_padding_outer . "$colors{'bright-magenta-HL'}" . " " x $table_padding_inner . sprintf( "%-$col_width{1}s", "TOP OVERALL THREAD POOLS ─ ACTIVE THREADS" ) . " " x $table_padding_inner;
                $header_title .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", "Count" ) . " " x $table_padding_inner; 
                $header_title .= "$colors{'NC'}$colors{'bright-magenta'}";
            }

            print "$header_title\n";
            print " " x $table_padding_outer . "─" x $table_width . "$colors{'NC'}\n";

            # Print the top thread pools
            foreach my $key (@top_keys) {
                next if $messages_printed++ >= $messages_to_print{$grouping};
 
                my $row = " " x $table_padding_outer;

                if (defined $key && exists $threadpool_activity{$grouping}{$key}) {
                    my $message = substr( $key, 0, $col_width{1} );
                    my $occurrences = scalar keys %{$threadpool_activity{$grouping}{$key}};

                    $row .= " " x $table_padding_inner . sprintf( "%-$col_width{1}s", $message ) . " " x $table_padding_inner; 
                    $row .= " " x $table_padding_inner . sprintf( "%$col_width{2}s", $occurrences ) . " " x $table_padding_inner; 

                    print "$row\n";
                }
            }

            print "\n";
        }
    }

    return;
}

## MAIN ##

print_title();
adapt_to_terminal_settings(); 
adapt_to_command_line_options();

# READ AND PROCESS LOGS #
$start_time = [gettimeofday];
read_and_process_logs();
$end_time = [gettimeofday];
$elapsed_read_files = tv_interval($start_time, $end_time);

# INITIALIZE EMPTY TIME BUCKETS #
$start_time = [gettimeofday];
initialize_empty_time_windows();
$end_time = [gettimeofday];
$elapsed_initialize_empty_time_windows = tv_interval($start_time, $end_time);

# GROUP SIMILAR MESSAGES TOGETHER #
unless( $group_similar_sensitivity eq "none" ) {
    $start_time = [gettimeofday];

    $end_time = [gettimeofday];
    $elapsed_group_similar_messages = tv_interval($start_time, $end_time);
}

# CALCULATE STATISTICS #
$start_time = [gettimeofday];
print "Calculate statistics...";
calculate_all_statistics();
$end_time = [gettimeofday];
$elapsed_calculate_statistics = tv_interval($start_time, $end_time);

# CALCULATE HEATMAP BUCKETS (if enabled) #
calculate_heatmap_buckets() if $heatmap_enabled;

# NORMALIZE DATA FOR CONSOLE OUTPUT #
$start_time = [gettimeofday];
normalize_data_for_output();
$end_time = [gettimeofday];
$elapsed_normalize_data = tv_interval($start_time, $end_time);

$elapsed_total = $elapsed_read_files + $elapsed_initialize_empty_time_windows + $elapsed_calculate_statistics + $elapsed_normalize_data + $elapsed_group_similar_messages;

if( $write_messages_to_csv ) {														                # If write to CSV enabled, open filehandles
    $csv = Text::CSV->new({ binary => 1, eol => $/ });											    # Create a new CSV object
    my ($sec, $min, $hour, $mday, $mon, $year) = localtime();
    my $timestamp = sprintf( "%04d-%02d-%02d_%02d%02d%02d", $year + 1900, $mon + 1, $mday, $hour, $min, $sec );
    $csv_file_args =~ tr/!@#\$%\^&*()_+{}|:"<>?[\];',.\/\\`~ /_/;
    my $csv_file_name = "${timestamp}-LTL-STATS-${csv_file_args}.csv";
    open $csv_fh, '>', $csv_file_name or die "Could not open file: $!";								# Open a file for writing, then print the header/column names
    $csv->print($csv_fh, [ @output_columns ] );
}

print_bar_graph();
close $csv_fh or die "Could not close file: $!" if( $write_messages_to_csv && defined $csv_fh );	# Close the file handle

print_summary_table();

if( $write_messages_to_csv ) {														                # If write to CSV enabled, open filehandles
    $csv = Text::CSV->new({ binary => 1, eol => $/ });											    # Create a new CSV object
    my ($sec, $min, $hour, $mday, $mon, $year) = localtime();
    my $timestamp = sprintf( "%04d-%02d-%02d_%02d%02d%02d", $year + 1900, $mon + 1, $mday, $hour, $min, $sec );
    my $csv_file_name = "${timestamp}-LTL-MESSAGES-${csv_file_args}.csv";
    open $csv_fh, '>', $csv_file_name or die "Could not open file: $!";								# Open a file for writing, then print the header/column names
    $csv->print($csv_fh, [qw(Category Message Occurrences MeanBytes TotalBytes TotalBytesNice CountOccurrences CountMin CountMean CountMax CountSum MinDuration MeanDuration MaxDuration StdDev P1 P50 P75 P90 P95 P99 P99.9 CV TotalDuration TotalDurationNice Impact)]);
}

print_message_summary();														                    # Print and write message summaries
close $csv_fh or die "Could not close file: $!" if( $write_messages_to_csv && defined $csv_fh );	# Close the file handle

print_threadpool_summary() if $include_threadpool_summary;										    # Print threadpool summaries

print "\n";
exit;
